{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eaOEeYJ7QyNb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Things to execute\n"
      ],
      "metadata": {
        "id": "O8mKk7H3Xc0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-VC-FNMT3np",
        "outputId": "10736dda-163d-4de5-b705-16e1c4c15bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# animation\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# numerical methods\n",
        "import numpy as np\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "\n",
        "# data\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "# neural network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "# timer\n",
        "import time\n",
        "\n",
        "# pandas (to convert and save data)\n",
        "import pandas as pd\n",
        "\n",
        "# seaborn (heatmap)\n",
        "import seaborn as sns\n",
        "\n",
        "# google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# checkpoint\n",
        "import pickle\n",
        "\n",
        "# operating system\n",
        "import os\n",
        "\n",
        "# gaussian process regression\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "\n",
        "# math tools\n",
        "import math\n",
        "from functools import reduce\n",
        "\n",
        "# convolution operation\n",
        "import scipy.signal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MEAN & STD COMPUTER\n",
        "def compute_mean_std(dataset_parameters, batch_size=16, verbose=True, normalize=False):\n",
        "  \"\"\"\n",
        "  Function that computes the mean and standard deviation of the dataset\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # create the training data and load it\n",
        "  num_samples, block_size, m, n, tau, t0, rho = dataset_parameters\n",
        "\n",
        "  # load the dataset and dataloader\n",
        "  dataset = gol_dataset(num_samples, block_size, m, n, tau, t0, rho, balance=True, normalize=False)\n",
        "\n",
        "  # turn into np\n",
        "  data = np.array(dataset.data)\n",
        "\n",
        "  # compute the mean and standard deviation\n",
        "  mean = data.mean(axis=0)\n",
        "  std = data.std(axis=0)\n",
        "\n",
        "  # save it\n",
        "  file_path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "  mean_filename = f\"mean_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "  std_filename = f\"std_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "  np.save(file_path + mean_filename, mean)\n",
        "  np.save(file_path + std_filename, std)\n",
        "\n",
        "  # print the results\n",
        "  if verbose:\n",
        "    print(f\"Mean: {mean}\")\n",
        "    print(f\"Std: {std}\")\n",
        "\n",
        "\n",
        "  return mean, std\n",
        "\n",
        "def computing_neighbour_sum(grid):\n",
        "  \"\"\"\n",
        "  Computes the neighbours' sum for each cell in the grid with periodic boundary conditions\n",
        "  \"\"\"\n",
        "  return (\n",
        "    np.roll(np.roll(grid, 1, axis=0), 1, axis=1)  # top-left neighbor\n",
        "    + np.roll(np.roll(grid, 1, axis=0), 0, axis=1)  # top neighbor\n",
        "    + np.roll(np.roll(grid, 1, axis=0), -1, axis=1)  # top-right neighbor\n",
        "    + np.roll(np.roll(grid, 0, axis=0), 1, axis=1)  # left neighbor\n",
        "    + np.roll(np.roll(grid, 0, axis=0), -1, axis=1)  # right neighbor\n",
        "    + np.roll(np.roll(grid, -1, axis=0), 1, axis=1)  # bottom-left neighbor\n",
        "    + np.roll(np.roll(grid, -1, axis=0), 0, axis=1)  # bottom neighbor\n",
        "    + np.roll(np.roll(grid, -1, axis=0), -1, axis=1)  # bottom-right neighbor\n",
        "    )\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# GAME OF LIFE NEXT STEP GENERATOR\n",
        "def next_step_fn(grid):\n",
        "    \"\"\"Function that computes the next grid in Conway's Game of Life using periodic boundary conditions\"\"\"\n",
        "\n",
        "    # we are shifting the grid while wrapping around at the edges (torus) so as to impose the periodic boundary conditions\n",
        "    neighbours_sum = computing_neighbour_sum(grid)\n",
        "\n",
        "    # grid's length as a variable\n",
        "    n = len(grid)\n",
        "\n",
        "    # Conway's Game of Life rules\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "\n",
        "            # Cells with alive elements\n",
        "            if grid[i][j] == 1:\n",
        "                if (neighbours_sum[i][j] <= 1) or (neighbours_sum[i][j] >= 4):\n",
        "                    grid[i][j] = 0\n",
        "\n",
        "            # Cells with dead elements\n",
        "            elif grid[i][j] == 0:\n",
        "                if (neighbours_sum[i][j] == 3):\n",
        "                    grid[i][j] = 1\n",
        "\n",
        "    # we return the grid\n",
        "    return grid\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    # numpy seed\n",
        "    np.random.seed(seed)\n",
        "    # torch seed\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# COARSE GRAINING IMPLEMENTATION\n",
        "def block_average(grid, block_size):\n",
        "    \"\"\"\n",
        "    Function that applies coarse-graining for a block_size x block_size\n",
        "\n",
        "    \"\"\"\n",
        "    # length parameters\n",
        "    n = len(grid)\n",
        "\n",
        "    # we compute how many blocks will there be in the coarsed grid\n",
        "    new_blocks = n//block_size\n",
        "\n",
        "    # initialize sum variables\n",
        "    alive_sum = 0\n",
        "    dead_sum = 0\n",
        "\n",
        "    # initialize coarsed grid\n",
        "    coarse_grid = np.zeros((new_blocks,new_blocks),dtype=int)\n",
        "\n",
        "    # loops to go through the future blocks\n",
        "    for i in range(new_blocks):\n",
        "\n",
        "        for j in range(new_blocks):\n",
        "\n",
        "            # we create a subgrid by slicing our original grid\n",
        "            subgrid = grid[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
        "\n",
        "            # wrap when the dimensions do not match\n",
        "            # x-axis\n",
        "            if subgrid.shape[0] < block_size:\n",
        "              subgrid = np.vstack([subgrid, grid[0:block_size - subgrid.shape[0], j * block_size:(j + 1) * block_size]])\n",
        "            # y-axis\n",
        "            if subgrid.shape[1] < block_size:\n",
        "              subgrid = np.hstack([subgrid, grid[i * block_size:(i + 1) * block_size, 0:block_size - subgrid.shape[1]]])\n",
        "\n",
        "            # we sum over the elements of the subgrid\n",
        "            alive_sum = np.sum(subgrid)\n",
        "            dead_sum = block_size**2 - alive_sum\n",
        "\n",
        "            # let's see if we have more alive or dead and coarse-grain as such\n",
        "            if alive_sum > dead_sum:\n",
        "                coarse_grid[i,j] = 1\n",
        "            else:\n",
        "                coarse_grid[i,j] = 0\n",
        "\n",
        "    return coarse_grid\n",
        "\n",
        "\n",
        "# MULTILAYERPERCEPTRON: CREATION OF THE NEURAL NETWORK MODEL\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
        "    \"\"\"Initialization of the MLP\n",
        "\n",
        "        Parameters: num_input, num_output, num_hidden\n",
        "        - input_size: number of input neurons\n",
        "        - output_size: number of output neurons\n",
        "        - hidden_size: number of neurons in hidden layers (list because the number can differ layer to layer)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # calls the constructor of nn.Module (needed to use NN functionaliaties)\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    # array that will be the layers\n",
        "    layers = []\n",
        "\n",
        "    # number of neurons that each layer will have (this variable will be updated each time)\n",
        "    num_neurons = input_size\n",
        "\n",
        "    # loop that creates the layers of the required size\n",
        "    for num_hidden in hidden_size:\n",
        "\n",
        "      # nn.Linear creates a fully connected layer\n",
        "      layers.append(nn.Linear(num_neurons, num_hidden))\n",
        "\n",
        "      # batch normalization\n",
        "      layers.append(nn.BatchNorm1d(num_hidden))\n",
        "\n",
        "      # activation function - ReLU: Rectified Linear Unit (f(x) = max(0,x)): used in hidden layers\n",
        "      layers.append(nn.ReLU())\n",
        "\n",
        "      # apply the Dropout\n",
        "      layers.append(nn.Dropout(p=dropout_rate))\n",
        "\n",
        "      # update the number of neurons\n",
        "      num_neurons = num_hidden\n",
        "\n",
        "    # we connect the last two matrices\n",
        "    layers.append(nn.Linear(num_neurons, output_size))\n",
        "\n",
        "    # sigmoid activation because of the binary outcome\n",
        "    #layers.append(nn.Sigmoid())\n",
        "\n",
        "    # complete model of the neural network: layers + activation functions: *unpacks the list\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"We run an input tensor (x) through the model we defined before\"\"\"\n",
        "    x = x.view(x.size(0),-1)\n",
        "    # we return the input tensor but with our mlp applied\n",
        "    return self.model(x)\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# L1 REGULARIZATION\n",
        "\n",
        "def L1_regularization(model, lambda_l1):\n",
        "  \"\"\"\n",
        "  Function that implements L1 Regularization:\n",
        "    it adds a penalty to the loss function based on the abs(weights) to encourage sparsity and reduce overfitting\n",
        "\n",
        "  Parameters:\n",
        "  - model: neural network model\n",
        "  - lambda_l1: parameter that controls the weight of the penalty term\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize the loss\n",
        "  L1_loss = 0\n",
        "\n",
        "  # add the loss corresponding to the absolute values\n",
        "  for param in model.parameters():\n",
        "    L1_loss += torch.sum(torch.abs(param))\n",
        "\n",
        "  # return the loss with the weight controlling parameter\n",
        "  return lambda_l1 * L1_loss"
      ],
      "metadata": {
        "id": "M_u1suBTU-wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET GENERATION WITH ROLLING TO FIND BETTER DATA\n",
        "class gol_dataset_rolling():\n",
        "  def __init__(self, num_samples, block_size, m, n, tau, t0, rho, normalize):\n",
        "\n",
        "    \"\"\"\n",
        "    Initialization of the dataset: converting data into PyTorch tensors\n",
        "\n",
        "    Parameters: num_samples, n, m, tau, block_size\n",
        "    - num_samples: number of samples (random grids) that will be created\n",
        "    - block_size: size of the coarsed grid (optional)\n",
        "    - m: dimensions of the subgrid\n",
        "    - n: dimensions of the grid\n",
        "    - tau: how many generations will we generate?\n",
        "    - t0: initialization time\n",
        "    - rho: density\n",
        "    - balance: if True, balance the dataset (equal number of alive and dead cells)\n",
        "    Data: grid sequences over a tau generations\n",
        "    Labels: center cell of the tau+1 generation\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # number of samples\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "    # grid coarsing parameter\n",
        "    self.block_size = block_size\n",
        "\n",
        "    # fixed parameters\n",
        "    self.n = n\n",
        "    self.m = m\n",
        "    self.tau = tau\n",
        "\n",
        "    # initialization time\n",
        "    self.t0 = t0\n",
        "\n",
        "    # density\n",
        "    self.rho = rho\n",
        "\n",
        "    # important to check whether the n and m values are possible\n",
        "    assert n >= m, \"n must be greater or equal than m\"\n",
        "\n",
        "    # data initialization\n",
        "    self.data = []\n",
        "\n",
        "    # labels initialization\n",
        "    self.labels = []\n",
        "\n",
        "    # generate the amount of data we want with balance\n",
        "    target = num_samples//2\n",
        "    alive_count = 0\n",
        "    dead_count = 0\n",
        "    counter = 0\n",
        "    while True:\n",
        "\n",
        "      # to add the data to the tensors we need an index counter = index\n",
        "      index = 0\n",
        "\n",
        "      if alive_count >= target and dead_count >= target:\n",
        "        break\n",
        "\n",
        "      # NxN grid\n",
        "      grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "\n",
        "      # we select the top-left corner from which we'll start the MxM subgrid\n",
        "      i, j = np.random.randint(0, n-m+1, 2)\n",
        "\n",
        "      # initialize sequence: matrix that will store tau grids\n",
        "      sequence = np.zeros((tau, m//block_size, m//block_size), dtype=np.float32)\n",
        "\n",
        "      # loop that iterates the initial grid t_0 times to arrive to the initialization time\n",
        "      for t in range(t0):\n",
        "\n",
        "        # we update the grid t0 generations\n",
        "        grid = next_step_fn(grid)\n",
        "\n",
        "      # loop that iterates the initial grid tau times according to the game of life rules\n",
        "      for t in range(tau):\n",
        "\n",
        "        # choose an MxM subgrid\n",
        "        subgrid = grid[i:i+m, j:j+m]\n",
        "\n",
        "        # apply coarse-graining\n",
        "        coarse_grid = block_average(subgrid, block_size)\n",
        "\n",
        "        # add to the data\n",
        "        sequence[t] = coarse_grid\n",
        "\n",
        "        # update the grid\n",
        "        grid = next_step_fn(grid)\n",
        "\n",
        "      # coarse grain the tau+1 grid\n",
        "      subgrid = grid[i:i+m, j:j+m]\n",
        "      coarse_grid = block_average(subgrid, block_size)\n",
        "      label = coarse_grid[m//(2*block_size), m//(2*block_size)]\n",
        "\n",
        "      if dead_count == target and label == 0:\n",
        "        for i in range(len(coarse_grid)):\n",
        "          for j in range(len(coarse_grid)):\n",
        "            if coarse_grid[i,j] == 1:\n",
        "              label = coarse_grid[i,j]\n",
        "              for t in range(tau):\n",
        "                sequence[t] = np.roll(sequence[t], -i+len(coarse_grid)//2, axis=0)\n",
        "                sequence[t] = np.roll(sequence[t], -j+len(coarse_grid)//2, axis=1)\n",
        "              break\n",
        "          if label == 1:\n",
        "            break\n",
        "\n",
        "      elif alive_count == target and label == 1:\n",
        "        for i in range(len(coarse_grid)):\n",
        "          for j in range(len(coarse_grid)):\n",
        "            if coarse_grid[i,j] == 0:\n",
        "              label = coarse_grid[i,j]\n",
        "              coarse_grid = np.roll(coarse_grid, -i, axis=0)\n",
        "              coarse_grid = np.roll(coarse_grid, -j, axis=1)\n",
        "              break\n",
        "          if label == 0:\n",
        "            break\n",
        "\n",
        "      if int(label) == 1 and alive_count < target:\n",
        "        self.data.append(sequence)\n",
        "        self.labels.append(label)\n",
        "        alive_count += 1\n",
        "\n",
        "      elif int(label) == 0 and dead_count < target:\n",
        "        self.data.append(sequence)\n",
        "        self.labels.append(label)\n",
        "        dead_count += 1\n",
        "\n",
        "      counter += 1\n",
        "\n",
        "    # print(f\"Counter : {counter}, Dead count : {dead_count}, Alive count : {alive_count}\")\n",
        "    # data normalization\n",
        "    if normalize:\n",
        "      self.normalize()\n",
        "\n",
        "    # turn into torch tensors\n",
        "    self.data = torch.tensor(self.data, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Length of the dataset (how many samples exist)\"\"\"\n",
        "    length = len(self.labels)\n",
        "    return length\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\"Retrieve a single sample from the dataset\"\"\"\n",
        "\n",
        "    x = self.data[idx]\n",
        "\n",
        "    # labels as the y vector\n",
        "    y = self.labels[idx]\n",
        "\n",
        "    return x,y\n",
        "\n",
        "  def normalize(self):\n",
        "    \"\"\"Normalize dataset using precomputed mean and std\"\"\"\n",
        "\n",
        "    self.data = np.array(self.data)\n",
        "    tau, m, m = self.data.shape[1:]\n",
        "    #mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{self.block_size}_{self.m}_{self.n}_{self.tau}_{self.rho}.npy\"\n",
        "    #std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{self.block_size}_{self.m}_{self.n}_{self.tau}_{self.rho}.npy\"\n",
        "\n",
        "    try:\n",
        "      mean = np.load(mean_path)\n",
        "      std = np.load(std_path)\n",
        "    except:\n",
        "      raise RuntimeError(\"Mean and std files not found\")\n",
        "\n",
        "    # avoid NaN\n",
        "    eps = 1e-6\n",
        "    std[std < eps] = 1\n",
        "    self.data = (self.data - mean) / std\n"
      ],
      "metadata": {
        "id": "LgS7679enFDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET GENERATION FIXED PARAMETERS AND BLOCK SIZE AVERAGE COARSE-GRAINING\n",
        "class gol_dataset():\n",
        "  def __init__(self, num_samples, block_size, m, n, tau, t0, rho, balance, normalize):\n",
        "\n",
        "    \"\"\"Initialization of the dataset: converting data into PyTorch tensors\n",
        "\n",
        "    Parameters: num_samples, n, m, tau, block_size\n",
        "    - num_samples: number of samples (random grids) that will be created\n",
        "    - block_size: size of the coarsed grid (optional)\n",
        "    - m: dimensions of the subgrid\n",
        "    - n: dimensions of the grid\n",
        "    - tau: how many generations will we generate?\n",
        "    - t0: initialization time\n",
        "    - rho: density\n",
        "    - balance: if True, balance the dataset (equal number of alive and dead cells)\n",
        "    Data: grid sequences over a tau generations\n",
        "    Labels: center cell of the tau+1 generation\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # number of samples\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "    # grid coarsing parameter\n",
        "    self.block_size = block_size\n",
        "\n",
        "    # fixed parameters\n",
        "    self.n = n\n",
        "    self.m = m\n",
        "    self.tau = tau\n",
        "\n",
        "    # initialization time\n",
        "    self.t0 = t0\n",
        "\n",
        "    # density\n",
        "    self.rho = rho\n",
        "\n",
        "    # important to check whether the n and m values are possible\n",
        "    assert n >= m, \"n must be greater or equal than m\"\n",
        "\n",
        "    # data initialization\n",
        "    self.data = []\n",
        "\n",
        "    # labels initialization\n",
        "    self.labels = []\n",
        "\n",
        "    # generate the amount of data we want with balance\n",
        "    if balance:\n",
        "      target = num_samples//2\n",
        "      alive_count = 0\n",
        "      dead_count = 0\n",
        "    else:\n",
        "      total_target = num_samples\n",
        "\n",
        "    counter = 0\n",
        "    while True:\n",
        "\n",
        "      # to add the data to the tensors we need an index counter = index\n",
        "      index = 0\n",
        "\n",
        "      if balance:\n",
        "        if alive_count >= target and dead_count >= target:\n",
        "          break\n",
        "      else:\n",
        "        if len(self.data) >= total_target:\n",
        "          break\n",
        "\n",
        "      # NxN grid\n",
        "      grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "\n",
        "      # we select the top-left corner from which we'll start the MxM subgrid\n",
        "      i, j = np.random.randint(0, n-m+1, 2)\n",
        "\n",
        "      # initialize sequence: matrix that will store tau grids\n",
        "      sequence = np.zeros((tau, m//block_size, m//block_size), dtype=np.float32)\n",
        "\n",
        "      # loop that iterates the initial grid t_0 times to arrive to the initialization time\n",
        "      for t in range(t0):\n",
        "\n",
        "        # we update the grid t0 generations\n",
        "        grid = next_step_fn(grid)\n",
        "\n",
        "      # loop that iterates the initial grid tau times according to the game of life rules\n",
        "      for t in range(tau):\n",
        "\n",
        "        # choose an MxM subgrid\n",
        "        subgrid = grid[i:i+m, j:j+m]\n",
        "\n",
        "        # apply coarse-graining\n",
        "        coarse_grid = block_average(subgrid, block_size)\n",
        "\n",
        "        # add to the data\n",
        "        sequence[t] = coarse_grid\n",
        "\n",
        "        # update the grid\n",
        "        grid = next_step_fn(grid)\n",
        "\n",
        "      # coarse grain the tau+1 grid\n",
        "      subgrid = grid[i:i+m, j:j+m]\n",
        "      coarse_grid = block_average(subgrid, block_size)\n",
        "      label = coarse_grid[m//(2*block_size), m//(2*block_size)]\n",
        "\n",
        "      if balance:\n",
        "        if int(label) == 1 and alive_count < target:\n",
        "          self.data.append(sequence)\n",
        "          self.labels.append(label)\n",
        "          alive_count += 1\n",
        "          index += 1\n",
        "        elif int(label) == 0 and dead_count < target:\n",
        "          self.data.append(sequence)\n",
        "          self.labels.append(label)\n",
        "          dead_count += 1\n",
        "          index += 1\n",
        "      else:\n",
        "        self.data.append(sequence)\n",
        "        self.labels.append(label)\n",
        "\n",
        "      # have 2 datasets: don't filter one (balance and imbalanced)\n",
        "\n",
        "      counter += 1\n",
        "    print(f\"Counter : {counter}, Dead count : {dead_count}, Alive coun : {alive_count}\")\n",
        "\n",
        "    if normalize:\n",
        "      self.normalize()\n",
        "\n",
        "    # normalize data\n",
        "    # turn into torch tensors\n",
        "    self.data = torch.tensor(self.data, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Length of the dataset (how many samples exist)\"\"\"\n",
        "    length = len(self.labels)\n",
        "    return length\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\"Retrieve a single sample from the dataset\"\"\"\n",
        "\n",
        "    x = self.data[idx]\n",
        "\n",
        "    # labels as the y vector\n",
        "    y = self.labels[idx]\n",
        "\n",
        "    return x,y\n",
        "\n",
        "  def normalize(self):\n",
        "    \"\"\"Normalize dataset using precomputed mean and std\"\"\"\n",
        "\n",
        "    self.data = np.array(self.data)\n",
        "    tau, m, m = self.data.shape[1:]\n",
        "    mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{self.block_size}_{self.m}_{self.n}_{self.tau}_{self.rho}.npy\"\n",
        "    std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{self.block_size}_{self.m}_{self.n}_{self.tau}_{self.rho}.npy\"\n",
        "\n",
        "    try:\n",
        "      mean = np.load(mean_path)\n",
        "      std = np.load(std_path)\n",
        "    except:\n",
        "      raise RuntimeError(\"Mean and std files not found\")\n",
        "\n",
        "    # avoid NaN\n",
        "    eps = 1e-6\n",
        "    std[std < eps] = 1\n",
        "    self.data = (self.data - mean) / std\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# TRAINING AND VALIDATING\n",
        "def train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed, conv, balance, lambda_l1=0.01, printing_rhythm=10, verbose=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that trains the model and validates it\n",
        "\n",
        "  Parameters:\n",
        "  - model: MLP neural network model\n",
        "  - batch_size: size of the batches\n",
        "  - train_size: size of the training data\n",
        "  - val_size: size of the validation data\n",
        "  - fixed: if True, fixed grid dimensions\n",
        "          if False, multipliers\n",
        "  - conv: if True, convolutional coarse graining\n",
        "          if False, block average coarse graining\n",
        "  - balance: if True, balance the dataset (equal number of alive and dead cells)\n",
        "  - lambda_l1: parameter that controls the weight of the penalty term\n",
        "  - printing_rhythm: how often to print the loss\n",
        "  - dataset_parameters: parameters of the dataset (num_samples, block_size, m_multiplier, n_multiplier, tau_multiplier, t0, rho)\n",
        "  - verbose: if True, prints the loss\n",
        "\n",
        "  Returns:\n",
        "  - training_loss\n",
        "  - validation_loss\n",
        "  - accuracy\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize the losses\n",
        "  train_losses_per_batch = []\n",
        "  val_losses_per_batch = []\n",
        "  accuracy_per_batch = []\n",
        "\n",
        "  # create the training data and load it\n",
        "  num_samples, block_size, m, n, tau, t0, rho = dataset_parameters\n",
        "  training_dataset = gol_dataset_rolling(train_size, block_size, m, n, tau, t0, rho, normalize=True)\n",
        "  train_loader = DataLoader(training_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "  # now, we generate validation data\n",
        "  validation_dataset = gol_dataset_rolling(val_size, block_size, m, n, tau, t0, rho, normalize=True)\n",
        "  validation_loader = DataLoader(validation_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "  # print the length of the dataset\n",
        "  print(f\"Length of the training dataset: {len(training_dataset)}\")\n",
        "\n",
        "  # optimizer and loss function\n",
        "  optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
        "  loss_fn = nn.BCEWithLogitsLoss()\n",
        "  # loss_fn = nn.BCELoss()\n",
        "\n",
        "  # different optimizer?\n",
        "  # test different gridsizes\n",
        "\n",
        "  # loop that goes through the batches of the training data\n",
        "  for i, batch in enumerate(train_loader):\n",
        "\n",
        "    # evaluation before training\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct_before = 0\n",
        "        total_before = 0\n",
        "        for x_full, y_full in train_loader:\n",
        "            x_full = x_full.view(x_full.size(0), -1)\n",
        "            y_pred_full = model(x_full).squeeze()\n",
        "            y_pred_binary_full = (y_pred_full > 0.5).float()\n",
        "            correct_before += (y_pred_binary_full == y_full).float().sum().item()\n",
        "            total_before += y_full.size(0)\n",
        "        accuracy_before = correct_before / total_before\n",
        "\n",
        "    # print only after printing rhythm\n",
        "    if verbose and i % printing_rhythm == 0:\n",
        "      print(f\"[Pre-batch {i}] Accuracy on full training data: {accuracy_before:.4f}\")\n",
        "\n",
        "    # initialize the counters\n",
        "    model.train()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    zero_count_train = 0\n",
        "    one_count_train = 0\n",
        "\n",
        "    # establish training\n",
        "    model.train()\n",
        "\n",
        "    # define the x,y\n",
        "    x_training, y_training = batch\n",
        "\n",
        "    # input data\n",
        "    x_training = x_training.view(x_training.size(0), -1)\n",
        "\n",
        "    # reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # predict with the model (forward pass) (.squeeze erases the extradimension)\n",
        "    y_pred = model(x_training).squeeze()\n",
        "\n",
        "    # compute the training loss\n",
        "    loss = loss_fn(y_pred, y_training)\n",
        "    raw_loss = loss.item()\n",
        "\n",
        "    # add L1 regularization\n",
        "    loss += L1_regularization(model, lambda_l1)\n",
        "\n",
        "    # backpropagation: compute gradient for the weights\n",
        "    loss.backward()\n",
        "\n",
        "    # to prevent exploding gradients (try vanishing gradients too)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "\n",
        "    # update weights with the optimizer (Adam in our case)\n",
        "    optimizer.step()\n",
        "\n",
        "    # save the data lost by batch\n",
        "    train_losses_per_batch.append(raw_loss)\n",
        "\n",
        "    # as we get a P(0,1) we need to convert to binary values\n",
        "    y_acc_train = (y_pred > 0.5).float()\n",
        "\n",
        "    # count correct predictions\n",
        "    correct_train += (y_acc_train == y_training).float().sum().item()\n",
        "\n",
        "    # count the amount of zeros and ones\n",
        "    zero_count_train += (y_acc_train == 0).float().sum().item()\n",
        "    one_count_train += (y_acc_train == 1).float().sum().item()\n",
        "\n",
        "    # count total predictions\n",
        "    total_train += y_training.size(0)\n",
        "\n",
        "    # accuracy training\n",
        "    accuracy_train = correct_train / total_train\n",
        "\n",
        "    # define the validation loss\n",
        "    val_loss = 0\n",
        "\n",
        "    # disable the gradient\n",
        "    with torch.no_grad():\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      zero_count = 0\n",
        "      one_count = 0\n",
        "      model.eval()\n",
        "\n",
        "      # loop that goes through the batches of data in the validation data\n",
        "      for batch1 in validation_loader:\n",
        "\n",
        "        # batch\n",
        "        x_val, y_val = batch1\n",
        "\n",
        "        # prepare input\n",
        "        x_val = x_val.view(x_val.size(0), -1)\n",
        "\n",
        "        # predict the y\n",
        "        y_pred = model(x_val).squeeze()\n",
        "\n",
        "        # as we get a P(0,1) we need to convert to binary values\n",
        "        y_acc = (y_pred > 0.5).float()\n",
        "\n",
        "        # count correct predictions\n",
        "        correct += (y_acc == y_val).float().sum().item()\n",
        "\n",
        "        # count the amount of zeros and ones\n",
        "        zero_count += (y_acc == 0).float().sum().item()\n",
        "        one_count += (y_acc == 1).float().sum().item()\n",
        "\n",
        "        # count total predictions\n",
        "        total += y_val.size(0)\n",
        "\n",
        "        # compute the loss\n",
        "        loss_val = loss_fn(y_pred, y_val)\n",
        "\n",
        "        # add the loss in each step\n",
        "        val_loss += loss_val.item()\n",
        "\n",
        "      # average the validation loss for the data loaded and add it to the returned data\n",
        "      val_loss /= len(validation_loader)\n",
        "      val_losses_per_batch.append(val_loss)\n",
        "\n",
        "      # compute accuracy and average loss\n",
        "      accuracy = correct / total\n",
        "      accuracy_per_batch.append(accuracy)\n",
        "\n",
        "      # add convergence when it learns\n",
        "      #if i >= 4 and (accuracy_per_batch[i] == accuracy_per_batch[i-1] == accuracy_per_batch[i-2] == accuracy_per_batch[i-3] == accuracy_per_batch[i-4] == 1.):\n",
        "      #  print(\"Convergence reached: Model trained\")\n",
        "      #  break\n",
        "\n",
        "\n",
        "      # print the values obtained if we want\n",
        "      if verbose and i % printing_rhythm == 0:\n",
        "        print(f\"Batch: {i}, Training Loss: {raw_loss:.6f}, Validation Loss: {val_loss:.6f}, TRAINING: One counter: {int(one_count_train)}, Zero counter: {int(zero_count_train)}, Accuracy: {accuracy_train} \\| VALIDATION: One counter: {int(one_count)}, Zero counter: {int(zero_count)}, Accuracy: {accuracy}\")\n",
        "\n",
        "  return model, train_losses_per_batch, val_losses_per_batch, accuracy_per_batch\n",
        "\n",
        "\n",
        "# TEST THE MODEL GENERATING THE DATASET INSIDE\n",
        "def testing(model, batch_size, dataset_parameters, fixed, conv, verbose=True, balance=False):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Function that tests the accuracy of the neural network\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # create the training data and load it\n",
        "  num_samples, block_size, m, n, tau, t0, rho = dataset_parameters\n",
        "  test_dataset = gol_dataset(num_samples, block_size, m, n, tau, t0, rho, balance, normalize=True)\n",
        "\n",
        "  # load the data and test everything\n",
        "  test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False) #skip it\n",
        "  loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  # first we have to turn into evaluation mode with this command\n",
        "  model.eval()\n",
        "\n",
        "  # for faster testing, disable gradient computation\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # monitorizing loss and correct predictions\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    zero_count = 0\n",
        "    one_count = 0\n",
        "    total_loss = 0\n",
        "    real_one = 0\n",
        "    real_zero = 0\n",
        "    i = 1\n",
        "\n",
        "    # loop that goes through the batches of data\n",
        "    for batch in test_loader:\n",
        "\n",
        "      # input data (x) and labels (y)\n",
        "      x, y_label = batch\n",
        "\n",
        "      # we need to flatten the input to match the dimensions when training\n",
        "      x = x.view(x.size(0), -1)\n",
        "\n",
        "      # output y_out obtained with our trained model\n",
        "      y_out = model(x).squeeze()\n",
        "\n",
        "      # as we get a P(0,1) we need to convert to binary values\n",
        "      y_pred = (y_out > 0.5).float()\n",
        "\n",
        "      # compute loss and count it\n",
        "      loss = loss_fn(y_out, y_label)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      # count correct predictions\n",
        "      correct += (y_pred == y_label).float().sum().item()\n",
        "\n",
        "      # count the amount of zeros and ones\n",
        "      zero_count += (y_pred == 0).float().sum().item()\n",
        "      one_count += (y_pred == 1).float().sum().item()\n",
        "      real_one += (y_label == 1).float().sum().item()\n",
        "      real_zero += (y_label == 0).float().sum().item()\n",
        "\n",
        "      # print(f\"Batch: {i}, Prediction: {y_pred}, Real: {y_label}\")\n",
        "\n",
        "      # count total predictions\n",
        "      total += y_label.size(0)\n",
        "\n",
        "      i+=1\n",
        "  # compute accuracy and average loss\n",
        "  accuracy = correct / total\n",
        "  avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "  # print the results\n",
        "  if verbose:\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Predicted one counter: {int(one_count)}, Predicted zero counter: {int(zero_count)}\")\n",
        "    print(f\"Real one counter: {int(real_one)}, Real zero counter: {int(real_zero)}\")\n",
        "\n",
        "  # return accuracy and loss for the dataset\n",
        "  return accuracy, avg_loss\n"
      ],
      "metadata": {
        "id": "CQqw77b0UM21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rolling dataset\n",
        "set_all_seeds(73)\n",
        "dataset = gol_dataset_rolling(1000, 5, 15, 15, 5, 0, 0.5, False)\n",
        "set_all_seeds(73)\n",
        "dataset_2 = gol_dataset(1000, 5, 15, 15, 5, 0, 0.5, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xojRL3FNfZ5C",
        "outputId": "feacacc5-4ae4-4f66-a0da-3a5c01431954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter : 2736, Dead count : 500, Alive count : 500\n",
            "Counter : 17924, Dead count : 500, Alive coun : 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "mFn49yE3YOf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the seed\n",
        "seed = 73\n",
        "set_all_seeds(seed)"
      ],
      "metadata": {
        "id": "mci1yeCEYOEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean & std\n",
        "for block_size in range(7, 12, 2):\n",
        "  num_samples = 15000\n",
        "  n = 25\n",
        "  m = 25\n",
        "  rho = 0.5\n",
        "  t0 = 0\n",
        "  tau = block_size\n",
        "  dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "  # obtain mean & std\n",
        "  mean, std = compute_mean_std(dataset_parameters)"
      ],
      "metadata": {
        "id": "rp0Vph_CaDCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block size = 1 (wrong normalization)"
      ],
      "metadata": {
        "id": "eaOEeYJ7QyNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fix n,m and iterate through different block_sizes\n",
        "n = 15\n",
        "m = 15\n",
        "block_size = 1\n",
        "print(\"_______________________________________________________________________\")\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 0\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [input_size//2, input_size//4]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_s0ikCjeMeH",
        "outputId": "9213273a-6123-43f2-e26c-fe448312d86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 1\n",
            "Model created with input_size: 225\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.729724, Validation Loss: 0.695159, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.5073\n",
            "Batch: 10, Training Loss: 0.736712, Validation Loss: 0.680801, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 15, Zero counter: 1009, Accuracy: 0.5009765625\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5000\n",
            "Batch: 20, Training Loss: 0.642274, Validation Loss: 0.671909, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.8125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5000\n",
            "Batch: 30, Training Loss: 0.549392, Validation Loss: 0.662360, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5000\n",
            "Batch: 40, Training Loss: 0.577945, Validation Loss: 0.631457, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 50] Accuracy on full training data: 0.4999\n",
            "Batch: 50, Training Loss: 0.564150, Validation Loss: 0.606445, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5883\n",
            "Batch: 60, Training Loss: 0.651831, Validation Loss: 0.622647, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.25 \\| VALIDATION: One counter: 288, Zero counter: 736, Accuracy: 0.615234375\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5064\n",
            "Batch: 70, Training Loss: 0.555533, Validation Loss: 0.608699, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5009765625\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5129\n",
            "Batch: 80, Training Loss: 0.583270, Validation Loss: 0.593235, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.8125 \\| VALIDATION: One counter: 64, Zero counter: 960, Accuracy: 0.525390625\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5344\n",
            "Batch: 90, Training Loss: 0.559294, Validation Loss: 0.632132, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.375 \\| VALIDATION: One counter: 61, Zero counter: 963, Accuracy: 0.5185546875\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5000\n",
            "Batch: 100, Training Loss: 0.527367, Validation Loss: 0.576159, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5000\n",
            "Batch: 110, Training Loss: 0.547754, Validation Loss: 0.582938, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5000\n",
            "Batch: 120, Training Loss: 0.548415, Validation Loss: 0.541862, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 130] Accuracy on full training data: 0.5000\n",
            "Batch: 130, Training Loss: 0.501427, Validation Loss: 0.571111, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 140] Accuracy on full training data: 0.5000\n",
            "Batch: 140, Training Loss: 0.518499, Validation Loss: 0.532306, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 150] Accuracy on full training data: 0.6435\n",
            "Batch: 150, Training Loss: 0.493018, Validation Loss: 0.492127, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.875 \\| VALIDATION: One counter: 266, Zero counter: 758, Accuracy: 0.62890625\n",
            "[Pre-batch 160] Accuracy on full training data: 0.7523\n",
            "Batch: 160, Training Loss: 0.476088, Validation Loss: 0.497331, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 414, Zero counter: 610, Accuracy: 0.728515625\n",
            "[Pre-batch 170] Accuracy on full training data: 0.7701\n",
            "Batch: 170, Training Loss: 0.516650, Validation Loss: 0.490552, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 456, Zero counter: 568, Accuracy: 0.7578125\n",
            "[Pre-batch 180] Accuracy on full training data: 0.8017\n",
            "Batch: 180, Training Loss: 0.485112, Validation Loss: 0.476129, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.9375 \\| VALIDATION: One counter: 571, Zero counter: 453, Accuracy: 0.8115234375\n",
            "[Pre-batch 190] Accuracy on full training data: 0.8164\n",
            "Batch: 190, Training Loss: 0.731872, Validation Loss: 0.445427, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.5625 \\| VALIDATION: One counter: 543, Zero counter: 481, Accuracy: 0.8251953125\n",
            "[Pre-batch 200] Accuracy on full training data: 0.7956\n",
            "Batch: 200, Training Loss: 0.438628, Validation Loss: 0.461266, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 492, Zero counter: 532, Accuracy: 0.779296875\n",
            "[Pre-batch 210] Accuracy on full training data: 0.7969\n",
            "Batch: 210, Training Loss: 0.397822, Validation Loss: 0.452053, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 500, Zero counter: 524, Accuracy: 0.78515625\n",
            "[Pre-batch 220] Accuracy on full training data: 0.8317\n",
            "Batch: 220, Training Loss: 0.535439, Validation Loss: 0.450451, TRAINING: One counter: 11, Zero counter: 5, Accuracy: 0.75 \\| VALIDATION: One counter: 560, Zero counter: 464, Accuracy: 0.83203125\n",
            "[Pre-batch 230] Accuracy on full training data: 0.8286\n",
            "Batch: 230, Training Loss: 0.397774, Validation Loss: 0.482547, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 650, Zero counter: 374, Accuracy: 0.830078125\n",
            "[Pre-batch 240] Accuracy on full training data: 0.8373\n",
            "Batch: 240, Training Loss: 0.332684, Validation Loss: 0.432276, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 618, Zero counter: 406, Accuracy: 0.830078125\n",
            "[Pre-batch 250] Accuracy on full training data: 0.8531\n",
            "Batch: 250, Training Loss: 0.472965, Validation Loss: 0.394723, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.75 \\| VALIDATION: One counter: 535, Zero counter: 489, Accuracy: 0.8330078125\n",
            "[Pre-batch 260] Accuracy on full training data: 0.8669\n",
            "Batch: 260, Training Loss: 0.289346, Validation Loss: 0.418495, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 599, Zero counter: 425, Accuracy: 0.8662109375\n",
            "[Pre-batch 270] Accuracy on full training data: 0.8237\n",
            "Batch: 270, Training Loss: 0.359824, Validation Loss: 0.375694, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 492, Zero counter: 532, Accuracy: 0.8203125\n",
            "[Pre-batch 280] Accuracy on full training data: 0.8356\n",
            "Batch: 280, Training Loss: 0.503299, Validation Loss: 0.380886, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 476, Zero counter: 548, Accuracy: 0.822265625\n",
            "[Pre-batch 290] Accuracy on full training data: 0.8176\n",
            "Batch: 290, Training Loss: 0.425735, Validation Loss: 0.391515, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 461, Zero counter: 563, Accuracy: 0.8037109375\n",
            "[Pre-batch 300] Accuracy on full training data: 0.8209\n",
            "Batch: 300, Training Loss: 0.489580, Validation Loss: 0.392004, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.6875 \\| VALIDATION: One counter: 508, Zero counter: 516, Accuracy: 0.8203125\n",
            "[Pre-batch 310] Accuracy on full training data: 0.8566\n",
            "Batch: 310, Training Loss: 0.286946, Validation Loss: 0.419953, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 653, Zero counter: 371, Accuracy: 0.8505859375\n",
            "[Pre-batch 320] Accuracy on full training data: 0.8714\n",
            "Batch: 320, Training Loss: 0.318287, Validation Loss: 0.391203, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.875 \\| VALIDATION: One counter: 586, Zero counter: 438, Accuracy: 0.876953125\n",
            "[Pre-batch 330] Accuracy on full training data: 0.8731\n",
            "Batch: 330, Training Loss: 0.350497, Validation Loss: 0.352005, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 548, Zero counter: 476, Accuracy: 0.87890625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.8553\n",
            "Batch: 340, Training Loss: 0.311855, Validation Loss: 0.350558, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 480, Zero counter: 544, Accuracy: 0.837890625\n",
            "[Pre-batch 350] Accuracy on full training data: 0.8880\n",
            "Batch: 350, Training Loss: 0.338810, Validation Loss: 0.345662, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 525, Zero counter: 499, Accuracy: 0.8759765625\n",
            "[Pre-batch 360] Accuracy on full training data: 0.8911\n",
            "Batch: 360, Training Loss: 0.485501, Validation Loss: 0.354312, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 569, Zero counter: 455, Accuracy: 0.8955078125\n",
            "[Pre-batch 370] Accuracy on full training data: 0.8491\n",
            "Batch: 370, Training Loss: 0.337362, Validation Loss: 0.412599, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.75 \\| VALIDATION: One counter: 670, Zero counter: 354, Accuracy: 0.837890625\n",
            "[Pre-batch 380] Accuracy on full training data: 0.8741\n",
            "Batch: 380, Training Loss: 0.415856, Validation Loss: 0.372171, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.875 \\| VALIDATION: One counter: 630, Zero counter: 394, Accuracy: 0.865234375\n",
            "[Pre-batch 390] Accuracy on full training data: 0.8582\n",
            "Batch: 390, Training Loss: 0.353690, Validation Loss: 0.378623, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 553, Zero counter: 471, Accuracy: 0.8408203125\n",
            "[Pre-batch 400] Accuracy on full training data: 0.8466\n",
            "Batch: 400, Training Loss: 0.458063, Validation Loss: 0.392944, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 489, Zero counter: 535, Accuracy: 0.8115234375\n",
            "[Pre-batch 410] Accuracy on full training data: 0.8629\n",
            "Batch: 410, Training Loss: 1.115506, Validation Loss: 0.380966, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.375 \\| VALIDATION: One counter: 510, Zero counter: 514, Accuracy: 0.830078125\n",
            "[Pre-batch 420] Accuracy on full training data: 0.8532\n",
            "Batch: 420, Training Loss: 0.408512, Validation Loss: 0.414776, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 640, Zero counter: 384, Accuracy: 0.85546875\n",
            "[Pre-batch 430] Accuracy on full training data: 0.8829\n",
            "Batch: 430, Training Loss: 0.325055, Validation Loss: 0.374413, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 582, Zero counter: 442, Accuracy: 0.87109375\n",
            "[Pre-batch 440] Accuracy on full training data: 0.8526\n",
            "Batch: 440, Training Loss: 0.373075, Validation Loss: 0.358762, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 492, Zero counter: 532, Accuracy: 0.84375\n",
            "[Pre-batch 450] Accuracy on full training data: 0.7184\n",
            "Batch: 450, Training Loss: 1.055099, Validation Loss: 0.517558, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.4375 \\| VALIDATION: One counter: 324, Zero counter: 700, Accuracy: 0.71484375\n",
            "[Pre-batch 460] Accuracy on full training data: 0.8918\n",
            "Batch: 460, Training Loss: 0.443634, Validation Loss: 0.338098, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.75 \\| VALIDATION: One counter: 587, Zero counter: 437, Accuracy: 0.8916015625\n",
            "[Pre-batch 470] Accuracy on full training data: 0.8986\n",
            "Batch: 470, Training Loss: 0.477064, Validation Loss: 0.334260, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.8125 \\| VALIDATION: One counter: 583, Zero counter: 441, Accuracy: 0.8896484375\n",
            "[Pre-batch 480] Accuracy on full training data: 0.8982\n",
            "Batch: 480, Training Loss: 0.330099, Validation Loss: 0.357227, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 609, Zero counter: 415, Accuracy: 0.8798828125\n",
            "[Pre-batch 490] Accuracy on full training data: 0.8986\n",
            "Batch: 490, Training Loss: 0.634313, Validation Loss: 0.375601, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.6875 \\| VALIDATION: One counter: 624, Zero counter: 400, Accuracy: 0.87890625\n",
            "[Pre-batch 500] Accuracy on full training data: 0.8853\n",
            "Batch: 500, Training Loss: 0.282708, Validation Loss: 0.370784, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 589, Zero counter: 435, Accuracy: 0.8779296875\n",
            "[Pre-batch 510] Accuracy on full training data: 0.7592\n",
            "Batch: 510, Training Loss: 0.299713, Validation Loss: 0.367362, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 392, Zero counter: 632, Accuracy: 0.7578125\n",
            "[Pre-batch 520] Accuracy on full training data: 0.8438\n",
            "Batch: 520, Training Loss: 0.303596, Validation Loss: 0.337764, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 461, Zero counter: 563, Accuracy: 0.8212890625\n",
            "[Pre-batch 530] Accuracy on full training data: 0.8858\n",
            "Batch: 530, Training Loss: 0.404518, Validation Loss: 0.321644, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 517, Zero counter: 507, Accuracy: 0.8759765625\n",
            "[Pre-batch 540] Accuracy on full training data: 0.9143\n",
            "Batch: 540, Training Loss: 0.316478, Validation Loss: 0.336883, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 596, Zero counter: 428, Accuracy: 0.912109375\n",
            "[Pre-batch 550] Accuracy on full training data: 0.8873\n",
            "Batch: 550, Training Loss: 0.364339, Validation Loss: 0.363890, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.8125 \\| VALIDATION: One counter: 619, Zero counter: 405, Accuracy: 0.8896484375\n",
            "[Pre-batch 560] Accuracy on full training data: 0.9022\n",
            "Batch: 560, Training Loss: 0.248378, Validation Loss: 0.328748, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 584, Zero counter: 440, Accuracy: 0.90234375\n",
            "[Pre-batch 570] Accuracy on full training data: 0.9061\n",
            "Batch: 570, Training Loss: 0.589035, Validation Loss: 0.322001, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.75 \\| VALIDATION: One counter: 588, Zero counter: 436, Accuracy: 0.904296875\n",
            "[Pre-batch 580] Accuracy on full training data: 0.8985\n",
            "Batch: 580, Training Loss: 0.172823, Validation Loss: 0.311318, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 546, Zero counter: 478, Accuracy: 0.884765625\n",
            "[Pre-batch 590] Accuracy on full training data: 0.8064\n",
            "Batch: 590, Training Loss: 0.311829, Validation Loss: 0.340278, TRAINING: One counter: 11, Zero counter: 5, Accuracy: 0.9375 \\| VALIDATION: One counter: 509, Zero counter: 515, Accuracy: 0.8447265625\n",
            "[Pre-batch 600] Accuracy on full training data: 0.8907\n",
            "Batch: 600, Training Loss: 0.374116, Validation Loss: 0.328590, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.875 \\| VALIDATION: One counter: 570, Zero counter: 454, Accuracy: 0.87890625\n",
            "[Pre-batch 610] Accuracy on full training data: 0.8812\n",
            "Batch: 610, Training Loss: 0.226404, Validation Loss: 0.346824, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 570, Zero counter: 454, Accuracy: 0.87109375\n",
            "[Pre-batch 620] Accuracy on full training data: 0.8652\n",
            "Batch: 620, Training Loss: 0.394031, Validation Loss: 0.339293, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.6875 \\| VALIDATION: One counter: 509, Zero counter: 515, Accuracy: 0.8525390625\n",
            "[Pre-batch 630] Accuracy on full training data: 0.7315\n",
            "Batch: 630, Training Loss: 0.276540, Validation Loss: 0.927534, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 324, Zero counter: 700, Accuracy: 0.734375\n",
            "[Pre-batch 640] Accuracy on full training data: 0.8084\n",
            "Batch: 640, Training Loss: 0.226075, Validation Loss: 0.336209, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 447, Zero counter: 577, Accuracy: 0.8115234375\n",
            "[Pre-batch 650] Accuracy on full training data: 0.8550\n",
            "Batch: 650, Training Loss: 0.216771, Validation Loss: 0.307654, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 508, Zero counter: 516, Accuracy: 0.857421875\n",
            "[Pre-batch 660] Accuracy on full training data: 0.9016\n",
            "Batch: 660, Training Loss: 0.307163, Validation Loss: 0.295528, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 560, Zero counter: 464, Accuracy: 0.904296875\n",
            "[Pre-batch 670] Accuracy on full training data: 0.8643\n",
            "Batch: 670, Training Loss: 0.111412, Validation Loss: 0.418631, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 666, Zero counter: 358, Accuracy: 0.849609375\n",
            "[Pre-batch 680] Accuracy on full training data: 0.9113\n",
            "Batch: 680, Training Loss: 0.330323, Validation Loss: 0.318766, TRAINING: One counter: 11, Zero counter: 5, Accuracy: 0.9375 \\| VALIDATION: One counter: 599, Zero counter: 425, Accuracy: 0.9091796875\n",
            "[Pre-batch 690] Accuracy on full training data: 0.9054\n",
            "Batch: 690, Training Loss: 0.268465, Validation Loss: 0.300272, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 537, Zero counter: 487, Accuracy: 0.8955078125\n",
            "[Pre-batch 700] Accuracy on full training data: 0.8880\n",
            "Batch: 700, Training Loss: 0.180458, Validation Loss: 0.301862, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 1.0 \\| VALIDATION: One counter: 547, Zero counter: 477, Accuracy: 0.9052734375\n",
            "[Pre-batch 710] Accuracy on full training data: 0.9077\n",
            "Batch: 710, Training Loss: 0.477976, Validation Loss: 0.296750, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 554, Zero counter: 470, Accuracy: 0.908203125\n",
            "[Pre-batch 720] Accuracy on full training data: 0.9158\n",
            "Batch: 720, Training Loss: 0.300589, Validation Loss: 0.302483, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 567, Zero counter: 457, Accuracy: 0.9130859375\n",
            "[Pre-batch 730] Accuracy on full training data: 0.9137\n",
            "Batch: 730, Training Loss: 0.620087, Validation Loss: 0.328201, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.625 \\| VALIDATION: One counter: 602, Zero counter: 422, Accuracy: 0.90625\n",
            "[Pre-batch 740] Accuracy on full training data: 0.8973\n",
            "Batch: 740, Training Loss: 0.267114, Validation Loss: 0.331399, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 546, Zero counter: 478, Accuracy: 0.88671875\n",
            "[Pre-batch 750] Accuracy on full training data: 0.9014\n",
            "Batch: 750, Training Loss: 0.577958, Validation Loss: 0.321995, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 535, Zero counter: 489, Accuracy: 0.8896484375\n",
            "[Pre-batch 760] Accuracy on full training data: 0.8899\n",
            "Batch: 760, Training Loss: 0.373599, Validation Loss: 0.303344, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 536, Zero counter: 488, Accuracy: 0.89453125\n",
            "[Pre-batch 770] Accuracy on full training data: 0.9086\n",
            "Batch: 770, Training Loss: 0.329479, Validation Loss: 0.312285, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 570, Zero counter: 454, Accuracy: 0.900390625\n",
            "[Pre-batch 780] Accuracy on full training data: 0.8992\n",
            "Batch: 780, Training Loss: 0.387201, Validation Loss: 0.338259, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 568, Zero counter: 456, Accuracy: 0.8828125\n",
            "[Pre-batch 790] Accuracy on full training data: 0.8972\n",
            "Batch: 790, Training Loss: 0.293830, Validation Loss: 0.343657, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 602, Zero counter: 422, Accuracy: 0.888671875\n",
            "[Pre-batch 800] Accuracy on full training data: 0.9144\n",
            "Batch: 800, Training Loss: 0.419363, Validation Loss: 0.324793, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 590, Zero counter: 434, Accuracy: 0.90234375\n",
            "[Pre-batch 810] Accuracy on full training data: 0.9114\n",
            "Batch: 810, Training Loss: 0.513272, Validation Loss: 0.308145, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 557, Zero counter: 467, Accuracy: 0.8974609375\n",
            "[Pre-batch 820] Accuracy on full training data: 0.8977\n",
            "Batch: 820, Training Loss: 0.532331, Validation Loss: 0.297179, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 564, Zero counter: 460, Accuracy: 0.90234375\n",
            "[Pre-batch 830] Accuracy on full training data: 0.8944\n",
            "Batch: 830, Training Loss: 0.319302, Validation Loss: 0.301833, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.875 \\| VALIDATION: One counter: 521, Zero counter: 503, Accuracy: 0.8837890625\n",
            "[Pre-batch 840] Accuracy on full training data: 0.8855\n",
            "Batch: 840, Training Loss: 0.424993, Validation Loss: 0.331493, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 513, Zero counter: 511, Accuracy: 0.8720703125\n",
            "[Pre-batch 850] Accuracy on full training data: 0.9006\n",
            "Batch: 850, Training Loss: 0.367158, Validation Loss: 0.295517, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 526, Zero counter: 498, Accuracy: 0.884765625\n",
            "[Pre-batch 860] Accuracy on full training data: 0.9127\n",
            "Batch: 860, Training Loss: 0.464387, Validation Loss: 0.295803, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.75 \\| VALIDATION: One counter: 583, Zero counter: 441, Accuracy: 0.9091796875\n",
            "[Pre-batch 870] Accuracy on full training data: 0.9031\n",
            "Batch: 870, Training Loss: 0.343605, Validation Loss: 0.330098, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 610, Zero counter: 414, Accuracy: 0.8984375\n",
            "[Pre-batch 880] Accuracy on full training data: 0.9227\n",
            "Batch: 880, Training Loss: 0.163408, Validation Loss: 0.289940, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 572, Zero counter: 452, Accuracy: 0.927734375\n",
            "[Pre-batch 890] Accuracy on full training data: 0.9264\n",
            "Batch: 890, Training Loss: 0.227340, Validation Loss: 0.301683, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 579, Zero counter: 445, Accuracy: 0.9287109375\n",
            "[Pre-batch 900] Accuracy on full training data: 0.9141\n",
            "Batch: 900, Training Loss: 0.184376, Validation Loss: 0.286850, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 565, Zero counter: 459, Accuracy: 0.9248046875\n",
            "[Pre-batch 910] Accuracy on full training data: 0.9237\n",
            "Batch: 910, Training Loss: 0.384184, Validation Loss: 0.285950, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 581, Zero counter: 443, Accuracy: 0.9169921875\n",
            "[Pre-batch 920] Accuracy on full training data: 0.9217\n",
            "Batch: 920, Training Loss: 0.183543, Validation Loss: 0.285112, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 568, Zero counter: 456, Accuracy: 0.921875\n",
            "[Pre-batch 930] Accuracy on full training data: 0.9260\n",
            "Batch: 930, Training Loss: 0.185793, Validation Loss: 0.299426, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 572, Zero counter: 452, Accuracy: 0.9296875\n",
            "[Pre-batch 940] Accuracy on full training data: 0.9279\n",
            "Batch: 940, Training Loss: 0.279077, Validation Loss: 0.280991, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 567, Zero counter: 457, Accuracy: 0.9208984375\n",
            "[Pre-batch 950] Accuracy on full training data: 0.9305\n",
            "Batch: 950, Training Loss: 0.497502, Validation Loss: 0.290027, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 571, Zero counter: 453, Accuracy: 0.9189453125\n",
            "[Pre-batch 960] Accuracy on full training data: 0.9273\n",
            "Batch: 960, Training Loss: 0.270154, Validation Loss: 0.294744, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 562, Zero counter: 462, Accuracy: 0.919921875\n",
            "[Pre-batch 970] Accuracy on full training data: 0.9317\n",
            "Batch: 970, Training Loss: 0.174037, Validation Loss: 0.277125, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 576, Zero counter: 448, Accuracy: 0.931640625\n",
            "[Pre-batch 980] Accuracy on full training data: 0.9034\n",
            "Batch: 980, Training Loss: 0.357521, Validation Loss: 0.335455, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.875 \\| VALIDATION: One counter: 612, Zero counter: 412, Accuracy: 0.90234375\n",
            "[Pre-batch 990] Accuracy on full training data: 0.8958\n",
            "Batch: 990, Training Loss: 0.741388, Validation Loss: 0.301873, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.625 \\| VALIDATION: One counter: 535, Zero counter: 489, Accuracy: 0.8935546875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#__________________________________________________________________________________________________________________________________________\n",
        "# IMBALANCED DATASET\n",
        "n = 15\n",
        "m = 15\n",
        "block_size = 1\n",
        "tau = block_size\n",
        "rho = 0.5\n",
        "correct = 0\n",
        "total = 0\n",
        "one = 0\n",
        "zero = 0\n",
        "ones = 0\n",
        "zeros = 0\n",
        "mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "mean = np.load(mean_path)\n",
        "std = np.load(std_path)\n",
        "mean = torch.tensor(mean, dtype=torch.float32)\n",
        "std = torch.tensor(std, dtype=torch.float32)\n",
        "batch_x = []\n",
        "batch_y_true = []\n",
        "batch_size = 16\n",
        "total_samples = 1789\n",
        "for iter in range(total_samples):\n",
        "    trained_model_test_1.eval()\n",
        "    with torch.no_grad():\n",
        "        grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "        x_single_sample = []\n",
        "        for _ in range(tau):\n",
        "            coarse_grid = block_average(grid, block_size)\n",
        "            x_single_sample.append(coarse_grid)\n",
        "            grid = next_step_fn(grid)\n",
        "        x_single_sample = np.array(x_single_sample)\n",
        "        coarse_grid_final = block_average(grid, block_size)\n",
        "        y_single_sample = coarse_grid_final[m//(2*block_size), m//(2*block_size)]\n",
        "        x_single_sample = torch.tensor(x_single_sample, dtype=torch.float32)\n",
        "        # normalize\n",
        "        x_single_sample = (x_single_sample - mean) / std\n",
        "        eps = 1e-6\n",
        "        std[std < eps] = 1.0\n",
        "        x_single_sample = x_single_sample.view(1, -1)\n",
        "        batch_x.append(x_single_sample)\n",
        "        batch_y_true.append(y_single_sample)\n",
        "        # process the batch when it's full or at the end of iterations\n",
        "        if len(batch_x) == batch_size or (iter == (1000 - 1) and len(batch_x) > 0):\n",
        "            x_batch_tensor = torch.cat(batch_x, dim=0)\n",
        "            y_true_batch_tensor = torch.tensor(batch_y_true, dtype=torch.float32)\n",
        "\n",
        "            y_pred_batch = trained_model_test(x_batch_tensor).squeeze()\n",
        "\n",
        "            # in case it is only a scalar\n",
        "            if y_pred_batch.dim() == 0:\n",
        "                y_pred_batch = y_pred_batch.unsqueeze(0)\n",
        "\n",
        "            # prediction batch\n",
        "            y_pred_batch = (y_pred_batch > 0.5).float()\n",
        "\n",
        "            # accuracies\n",
        "            for i in range(len(batch_x)):\n",
        "                y_pred = y_pred_batch[i]\n",
        "                y_true = y_true_batch_tensor[i]\n",
        "\n",
        "                if y_pred == 0:\n",
        "                    zero += 1\n",
        "                elif y_pred == 1:\n",
        "                    one += 1\n",
        "                if y_true == 0:\n",
        "                    zeros += 1\n",
        "                elif y_true == 1:\n",
        "                    ones += 1\n",
        "                correct += (y_pred == y_true).float().sum().item()\n",
        "                total += 1\n",
        "\n",
        "            # reset batch for the next iteration\n",
        "            batch_x = []\n",
        "            batch_y_true = []\n",
        "\n",
        "print(f\"Imbalanced dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")\n",
        "\n",
        "#__________________________________________________________________________________________________________________________________________\n",
        "# BALANCED AND RAW DATASET\n",
        "num_samples = 1000\n",
        "balanced_data = []\n",
        "balanced_labels = []\n",
        "raw_data = []\n",
        "raw_labels = []\n",
        "alive_count = 0\n",
        "dead_count = 0\n",
        "target = num_samples//2\n",
        "while True:\n",
        "  grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "  sequence = np.zeros((tau, m//block_size, m//block_size), dtype=np.float32)\n",
        "  for t in range(tau):\n",
        "    coarse_grid = block_average(grid, block_size)\n",
        "    sequence[t] = coarse_grid\n",
        "    grid = next_step_fn(grid)\n",
        "  coarse_grid = block_average(grid, block_size)\n",
        "  label = coarse_grid[m//(2*block_size), m//(2*block_size)]\n",
        "  raw_data.append(sequence)\n",
        "  raw_labels.append(label)\n",
        "  if int(label) == 1 and alive_count < target:\n",
        "    balanced_data.append(sequence)\n",
        "    balanced_labels.append(label)\n",
        "    alive_count += 1\n",
        "  elif int(label) == 0 and dead_count < target:\n",
        "    balanced_data.append(sequence)\n",
        "    balanced_labels.append(label)\n",
        "    dead_count += 1\n",
        "  if alive_count == target and dead_count == target:\n",
        "    break\n",
        "balanced_data = np.array(balanced_data)\n",
        "raw_data = np.array(raw_data)\n",
        "mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "mean = np.load(mean_path)\n",
        "std = np.load(std_path)\n",
        "eps = 1e-6\n",
        "std[std<eps] = 1\n",
        "balanced_data = (balanced_data - mean) / std\n",
        "raw_data = (raw_data - mean) / std\n",
        "balanced_data = torch.tensor(balanced_data, dtype=torch.float32)\n",
        "raw_data = torch.tensor(raw_data, dtype=torch.float32)\n",
        "balanced_labels = torch.tensor(balanced_labels, dtype=torch.float32)\n",
        "raw_labels = torch.tensor(raw_labels, dtype=torch.float32)\n",
        "print(f\"Amount of raw data: {len(raw_data)}\")\n",
        "print(f\"Amount of balanced data: {len(balanced_data)}\")\n",
        "z = 0\n",
        "o = 0\n",
        "for label in balanced_labels:\n",
        "  if label== 0:\n",
        "    z += 1\n",
        "  elif label == 1:\n",
        "    o += 1\n",
        "print(f\"Balanced dataset: 0s: {z}, 1s: {o}\")\n",
        "\n",
        "# predictions\n",
        "trained_model_test_1.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "  # balanced data\n",
        "  zero = 0\n",
        "  one = 0\n",
        "  zeros = 0\n",
        "  ones = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in range(len(balanced_data)):\n",
        "    x = balanced_data[i]\n",
        "    y_true = balanced_labels[i]\n",
        "    x = x.view(1, -1)\n",
        "    y_pred = trained_model_test(x).squeeze()\n",
        "    y_pred = (y_pred > 0.5).float()\n",
        "    correct += (y_pred == y_true).float().sum().item()\n",
        "    total += 1\n",
        "    if y_pred == 0:\n",
        "      zero += 1\n",
        "    elif y_pred == 1:\n",
        "      one += 1\n",
        "    if y_true == 0:\n",
        "      zeros += 1\n",
        "    elif y_true == 1:\n",
        "      ones += 1\n",
        "\n",
        "  print(f\"Balanced dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")\n",
        "\n",
        "  # raw data\n",
        "  zero = 0\n",
        "  one = 0\n",
        "  zeros = 0\n",
        "  ones = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in range(len(raw_data)):\n",
        "    x = raw_data[i]\n",
        "    y_true = raw_labels[i]\n",
        "    x = x.view(1, -1)\n",
        "    y_pred = trained_model_test(x).squeeze()\n",
        "    y_pred = (y_pred > 0.5).float()\n",
        "    correct += (y_pred == y_true).float().sum().item()\n",
        "    total += 1\n",
        "    if y_pred == 0:\n",
        "      zero += 1\n",
        "    elif y_pred == 1:\n",
        "      one += 1\n",
        "    if y_true == 0:\n",
        "      zeros += 1\n",
        "    elif y_true == 1:\n",
        "      ones += 1\n",
        "\n",
        "  print(f\"Raw dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jjeyzhAk2pE",
        "outputId": "14bf64ba-7c33-411c-eddd-c431afd7d1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalanced dataset: Accuracy: 0.8923766816143498, Predicted 0s: 1126, Predicted 1s: 658, Real 0s: 1302, Real 1s: 482\n",
            "Amount of raw data: 1792\n",
            "Amount of balanced data: 1000\n",
            "Balanced dataset: 0s: 500, 1s: 500\n",
            "Balanced dataset: Accuracy: 0.92, Predicted 0s: 448, Predicted 1s: 552, Real 0s: 500, Real 1s: 500\n",
            "Raw dataset: Accuracy: 0.8934151785714286, Predicted 0s: 1129, Predicted 1s: 663, Real 0s: 1292, Real 1s: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try using the testing function now\n",
        "testing(trained_model_test, batch_size=16, dataset_parameters=dataset_parameters, fixed=False, conv=False, verbose=True, balance=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS815KwZON0G",
        "outputId": "22dfaf49-14b9-40ec-cce0-d6fd89c97c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========DATASET=========\n",
            "Batch: 1, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.]), Real: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
            "Batch: 3, Prediction: tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]), Real: tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 4, Prediction: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.]), Real: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
            "Batch: 8, Prediction: tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
            "Batch: 9, Prediction: tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]), Real: tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
            "Batch: 10, Prediction: tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 11, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 13, Prediction: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
            "Batch: 14, Prediction: tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
            "Batch: 15, Prediction: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.]), Real: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 16, Prediction: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 17, Prediction: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
            "Batch: 18, Prediction: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.]), Real: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
            "Batch: 19, Prediction: tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 20, Prediction: tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.]), Real: tensor([1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
            "Batch: 21, Prediction: tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.]), Real: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
            "Batch: 22, Prediction: tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.]), Real: tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
            "Batch: 23, Prediction: tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]), Real: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
            "Batch: 24, Prediction: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
            "Batch: 25, Prediction: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.]), Real: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 26, Prediction: tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.]), Real: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 27, Prediction: tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
            "Batch: 28, Prediction: tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 29, Prediction: tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.]), Real: tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 30, Prediction: tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.]), Real: tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
            "Batch: 31, Prediction: tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.]), Real: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 32, Prediction: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.]), Real: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
            "Batch: 33, Prediction: tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.]), Real: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 34, Prediction: tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 35, Prediction: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
            "Batch: 36, Prediction: tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
            "Batch: 37, Prediction: tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]), Real: tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
            "Batch: 38, Prediction: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 39, Prediction: tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
            "Batch: 40, Prediction: tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 41, Prediction: tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
            "Batch: 42, Prediction: tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.]), Real: tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
            "Batch: 43, Prediction: tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
            "Batch: 44, Prediction: tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.]), Real: tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 45, Prediction: tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 46, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 47, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 48, Prediction: tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 49, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 50, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 51, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 52, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 53, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 54, Prediction: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 55, Prediction: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 56, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 57, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 58, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 59, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 60, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 61, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 62, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 63, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 64, Prediction: tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Test Accuracy: 0.8984\n",
            "Test Loss: 0.3229\n",
            "Predicted one counter: 584, Predicted zero counter: 440\n",
            "Real one counter: 512, Real zero counter: 512\n",
            "_________________________________________________________________________________________\n",
            "========SUBSET=========\n",
            "Batch: 1, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.]), Real: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
            "Batch: 3, Prediction: tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]), Real: tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 4, Prediction: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.]), Real: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
            "Batch: 8, Prediction: tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
            "Batch: 9, Prediction: tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]), Real: tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
            "Batch: 10, Prediction: tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 11, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 13, Prediction: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
            "Batch: 14, Prediction: tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
            "Test Accuracy: 0.9018\n",
            "Test Loss: 0.0000\n",
            "Predicted one counter: 81, Predicted zero counter: 143\n",
            "Real one counter: 69, Real zero counter: 155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9017857142857143, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block size = 1 (good normalization)"
      ],
      "metadata": {
        "id": "LNIFC6-kAIrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fix n,m and iterate through different block_sizes\n",
        "n = 15\n",
        "m = 15\n",
        "block_size = 1\n",
        "print(\"_______________________________________________________________________\")\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 0\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [input_size//2, input_size//4]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q412uGZL9sOG",
        "outputId": "5f605493-082f-4b8c-cc7e-b73d0ab98553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 1\n",
            "Model created with input_size: 225\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.770668, Validation Loss: 0.695594, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.5007\n",
            "Batch: 10, Training Loss: 0.784085, Validation Loss: 0.681388, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 2, Zero counter: 1022, Accuracy: 0.501953125\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5010\n",
            "Batch: 20, Training Loss: 0.659027, Validation Loss: 0.675190, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.6875 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5029296875\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5000\n",
            "Batch: 30, Training Loss: 0.639809, Validation Loss: 0.675599, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5000\n",
            "Batch: 40, Training Loss: 0.579209, Validation Loss: 0.645038, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5007\n",
            "Batch: 50, Training Loss: 0.646980, Validation Loss: 0.643240, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5340\n",
            "Batch: 60, Training Loss: 0.680821, Validation Loss: 0.626672, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.4375 \\| VALIDATION: One counter: 91, Zero counter: 933, Accuracy: 0.5458984375\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5336\n",
            "Batch: 70, Training Loss: 0.520990, Validation Loss: 0.622298, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 90, Zero counter: 934, Accuracy: 0.52734375\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5004\n",
            "Batch: 80, Training Loss: 0.627517, Validation Loss: 0.587730, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5006\n",
            "Batch: 90, Training Loss: 0.659880, Validation Loss: 0.560922, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5000\n",
            "Batch: 100, Training Loss: 0.527701, Validation Loss: 0.576627, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5000\n",
            "Batch: 110, Training Loss: 0.544147, Validation Loss: 0.572924, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5000\n",
            "Batch: 120, Training Loss: 0.556197, Validation Loss: 0.548000, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.50390625\n",
            "[Pre-batch 130] Accuracy on full training data: 0.6869\n",
            "Batch: 130, Training Loss: 0.579406, Validation Loss: 0.536438, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.625 \\| VALIDATION: One counter: 366, Zero counter: 658, Accuracy: 0.6953125\n",
            "[Pre-batch 140] Accuracy on full training data: 0.7811\n",
            "Batch: 140, Training Loss: 0.506174, Validation Loss: 0.511208, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.6875 \\| VALIDATION: One counter: 548, Zero counter: 476, Accuracy: 0.783203125\n",
            "[Pre-batch 150] Accuracy on full training data: 0.7808\n",
            "Batch: 150, Training Loss: 0.523169, Validation Loss: 0.505688, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.75 \\| VALIDATION: One counter: 467, Zero counter: 557, Accuracy: 0.7744140625\n",
            "[Pre-batch 160] Accuracy on full training data: 0.7522\n",
            "Batch: 160, Training Loss: 0.689517, Validation Loss: 0.479718, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 425, Zero counter: 599, Accuracy: 0.7431640625\n",
            "[Pre-batch 170] Accuracy on full training data: 0.7369\n",
            "Batch: 170, Training Loss: 0.421182, Validation Loss: 0.487507, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 414, Zero counter: 610, Accuracy: 0.736328125\n",
            "[Pre-batch 180] Accuracy on full training data: 0.7956\n",
            "Batch: 180, Training Loss: 0.488247, Validation Loss: 0.469253, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.8125 \\| VALIDATION: One counter: 572, Zero counter: 452, Accuracy: 0.798828125\n",
            "[Pre-batch 190] Accuracy on full training data: 0.7961\n",
            "Batch: 190, Training Loss: 0.554936, Validation Loss: 0.463867, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.6875 \\| VALIDATION: One counter: 551, Zero counter: 473, Accuracy: 0.8017578125\n",
            "[Pre-batch 200] Accuracy on full training data: 0.8023\n",
            "Batch: 200, Training Loss: 0.457185, Validation Loss: 0.464793, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 548, Zero counter: 476, Accuracy: 0.794921875\n",
            "[Pre-batch 210] Accuracy on full training data: 0.8390\n",
            "Batch: 210, Training Loss: 0.438436, Validation Loss: 0.435027, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 572, Zero counter: 452, Accuracy: 0.833984375\n",
            "[Pre-batch 220] Accuracy on full training data: 0.8273\n",
            "Batch: 220, Training Loss: 0.454046, Validation Loss: 0.423836, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 542, Zero counter: 482, Accuracy: 0.814453125\n",
            "[Pre-batch 230] Accuracy on full training data: 0.8197\n",
            "Batch: 230, Training Loss: 0.443344, Validation Loss: 0.428618, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.8125 \\| VALIDATION: One counter: 570, Zero counter: 454, Accuracy: 0.818359375\n",
            "[Pre-batch 240] Accuracy on full training data: 0.8175\n",
            "Batch: 240, Training Loss: 0.553449, Validation Loss: 0.436877, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 532, Zero counter: 492, Accuracy: 0.806640625\n",
            "[Pre-batch 250] Accuracy on full training data: 0.7956\n",
            "Batch: 250, Training Loss: 0.435266, Validation Loss: 0.437181, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.9375 \\| VALIDATION: One counter: 458, Zero counter: 566, Accuracy: 0.771484375\n",
            "[Pre-batch 260] Accuracy on full training data: 0.8266\n",
            "Batch: 260, Training Loss: 0.298199, Validation Loss: 0.405126, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 1.0 \\| VALIDATION: One counter: 510, Zero counter: 514, Accuracy: 0.8359375\n",
            "[Pre-batch 270] Accuracy on full training data: 0.8439\n",
            "Batch: 270, Training Loss: 0.320064, Validation Loss: 0.422871, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 600, Zero counter: 424, Accuracy: 0.83203125\n",
            "[Pre-batch 280] Accuracy on full training data: 0.8006\n",
            "Batch: 280, Training Loss: 0.375025, Validation Loss: 0.413213, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 521, Zero counter: 503, Accuracy: 0.7978515625\n",
            "[Pre-batch 290] Accuracy on full training data: 0.8592\n",
            "Batch: 290, Training Loss: 0.444921, Validation Loss: 0.387682, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 590, Zero counter: 434, Accuracy: 0.849609375\n",
            "[Pre-batch 300] Accuracy on full training data: 0.8373\n",
            "Batch: 300, Training Loss: 0.462993, Validation Loss: 0.427647, TRAINING: One counter: 11, Zero counter: 5, Accuracy: 0.8125 \\| VALIDATION: One counter: 627, Zero counter: 397, Accuracy: 0.8251953125\n",
            "[Pre-batch 310] Accuracy on full training data: 0.8317\n",
            "Batch: 310, Training Loss: 0.732802, Validation Loss: 0.423129, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.625 \\| VALIDATION: One counter: 534, Zero counter: 490, Accuracy: 0.8046875\n",
            "[Pre-batch 320] Accuracy on full training data: 0.7878\n",
            "Batch: 320, Training Loss: 0.535796, Validation Loss: 0.444525, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.625 \\| VALIDATION: One counter: 479, Zero counter: 545, Accuracy: 0.7744140625\n",
            "[Pre-batch 330] Accuracy on full training data: 0.8170\n",
            "Batch: 330, Training Loss: 0.471344, Validation Loss: 0.434400, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 545, Zero counter: 479, Accuracy: 0.8115234375\n",
            "[Pre-batch 340] Accuracy on full training data: 0.8503\n",
            "Batch: 340, Training Loss: 0.307069, Validation Loss: 0.466646, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 661, Zero counter: 363, Accuracy: 0.8349609375\n",
            "[Pre-batch 350] Accuracy on full training data: 0.7874\n",
            "Batch: 350, Training Loss: 0.459316, Validation Loss: 0.419582, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 521, Zero counter: 503, Accuracy: 0.7919921875\n",
            "[Pre-batch 360] Accuracy on full training data: 0.7967\n",
            "Batch: 360, Training Loss: 0.524368, Validation Loss: 0.403625, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.625 \\| VALIDATION: One counter: 452, Zero counter: 572, Accuracy: 0.783203125\n",
            "[Pre-batch 370] Accuracy on full training data: 0.8562\n",
            "Batch: 370, Training Loss: 0.447200, Validation Loss: 0.354451, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 516, Zero counter: 508, Accuracy: 0.8515625\n",
            "[Pre-batch 380] Accuracy on full training data: 0.8788\n",
            "Batch: 380, Training Loss: 0.461676, Validation Loss: 0.332007, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 529, Zero counter: 495, Accuracy: 0.8681640625\n",
            "[Pre-batch 390] Accuracy on full training data: 0.8877\n",
            "Batch: 390, Training Loss: 0.233747, Validation Loss: 0.339590, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 555, Zero counter: 469, Accuracy: 0.8759765625\n",
            "[Pre-batch 400] Accuracy on full training data: 0.8962\n",
            "Batch: 400, Training Loss: 0.402134, Validation Loss: 0.356225, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 584, Zero counter: 440, Accuracy: 0.880859375\n",
            "[Pre-batch 410] Accuracy on full training data: 0.8998\n",
            "Batch: 410, Training Loss: 0.322655, Validation Loss: 0.341568, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 553, Zero counter: 471, Accuracy: 0.8779296875\n",
            "[Pre-batch 420] Accuracy on full training data: 0.9069\n",
            "Batch: 420, Training Loss: 0.381249, Validation Loss: 0.340614, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 580, Zero counter: 444, Accuracy: 0.90234375\n",
            "[Pre-batch 430] Accuracy on full training data: 0.9009\n",
            "Batch: 430, Training Loss: 0.245608, Validation Loss: 0.319200, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 594, Zero counter: 430, Accuracy: 0.900390625\n",
            "[Pre-batch 440] Accuracy on full training data: 0.8795\n",
            "Batch: 440, Training Loss: 0.264583, Validation Loss: 0.318897, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.9375 \\| VALIDATION: One counter: 555, Zero counter: 469, Accuracy: 0.8798828125\n",
            "[Pre-batch 450] Accuracy on full training data: 0.8561\n",
            "Batch: 450, Training Loss: 0.313914, Validation Loss: 0.341647, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 536, Zero counter: 488, Accuracy: 0.8515625\n",
            "[Pre-batch 460] Accuracy on full training data: 0.8808\n",
            "Batch: 460, Training Loss: 0.477399, Validation Loss: 0.340300, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.8125 \\| VALIDATION: One counter: 606, Zero counter: 418, Accuracy: 0.873046875\n",
            "[Pre-batch 470] Accuracy on full training data: 0.8661\n",
            "Batch: 470, Training Loss: 0.396293, Validation Loss: 0.359476, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 543, Zero counter: 481, Accuracy: 0.8427734375\n",
            "[Pre-batch 480] Accuracy on full training data: 0.8621\n",
            "Batch: 480, Training Loss: 0.432716, Validation Loss: 0.354480, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 551, Zero counter: 473, Accuracy: 0.8486328125\n",
            "[Pre-batch 490] Accuracy on full training data: 0.8690\n",
            "Batch: 490, Training Loss: 0.487505, Validation Loss: 0.356432, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 593, Zero counter: 431, Accuracy: 0.8662109375\n",
            "[Pre-batch 500] Accuracy on full training data: 0.8726\n",
            "Batch: 500, Training Loss: 0.449280, Validation Loss: 0.347084, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.8125 \\| VALIDATION: One counter: 565, Zero counter: 459, Accuracy: 0.8662109375\n",
            "[Pre-batch 510] Accuracy on full training data: 0.8773\n",
            "Batch: 510, Training Loss: 0.427468, Validation Loss: 0.329563, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 555, Zero counter: 469, Accuracy: 0.8720703125\n",
            "[Pre-batch 520] Accuracy on full training data: 0.8830\n",
            "Batch: 520, Training Loss: 0.291148, Validation Loss: 0.323389, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 557, Zero counter: 467, Accuracy: 0.8779296875\n",
            "[Pre-batch 530] Accuracy on full training data: 0.8978\n",
            "Batch: 530, Training Loss: 0.251880, Validation Loss: 0.319984, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 586, Zero counter: 438, Accuracy: 0.896484375\n",
            "[Pre-batch 540] Accuracy on full training data: 0.8898\n",
            "Batch: 540, Training Loss: 0.174338, Validation Loss: 0.348816, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 607, Zero counter: 417, Accuracy: 0.8876953125\n",
            "[Pre-batch 550] Accuracy on full training data: 0.8888\n",
            "Batch: 550, Training Loss: 0.382508, Validation Loss: 0.352207, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 611, Zero counter: 413, Accuracy: 0.8837890625\n",
            "[Pre-batch 560] Accuracy on full training data: 0.9016\n",
            "Batch: 560, Training Loss: 0.233697, Validation Loss: 0.329564, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 550, Zero counter: 474, Accuracy: 0.890625\n",
            "[Pre-batch 570] Accuracy on full training data: 0.8935\n",
            "Batch: 570, Training Loss: 0.290395, Validation Loss: 0.324444, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 526, Zero counter: 498, Accuracy: 0.873046875\n",
            "[Pre-batch 580] Accuracy on full training data: 0.9159\n",
            "Batch: 580, Training Loss: 0.283386, Validation Loss: 0.327601, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 575, Zero counter: 449, Accuracy: 0.9033203125\n",
            "[Pre-batch 590] Accuracy on full training data: 0.9137\n",
            "Batch: 590, Training Loss: 0.351218, Validation Loss: 0.329985, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 591, Zero counter: 433, Accuracy: 0.9052734375\n",
            "[Pre-batch 600] Accuracy on full training data: 0.9039\n",
            "Batch: 600, Training Loss: 0.349719, Validation Loss: 0.335654, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 611, Zero counter: 413, Accuracy: 0.8935546875\n",
            "[Pre-batch 610] Accuracy on full training data: 0.7667\n",
            "Batch: 610, Training Loss: 0.239308, Validation Loss: 0.400170, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 405, Zero counter: 619, Accuracy: 0.7783203125\n",
            "[Pre-batch 620] Accuracy on full training data: 0.8939\n",
            "Batch: 620, Training Loss: 0.430084, Validation Loss: 0.293869, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 543, Zero counter: 481, Accuracy: 0.8837890625\n",
            "[Pre-batch 630] Accuracy on full training data: 0.8844\n",
            "Batch: 630, Training Loss: 0.390233, Validation Loss: 0.305214, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 547, Zero counter: 477, Accuracy: 0.8818359375\n",
            "[Pre-batch 640] Accuracy on full training data: 0.9171\n",
            "Batch: 640, Training Loss: 0.329446, Validation Loss: 0.274177, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 566, Zero counter: 458, Accuracy: 0.90625\n",
            "[Pre-batch 650] Accuracy on full training data: 0.8966\n",
            "Batch: 650, Training Loss: 0.423455, Validation Loss: 0.335390, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.75 \\| VALIDATION: One counter: 623, Zero counter: 401, Accuracy: 0.8916015625\n",
            "[Pre-batch 660] Accuracy on full training data: 0.9214\n",
            "Batch: 660, Training Loss: 0.158047, Validation Loss: 0.283272, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 584, Zero counter: 440, Accuracy: 0.916015625\n",
            "[Pre-batch 670] Accuracy on full training data: 0.9161\n",
            "Batch: 670, Training Loss: 0.394344, Validation Loss: 0.302834, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 584, Zero counter: 440, Accuracy: 0.908203125\n",
            "[Pre-batch 680] Accuracy on full training data: 0.9067\n",
            "Batch: 680, Training Loss: 0.425001, Validation Loss: 0.331003, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 589, Zero counter: 435, Accuracy: 0.8916015625\n",
            "[Pre-batch 690] Accuracy on full training data: 0.8780\n",
            "Batch: 690, Training Loss: 0.436802, Validation Loss: 0.325312, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 513, Zero counter: 511, Accuracy: 0.8525390625\n",
            "[Pre-batch 700] Accuracy on full training data: 0.8977\n",
            "Batch: 700, Training Loss: 0.287109, Validation Loss: 0.318762, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 560, Zero counter: 464, Accuracy: 0.888671875\n",
            "[Pre-batch 710] Accuracy on full training data: 0.9130\n",
            "Batch: 710, Training Loss: 0.390380, Validation Loss: 0.297396, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 557, Zero counter: 467, Accuracy: 0.9033203125\n",
            "[Pre-batch 720] Accuracy on full training data: 0.9281\n",
            "Batch: 720, Training Loss: 0.222471, Validation Loss: 0.292535, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 589, Zero counter: 435, Accuracy: 0.9208984375\n",
            "[Pre-batch 730] Accuracy on full training data: 0.9279\n",
            "Batch: 730, Training Loss: 0.481819, Validation Loss: 0.284934, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.75 \\| VALIDATION: One counter: 583, Zero counter: 441, Accuracy: 0.9150390625\n",
            "[Pre-batch 740] Accuracy on full training data: 0.9214\n",
            "Batch: 740, Training Loss: 0.302085, Validation Loss: 0.302054, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 587, Zero counter: 437, Accuracy: 0.9169921875\n",
            "[Pre-batch 750] Accuracy on full training data: 0.9070\n",
            "Batch: 750, Training Loss: 0.219229, Validation Loss: 0.303000, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.9375 \\| VALIDATION: One counter: 557, Zero counter: 467, Accuracy: 0.9013671875\n",
            "[Pre-batch 760] Accuracy on full training data: 0.9188\n",
            "Batch: 760, Training Loss: 0.280088, Validation Loss: 0.307705, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 584, Zero counter: 440, Accuracy: 0.912109375\n",
            "[Pre-batch 770] Accuracy on full training data: 0.9198\n",
            "Batch: 770, Training Loss: 0.337934, Validation Loss: 0.327919, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 592, Zero counter: 432, Accuracy: 0.90625\n",
            "[Pre-batch 780] Accuracy on full training data: 0.8118\n",
            "Batch: 780, Training Loss: 0.390742, Validation Loss: 0.389350, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 415, Zero counter: 609, Accuracy: 0.7685546875\n",
            "[Pre-batch 790] Accuracy on full training data: 0.8617\n",
            "Batch: 790, Training Loss: 0.338154, Validation Loss: 0.331412, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 492, Zero counter: 532, Accuracy: 0.83984375\n",
            "[Pre-batch 800] Accuracy on full training data: 0.8858\n",
            "Batch: 800, Training Loss: 0.246731, Validation Loss: 0.298653, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 545, Zero counter: 479, Accuracy: 0.8818359375\n",
            "[Pre-batch 810] Accuracy on full training data: 0.8758\n",
            "Batch: 810, Training Loss: 0.250225, Validation Loss: 0.384316, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 1.0 \\| VALIDATION: One counter: 665, Zero counter: 359, Accuracy: 0.8486328125\n",
            "[Pre-batch 820] Accuracy on full training data: 0.8724\n",
            "Batch: 820, Training Loss: 0.259829, Validation Loss: 0.311289, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 1.0 \\| VALIDATION: One counter: 542, Zero counter: 482, Accuracy: 0.8671875\n",
            "[Pre-batch 830] Accuracy on full training data: 0.8911\n",
            "Batch: 830, Training Loss: 0.439745, Validation Loss: 0.307065, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 531, Zero counter: 493, Accuracy: 0.8701171875\n",
            "[Pre-batch 840] Accuracy on full training data: 0.9028\n",
            "Batch: 840, Training Loss: 0.224385, Validation Loss: 0.297167, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.9375 \\| VALIDATION: One counter: 561, Zero counter: 463, Accuracy: 0.9033203125\n",
            "[Pre-batch 850] Accuracy on full training data: 0.9177\n",
            "Batch: 850, Training Loss: 0.314963, Validation Loss: 0.305014, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 575, Zero counter: 449, Accuracy: 0.9033203125\n",
            "[Pre-batch 860] Accuracy on full training data: 0.9180\n",
            "Batch: 860, Training Loss: 0.313140, Validation Loss: 0.319673, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 589, Zero counter: 435, Accuracy: 0.9111328125\n",
            "[Pre-batch 870] Accuracy on full training data: 0.9022\n",
            "Batch: 870, Training Loss: 0.323849, Validation Loss: 0.310786, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 557, Zero counter: 467, Accuracy: 0.8974609375\n",
            "[Pre-batch 880] Accuracy on full training data: 0.9090\n",
            "Batch: 880, Training Loss: 0.277457, Validation Loss: 0.302283, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.9375 \\| VALIDATION: One counter: 564, Zero counter: 460, Accuracy: 0.908203125\n",
            "[Pre-batch 890] Accuracy on full training data: 0.8877\n",
            "Batch: 890, Training Loss: 0.212854, Validation Loss: 0.308465, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.9375 \\| VALIDATION: One counter: 526, Zero counter: 498, Accuracy: 0.875\n",
            "[Pre-batch 900] Accuracy on full training data: 0.9140\n",
            "Batch: 900, Training Loss: 0.374285, Validation Loss: 0.303695, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 578, Zero counter: 446, Accuracy: 0.90625\n",
            "[Pre-batch 910] Accuracy on full training data: 0.9117\n",
            "Batch: 910, Training Loss: 0.261214, Validation Loss: 0.318101, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 591, Zero counter: 433, Accuracy: 0.9091796875\n",
            "[Pre-batch 920] Accuracy on full training data: 0.9213\n",
            "Batch: 920, Training Loss: 0.145355, Validation Loss: 0.307401, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 580, Zero counter: 444, Accuracy: 0.916015625\n",
            "[Pre-batch 930] Accuracy on full training data: 0.9272\n",
            "Batch: 930, Training Loss: 0.347846, Validation Loss: 0.297644, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 577, Zero counter: 447, Accuracy: 0.9130859375\n",
            "[Pre-batch 940] Accuracy on full training data: 0.9207\n",
            "Batch: 940, Training Loss: 0.542275, Validation Loss: 0.295450, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 567, Zero counter: 457, Accuracy: 0.9150390625\n",
            "[Pre-batch 950] Accuracy on full training data: 0.9284\n",
            "Batch: 950, Training Loss: 0.488455, Validation Loss: 0.282718, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 581, Zero counter: 443, Accuracy: 0.9150390625\n",
            "[Pre-batch 960] Accuracy on full training data: 0.9158\n",
            "Batch: 960, Training Loss: 0.163416, Validation Loss: 0.303575, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 598, Zero counter: 426, Accuracy: 0.91015625\n",
            "[Pre-batch 970] Accuracy on full training data: 0.9147\n",
            "Batch: 970, Training Loss: 0.352934, Validation Loss: 0.302060, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 593, Zero counter: 431, Accuracy: 0.9052734375\n",
            "[Pre-batch 980] Accuracy on full training data: 0.9155\n",
            "Batch: 980, Training Loss: 0.750810, Validation Loss: 0.302247, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.5625 \\| VALIDATION: One counter: 581, Zero counter: 443, Accuracy: 0.9072265625\n",
            "[Pre-batch 990] Accuracy on full training data: 0.9154\n",
            "Batch: 990, Training Loss: 0.301822, Validation Loss: 0.293901, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 576, Zero counter: 448, Accuracy: 0.908203125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fix n,m and iterate through different block_sizes\n",
        "\n",
        "# n = 25\n",
        "# m = 25\n",
        "n = 25\n",
        "m = 25\n",
        "block_size = 1\n",
        "print(\"_______________________________________________________________________\")\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 0\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [input_size//2, input_size//4]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IQ7Tl41QsBz",
        "outputId": "2b1deeb7-da0a-4720-9ca8-91d90f9d1ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 1\n",
            "Model created with input_size: 625\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.740449, Validation Loss: 0.694549, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.5000\n",
            "Batch: 10, Training Loss: 0.641907, Validation Loss: 0.691980, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5002\n",
            "Batch: 20, Training Loss: 0.797815, Validation Loss: 0.688128, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5051\n",
            "Batch: 30, Training Loss: 0.621975, Validation Loss: 0.680247, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 7, Zero counter: 1017, Accuracy: 0.5009765625\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5224\n",
            "Batch: 40, Training Loss: 0.696011, Validation Loss: 0.662750, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.4375 \\| VALIDATION: One counter: 41, Zero counter: 983, Accuracy: 0.5126953125\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5471\n",
            "Batch: 50, Training Loss: 0.481362, Validation Loss: 0.654082, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.5625 \\| VALIDATION: One counter: 104, Zero counter: 920, Accuracy: 0.5390625\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5781\n",
            "Batch: 60, Training Loss: 0.748255, Validation Loss: 0.643904, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.625 \\| VALIDATION: One counter: 183, Zero counter: 841, Accuracy: 0.5693359375\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5819\n",
            "Batch: 70, Training Loss: 0.579160, Validation Loss: 0.637226, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.625 \\| VALIDATION: One counter: 217, Zero counter: 807, Accuracy: 0.5791015625\n",
            "[Pre-batch 80] Accuracy on full training data: 0.6306\n",
            "Batch: 80, Training Loss: 0.640020, Validation Loss: 0.596821, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.6875 \\| VALIDATION: One counter: 295, Zero counter: 729, Accuracy: 0.6181640625\n",
            "[Pre-batch 90] Accuracy on full training data: 0.6082\n",
            "Batch: 90, Training Loss: 0.744754, Validation Loss: 0.590706, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 246, Zero counter: 778, Accuracy: 0.587890625\n",
            "[Pre-batch 100] Accuracy on full training data: 0.6256\n",
            "Batch: 100, Training Loss: 0.427071, Validation Loss: 0.594882, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 344, Zero counter: 680, Accuracy: 0.62890625\n",
            "[Pre-batch 110] Accuracy on full training data: 0.6251\n",
            "Batch: 110, Training Loss: 0.553161, Validation Loss: 0.594691, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 358, Zero counter: 666, Accuracy: 0.6328125\n",
            "[Pre-batch 120] Accuracy on full training data: 0.6468\n",
            "Batch: 120, Training Loss: 0.598634, Validation Loss: 0.590288, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 403, Zero counter: 621, Accuracy: 0.6494140625\n",
            "[Pre-batch 130] Accuracy on full training data: 0.6663\n",
            "Batch: 130, Training Loss: 0.693245, Validation Loss: 0.575000, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.5625 \\| VALIDATION: One counter: 419, Zero counter: 605, Accuracy: 0.6748046875\n",
            "[Pre-batch 140] Accuracy on full training data: 0.5409\n",
            "Batch: 140, Training Loss: 0.445066, Validation Loss: 0.651963, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 99, Zero counter: 925, Accuracy: 0.5634765625\n",
            "[Pre-batch 150] Accuracy on full training data: 0.6563\n",
            "Batch: 150, Training Loss: 0.444044, Validation Loss: 0.527905, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.6875 \\| VALIDATION: One counter: 346, Zero counter: 678, Accuracy: 0.6796875\n",
            "[Pre-batch 160] Accuracy on full training data: 0.6442\n",
            "Batch: 160, Training Loss: 0.723733, Validation Loss: 0.545071, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.5 \\| VALIDATION: One counter: 320, Zero counter: 704, Accuracy: 0.640625\n",
            "[Pre-batch 170] Accuracy on full training data: 0.6919\n",
            "Batch: 170, Training Loss: 0.359609, Validation Loss: 0.549672, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.75 \\| VALIDATION: One counter: 442, Zero counter: 582, Accuracy: 0.685546875\n",
            "[Pre-batch 180] Accuracy on full training data: 0.6853\n",
            "Batch: 180, Training Loss: 0.567740, Validation Loss: 0.541276, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 354, Zero counter: 670, Accuracy: 0.69140625\n",
            "[Pre-batch 190] Accuracy on full training data: 0.6077\n",
            "Batch: 190, Training Loss: 0.485039, Validation Loss: 0.559348, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 237, Zero counter: 787, Accuracy: 0.6240234375\n",
            "[Pre-batch 200] Accuracy on full training data: 0.6406\n",
            "Batch: 200, Training Loss: 0.602663, Validation Loss: 0.505651, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 281, Zero counter: 743, Accuracy: 0.6552734375\n",
            "[Pre-batch 210] Accuracy on full training data: 0.6367\n",
            "Batch: 210, Training Loss: 0.351398, Validation Loss: 0.539400, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 297, Zero counter: 727, Accuracy: 0.6416015625\n",
            "[Pre-batch 220] Accuracy on full training data: 0.6951\n",
            "Batch: 220, Training Loss: 0.455947, Validation Loss: 0.520248, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.8125 \\| VALIDATION: One counter: 415, Zero counter: 609, Accuracy: 0.7041015625\n",
            "[Pre-batch 230] Accuracy on full training data: 0.7066\n",
            "Batch: 230, Training Loss: 0.497503, Validation Loss: 0.573429, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 474, Zero counter: 550, Accuracy: 0.705078125\n",
            "[Pre-batch 240] Accuracy on full training data: 0.6504\n",
            "Batch: 240, Training Loss: 0.463913, Validation Loss: 0.503332, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.875 \\| VALIDATION: One counter: 320, Zero counter: 704, Accuracy: 0.65625\n",
            "[Pre-batch 250] Accuracy on full training data: 0.7102\n",
            "Batch: 250, Training Loss: 0.564892, Validation Loss: 0.498581, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 462, Zero counter: 562, Accuracy: 0.720703125\n",
            "[Pre-batch 260] Accuracy on full training data: 0.6903\n",
            "Batch: 260, Training Loss: 0.463690, Validation Loss: 0.549727, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.8125 \\| VALIDATION: One counter: 446, Zero counter: 578, Accuracy: 0.705078125\n",
            "[Pre-batch 270] Accuracy on full training data: 0.6152\n",
            "Batch: 270, Training Loss: 0.478887, Validation Loss: 0.512244, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 172, Zero counter: 852, Accuracy: 0.59375\n",
            "[Pre-batch 280] Accuracy on full training data: 0.6437\n",
            "Batch: 280, Training Loss: 0.634485, Validation Loss: 0.526629, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 318, Zero counter: 706, Accuracy: 0.66015625\n",
            "[Pre-batch 290] Accuracy on full training data: 0.6777\n",
            "Batch: 290, Training Loss: 0.535988, Validation Loss: 0.512745, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 315, Zero counter: 709, Accuracy: 0.6552734375\n",
            "[Pre-batch 300] Accuracy on full training data: 0.5974\n",
            "Batch: 300, Training Loss: 0.475138, Validation Loss: 0.544675, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 219, Zero counter: 805, Accuracy: 0.6279296875\n",
            "[Pre-batch 310] Accuracy on full training data: 0.6497\n",
            "Batch: 310, Training Loss: 0.619629, Validation Loss: 0.524517, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 321, Zero counter: 703, Accuracy: 0.6865234375\n",
            "[Pre-batch 320] Accuracy on full training data: 0.6442\n",
            "Batch: 320, Training Loss: 0.500504, Validation Loss: 0.522080, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 270, Zero counter: 754, Accuracy: 0.64453125\n",
            "[Pre-batch 330] Accuracy on full training data: 0.6282\n",
            "Batch: 330, Training Loss: 0.656678, Validation Loss: 0.494706, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 251, Zero counter: 773, Accuracy: 0.6416015625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.6351\n",
            "Batch: 340, Training Loss: 0.551176, Validation Loss: 0.539869, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5 \\| VALIDATION: One counter: 276, Zero counter: 748, Accuracy: 0.6484375\n",
            "[Pre-batch 350] Accuracy on full training data: 0.6164\n",
            "Batch: 350, Training Loss: 0.484171, Validation Loss: 0.504550, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 205, Zero counter: 819, Accuracy: 0.6337890625\n",
            "[Pre-batch 360] Accuracy on full training data: 0.5962\n",
            "Batch: 360, Training Loss: 0.578171, Validation Loss: 0.548084, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 172, Zero counter: 852, Accuracy: 0.583984375\n",
            "[Pre-batch 370] Accuracy on full training data: 0.6554\n",
            "Batch: 370, Training Loss: 0.550219, Validation Loss: 0.500296, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 281, Zero counter: 743, Accuracy: 0.6630859375\n",
            "[Pre-batch 380] Accuracy on full training data: 0.6475\n",
            "Batch: 380, Training Loss: 0.436942, Validation Loss: 0.493703, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 354, Zero counter: 670, Accuracy: 0.681640625\n",
            "[Pre-batch 390] Accuracy on full training data: 0.6391\n",
            "Batch: 390, Training Loss: 0.537957, Validation Loss: 0.511295, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 255, Zero counter: 769, Accuracy: 0.6591796875\n",
            "[Pre-batch 400] Accuracy on full training data: 0.6355\n",
            "Batch: 400, Training Loss: 0.500073, Validation Loss: 0.567868, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.6875 \\| VALIDATION: One counter: 378, Zero counter: 646, Accuracy: 0.650390625\n",
            "[Pre-batch 410] Accuracy on full training data: 0.5634\n",
            "Batch: 410, Training Loss: 0.438903, Validation Loss: 0.557839, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 109, Zero counter: 915, Accuracy: 0.5478515625\n",
            "[Pre-batch 420] Accuracy on full training data: 0.6169\n",
            "Batch: 420, Training Loss: 0.584019, Validation Loss: 0.521333, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 249, Zero counter: 775, Accuracy: 0.6337890625\n",
            "[Pre-batch 430] Accuracy on full training data: 0.6388\n",
            "Batch: 430, Training Loss: 0.476602, Validation Loss: 0.502610, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 287, Zero counter: 737, Accuracy: 0.6513671875\n",
            "[Pre-batch 440] Accuracy on full training data: 0.6168\n",
            "Batch: 440, Training Loss: 0.666186, Validation Loss: 0.495413, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.5 \\| VALIDATION: One counter: 197, Zero counter: 827, Accuracy: 0.6298828125\n",
            "[Pre-batch 450] Accuracy on full training data: 0.6702\n",
            "Batch: 450, Training Loss: 0.485025, Validation Loss: 0.559385, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 420, Zero counter: 604, Accuracy: 0.66796875\n",
            "[Pre-batch 460] Accuracy on full training data: 0.6641\n",
            "Batch: 460, Training Loss: 0.720817, Validation Loss: 0.518907, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 321, Zero counter: 703, Accuracy: 0.6513671875\n",
            "[Pre-batch 470] Accuracy on full training data: 0.6517\n",
            "Batch: 470, Training Loss: 0.538513, Validation Loss: 0.516516, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 330, Zero counter: 694, Accuracy: 0.66796875\n",
            "[Pre-batch 480] Accuracy on full training data: 0.6671\n",
            "Batch: 480, Training Loss: 0.379465, Validation Loss: 0.516811, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.75 \\| VALIDATION: One counter: 370, Zero counter: 654, Accuracy: 0.666015625\n",
            "[Pre-batch 490] Accuracy on full training data: 0.5980\n",
            "Batch: 490, Training Loss: 0.418833, Validation Loss: 0.507464, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 146, Zero counter: 878, Accuracy: 0.587890625\n",
            "[Pre-batch 500] Accuracy on full training data: 0.6312\n",
            "Batch: 500, Training Loss: 0.553906, Validation Loss: 0.515158, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 228, Zero counter: 796, Accuracy: 0.603515625\n",
            "[Pre-batch 510] Accuracy on full training data: 0.6866\n",
            "Batch: 510, Training Loss: 0.545692, Validation Loss: 0.493023, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 353, Zero counter: 671, Accuracy: 0.6962890625\n",
            "[Pre-batch 520] Accuracy on full training data: 0.6844\n",
            "Batch: 520, Training Loss: 0.548503, Validation Loss: 0.518213, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 359, Zero counter: 665, Accuracy: 0.6865234375\n",
            "[Pre-batch 530] Accuracy on full training data: 0.6581\n",
            "Batch: 530, Training Loss: 0.466582, Validation Loss: 0.486743, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 306, Zero counter: 718, Accuracy: 0.6796875\n",
            "[Pre-batch 540] Accuracy on full training data: 0.5990\n",
            "Batch: 540, Training Loss: 0.586745, Validation Loss: 0.527092, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.875 \\| VALIDATION: One counter: 205, Zero counter: 819, Accuracy: 0.6044921875\n",
            "[Pre-batch 550] Accuracy on full training data: 0.5899\n",
            "Batch: 550, Training Loss: 0.668465, Validation Loss: 0.516723, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 148, Zero counter: 876, Accuracy: 0.572265625\n",
            "[Pre-batch 560] Accuracy on full training data: 0.5478\n",
            "Batch: 560, Training Loss: 0.488717, Validation Loss: 0.510773, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 99, Zero counter: 925, Accuracy: 0.5615234375\n",
            "[Pre-batch 570] Accuracy on full training data: 0.6122\n",
            "Batch: 570, Training Loss: 0.570077, Validation Loss: 0.508854, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 232, Zero counter: 792, Accuracy: 0.623046875\n",
            "[Pre-batch 580] Accuracy on full training data: 0.5836\n",
            "Batch: 580, Training Loss: 0.548517, Validation Loss: 0.499207, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 174, Zero counter: 850, Accuracy: 0.578125\n",
            "[Pre-batch 590] Accuracy on full training data: 0.6329\n",
            "Batch: 590, Training Loss: 0.491636, Validation Loss: 0.506271, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 210, Zero counter: 814, Accuracy: 0.6328125\n",
            "[Pre-batch 600] Accuracy on full training data: 0.6228\n",
            "Batch: 600, Training Loss: 0.462186, Validation Loss: 0.506050, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.75 \\| VALIDATION: One counter: 228, Zero counter: 796, Accuracy: 0.634765625\n",
            "[Pre-batch 610] Accuracy on full training data: 0.6143\n",
            "Batch: 610, Training Loss: 0.477328, Validation Loss: 0.516364, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 182, Zero counter: 842, Accuracy: 0.609375\n",
            "[Pre-batch 620] Accuracy on full training data: 0.6395\n",
            "Batch: 620, Training Loss: 0.433800, Validation Loss: 0.497719, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 238, Zero counter: 786, Accuracy: 0.638671875\n",
            "[Pre-batch 630] Accuracy on full training data: 0.6701\n",
            "Batch: 630, Training Loss: 0.480255, Validation Loss: 0.509266, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.75 \\| VALIDATION: One counter: 294, Zero counter: 730, Accuracy: 0.65625\n",
            "[Pre-batch 640] Accuracy on full training data: 0.5576\n",
            "Batch: 640, Training Loss: 0.471192, Validation Loss: 0.509179, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.8125 \\| VALIDATION: One counter: 92, Zero counter: 932, Accuracy: 0.548828125\n",
            "[Pre-batch 650] Accuracy on full training data: 0.6679\n",
            "Batch: 650, Training Loss: 0.470935, Validation Loss: 0.493450, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 316, Zero counter: 708, Accuracy: 0.689453125\n",
            "[Pre-batch 660] Accuracy on full training data: 0.6948\n",
            "Batch: 660, Training Loss: 0.553384, Validation Loss: 0.464016, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 337, Zero counter: 687, Accuracy: 0.7041015625\n",
            "[Pre-batch 670] Accuracy on full training data: 0.6363\n",
            "Batch: 670, Training Loss: 0.359599, Validation Loss: 0.518194, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 275, Zero counter: 749, Accuracy: 0.6728515625\n",
            "[Pre-batch 680] Accuracy on full training data: 0.7183\n",
            "Batch: 680, Training Loss: 0.424508, Validation Loss: 0.487539, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 414, Zero counter: 610, Accuracy: 0.759765625\n",
            "[Pre-batch 690] Accuracy on full training data: 0.7278\n",
            "Batch: 690, Training Loss: 0.521355, Validation Loss: 0.457893, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.9375 \\| VALIDATION: One counter: 392, Zero counter: 632, Accuracy: 0.72265625\n",
            "[Pre-batch 700] Accuracy on full training data: 0.6645\n",
            "Batch: 700, Training Loss: 0.450941, Validation Loss: 0.467414, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.875 \\| VALIDATION: One counter: 292, Zero counter: 732, Accuracy: 0.6796875\n",
            "[Pre-batch 710] Accuracy on full training data: 0.6976\n",
            "Batch: 710, Training Loss: 0.396618, Validation Loss: 0.475139, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.75 \\| VALIDATION: One counter: 323, Zero counter: 701, Accuracy: 0.7080078125\n",
            "[Pre-batch 720] Accuracy on full training data: 0.6496\n",
            "Batch: 720, Training Loss: 0.417692, Validation Loss: 0.488324, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 210, Zero counter: 814, Accuracy: 0.6484375\n",
            "[Pre-batch 730] Accuracy on full training data: 0.7929\n",
            "Batch: 730, Training Loss: 0.491542, Validation Loss: 0.453588, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 481, Zero counter: 543, Accuracy: 0.7861328125\n",
            "[Pre-batch 740] Accuracy on full training data: 0.7546\n",
            "Batch: 740, Training Loss: 0.532238, Validation Loss: 0.458725, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.8125 \\| VALIDATION: One counter: 414, Zero counter: 610, Accuracy: 0.76953125\n",
            "[Pre-batch 750] Accuracy on full training data: 0.6388\n",
            "Batch: 750, Training Loss: 0.483389, Validation Loss: 0.476609, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.6875 \\| VALIDATION: One counter: 224, Zero counter: 800, Accuracy: 0.646484375\n",
            "[Pre-batch 760] Accuracy on full training data: 0.7248\n",
            "Batch: 760, Training Loss: 0.443057, Validation Loss: 0.472393, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.625 \\| VALIDATION: One counter: 388, Zero counter: 636, Accuracy: 0.74609375\n",
            "[Pre-batch 770] Accuracy on full training data: 0.7620\n",
            "Batch: 770, Training Loss: 0.411324, Validation Loss: 0.444589, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 451, Zero counter: 573, Accuracy: 0.7802734375\n",
            "[Pre-batch 780] Accuracy on full training data: 0.7942\n",
            "Batch: 780, Training Loss: 0.495725, Validation Loss: 0.445220, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.8125 \\| VALIDATION: One counter: 466, Zero counter: 558, Accuracy: 0.802734375\n",
            "[Pre-batch 790] Accuracy on full training data: 0.7228\n",
            "Batch: 790, Training Loss: 0.450682, Validation Loss: 0.478042, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 335, Zero counter: 689, Accuracy: 0.7099609375\n",
            "[Pre-batch 800] Accuracy on full training data: 0.7843\n",
            "Batch: 800, Training Loss: 0.398806, Validation Loss: 0.466909, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 453, Zero counter: 571, Accuracy: 0.7998046875\n",
            "[Pre-batch 810] Accuracy on full training data: 0.7558\n",
            "Batch: 810, Training Loss: 0.463005, Validation Loss: 0.443523, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.75 \\| VALIDATION: One counter: 387, Zero counter: 637, Accuracy: 0.7646484375\n",
            "[Pre-batch 820] Accuracy on full training data: 0.7837\n",
            "Batch: 820, Training Loss: 0.592233, Validation Loss: 0.442329, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.6875 \\| VALIDATION: One counter: 450, Zero counter: 574, Accuracy: 0.8125\n",
            "[Pre-batch 830] Accuracy on full training data: 0.8189\n",
            "Batch: 830, Training Loss: 0.460876, Validation Loss: 0.436811, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 450, Zero counter: 574, Accuracy: 0.806640625\n",
            "[Pre-batch 840] Accuracy on full training data: 0.8245\n",
            "Batch: 840, Training Loss: 0.406188, Validation Loss: 0.449467, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.875 \\| VALIDATION: One counter: 481, Zero counter: 543, Accuracy: 0.8232421875\n",
            "[Pre-batch 850] Accuracy on full training data: 0.7181\n",
            "Batch: 850, Training Loss: 0.504521, Validation Loss: 0.463538, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.75 \\| VALIDATION: One counter: 362, Zero counter: 662, Accuracy: 0.73046875\n",
            "[Pre-batch 860] Accuracy on full training data: 0.8171\n",
            "Batch: 860, Training Loss: 0.533707, Validation Loss: 0.475074, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 519, Zero counter: 505, Accuracy: 0.8271484375\n",
            "[Pre-batch 870] Accuracy on full training data: 0.8115\n",
            "Batch: 870, Training Loss: 0.454654, Validation Loss: 0.470811, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.9375 \\| VALIDATION: One counter: 506, Zero counter: 518, Accuracy: 0.818359375\n",
            "[Pre-batch 880] Accuracy on full training data: 0.8271\n",
            "Batch: 880, Training Loss: 0.671444, Validation Loss: 0.453394, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.375 \\| VALIDATION: One counter: 487, Zero counter: 537, Accuracy: 0.8173828125\n",
            "[Pre-batch 890] Accuracy on full training data: 0.8309\n",
            "Batch: 890, Training Loss: 0.413162, Validation Loss: 0.440501, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.75 \\| VALIDATION: One counter: 462, Zero counter: 562, Accuracy: 0.80859375\n",
            "[Pre-batch 900] Accuracy on full training data: 0.8293\n",
            "Batch: 900, Training Loss: 0.672298, Validation Loss: 0.441050, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.5 \\| VALIDATION: One counter: 453, Zero counter: 571, Accuracy: 0.8076171875\n",
            "[Pre-batch 910] Accuracy on full training data: 0.8434\n",
            "Batch: 910, Training Loss: 0.460775, Validation Loss: 0.456719, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 510, Zero counter: 514, Accuracy: 0.84375\n",
            "[Pre-batch 920] Accuracy on full training data: 0.8448\n",
            "Batch: 920, Training Loss: 0.463523, Validation Loss: 0.472167, TRAINING: One counter: 6, Zero counter: 10, Accuracy: 0.9375 \\| VALIDATION: One counter: 520, Zero counter: 504, Accuracy: 0.841796875\n",
            "[Pre-batch 930] Accuracy on full training data: 0.8571\n",
            "Batch: 930, Training Loss: 0.337970, Validation Loss: 0.470224, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 1.0 \\| VALIDATION: One counter: 538, Zero counter: 486, Accuracy: 0.857421875\n",
            "[Pre-batch 940] Accuracy on full training data: 0.8390\n",
            "Batch: 940, Training Loss: 0.491246, Validation Loss: 0.455198, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.8125 \\| VALIDATION: One counter: 507, Zero counter: 517, Accuracy: 0.8427734375\n",
            "[Pre-batch 950] Accuracy on full training data: 0.8504\n",
            "Batch: 950, Training Loss: 0.430030, Validation Loss: 0.432132, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.6875 \\| VALIDATION: One counter: 474, Zero counter: 550, Accuracy: 0.828125\n",
            "[Pre-batch 960] Accuracy on full training data: 0.8279\n",
            "Batch: 960, Training Loss: 0.348952, Validation Loss: 0.442035, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.9375 \\| VALIDATION: One counter: 446, Zero counter: 578, Accuracy: 0.814453125\n",
            "[Pre-batch 970] Accuracy on full training data: 0.8454\n",
            "Batch: 970, Training Loss: 0.421918, Validation Loss: 0.459302, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.8125 \\| VALIDATION: One counter: 487, Zero counter: 537, Accuracy: 0.8369140625\n",
            "[Pre-batch 980] Accuracy on full training data: 0.8557\n",
            "Batch: 980, Training Loss: 0.483427, Validation Loss: 0.453029, TRAINING: One counter: 8, Zero counter: 8, Accuracy: 0.875 \\| VALIDATION: One counter: 519, Zero counter: 505, Accuracy: 0.8662109375\n",
            "[Pre-batch 990] Accuracy on full training data: 0.8772\n",
            "Batch: 990, Training Loss: 0.437052, Validation Loss: 0.450591, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.875 \\| VALIDATION: One counter: 540, Zero counter: 484, Accuracy: 0.890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_1.pth\")"
      ],
      "metadata": {
        "id": "oxorOrfZhAz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the saved model\n",
        "input_size = 225\n",
        "hidden_size = [input_size//2, input_size//4]\n",
        "output_size = 1\n",
        "trained_model_test_1 = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "trained_model_test_1.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/trained_model_test_1.pth\"))\n",
        "print(trained_model_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2n27YqAhBTA",
        "outputId": "dc26c756-cdc4-4da7-8672-a1a4119abf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=225, out_features=112, bias=True)\n",
            "    (1): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0, inplace=False)\n",
            "    (4): Linear(in_features=112, out_features=56, bias=True)\n",
            "    (5): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0, inplace=False)\n",
            "    (8): Linear(in_features=56, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#__________________________________________________________________________________________________________________________________________\n",
        "# IMBALANCED DATASET\n",
        "n = 15\n",
        "m = 15\n",
        "block_size = 1\n",
        "tau = block_size\n",
        "rho = 0.5\n",
        "correct = 0\n",
        "total = 0\n",
        "one = 0\n",
        "zero = 0\n",
        "ones = 0\n",
        "zeros = 0\n",
        "mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "mean = np.load(mean_path)\n",
        "std = np.load(std_path)\n",
        "mean = torch.tensor(mean, dtype=torch.float32)\n",
        "std = torch.tensor(std, dtype=torch.float32)\n",
        "batch_x = []\n",
        "batch_y_true = []\n",
        "batch_size = 16\n",
        "total_samples = 1789\n",
        "for iter in range(total_samples):\n",
        "    trained_model_test_1.eval()\n",
        "    with torch.no_grad():\n",
        "        grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "        x_single_sample = []\n",
        "        for _ in range(tau):\n",
        "            coarse_grid = block_average(grid, block_size)\n",
        "            x_single_sample.append(coarse_grid)\n",
        "            grid = next_step_fn(grid)\n",
        "        x_single_sample = np.array(x_single_sample)\n",
        "        coarse_grid_final = block_average(grid, block_size)\n",
        "        y_single_sample = coarse_grid_final[m//(2*block_size), m//(2*block_size)]\n",
        "        x_single_sample = torch.tensor(x_single_sample, dtype=torch.float32)\n",
        "        # normalize\n",
        "        x_single_sample = (x_single_sample - mean) / std\n",
        "        eps = 1e-6\n",
        "        std[std < eps] = 1.0\n",
        "        x_single_sample = x_single_sample.view(1, -1)\n",
        "        batch_x.append(x_single_sample)\n",
        "        batch_y_true.append(y_single_sample)\n",
        "        # process the batch when it's full or at the end of iterations\n",
        "        if len(batch_x) == batch_size or (iter == (1000 - 1) and len(batch_x) > 0):\n",
        "            x_batch_tensor = torch.cat(batch_x, dim=0)\n",
        "            y_true_batch_tensor = torch.tensor(batch_y_true, dtype=torch.float32)\n",
        "\n",
        "            y_pred_batch = trained_model_test(x_batch_tensor).squeeze()\n",
        "\n",
        "            # in case it is only a scalar\n",
        "            if y_pred_batch.dim() == 0:\n",
        "                y_pred_batch = y_pred_batch.unsqueeze(0)\n",
        "\n",
        "            # prediction batch\n",
        "            y_pred_batch = (y_pred_batch > 0.5).float()\n",
        "\n",
        "            # accuracies\n",
        "            for i in range(len(batch_x)):\n",
        "                y_pred = y_pred_batch[i]\n",
        "                y_true = y_true_batch_tensor[i]\n",
        "\n",
        "                if y_pred == 0:\n",
        "                    zero += 1\n",
        "                elif y_pred == 1:\n",
        "                    one += 1\n",
        "                if y_true == 0:\n",
        "                    zeros += 1\n",
        "                elif y_true == 1:\n",
        "                    ones += 1\n",
        "                correct += (y_pred == y_true).float().sum().item()\n",
        "                total += 1\n",
        "\n",
        "            # reset batch for the next iteration\n",
        "            batch_x = []\n",
        "            batch_y_true = []\n",
        "\n",
        "print(f\"Imbalanced dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")\n",
        "\n",
        "#__________________________________________________________________________________________________________________________________________\n",
        "# BALANCED AND RAW DATASET\n",
        "num_samples = 1000\n",
        "balanced_data = []\n",
        "balanced_labels = []\n",
        "raw_data = []\n",
        "raw_labels = []\n",
        "alive_count = 0\n",
        "dead_count = 0\n",
        "target = num_samples//2\n",
        "while True:\n",
        "  grid = np.random.choice([0,1],(n,n),p=[1 - rho, rho])\n",
        "  sequence = np.zeros((tau, m//block_size, m//block_size), dtype=np.float32)\n",
        "  for t in range(tau):\n",
        "    coarse_grid = block_average(grid, block_size)\n",
        "    sequence[t] = coarse_grid\n",
        "    grid = next_step_fn(grid)\n",
        "  coarse_grid = block_average(grid, block_size)\n",
        "  label = coarse_grid[m//(2*block_size), m//(2*block_size)]\n",
        "  raw_data.append(sequence)\n",
        "  raw_labels.append(label)\n",
        "  if int(label) == 1 and alive_count < target:\n",
        "    balanced_data.append(sequence)\n",
        "    balanced_labels.append(label)\n",
        "    alive_count += 1\n",
        "  elif int(label) == 0 and dead_count < target:\n",
        "    balanced_data.append(sequence)\n",
        "    balanced_labels.append(label)\n",
        "    dead_count += 1\n",
        "  if alive_count == target and dead_count == target:\n",
        "    break\n",
        "balanced_data = np.array(balanced_data)\n",
        "raw_data = np.array(raw_data)\n",
        "mean_path = f\"/content/drive/My Drive/Colab Notebooks/mean_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "std_path = f\"/content/drive/My Drive/Colab Notebooks/std_{block_size}_{m}_{n}_{tau}_{rho}.npy\"\n",
        "mean = np.load(mean_path)\n",
        "std = np.load(std_path)\n",
        "eps = 1e-6\n",
        "std[std<eps] = 1\n",
        "balanced_data = (balanced_data - mean) / std\n",
        "raw_data = (raw_data - mean) / std\n",
        "balanced_data = torch.tensor(balanced_data, dtype=torch.float32)\n",
        "raw_data = torch.tensor(raw_data, dtype=torch.float32)\n",
        "balanced_labels = torch.tensor(balanced_labels, dtype=torch.float32)\n",
        "raw_labels = torch.tensor(raw_labels, dtype=torch.float32)\n",
        "print(f\"Amount of raw data: {len(raw_data)}\")\n",
        "print(f\"Amount of balanced data: {len(balanced_data)}\")\n",
        "z = 0\n",
        "o = 0\n",
        "for label in balanced_labels:\n",
        "  if label== 0:\n",
        "    z += 1\n",
        "  elif label == 1:\n",
        "    o += 1\n",
        "print(f\"Balanced dataset: 0s: {z}, 1s: {o}\")\n",
        "\n",
        "# predictions\n",
        "trained_model_test_1.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "  # balanced data\n",
        "  zero = 0\n",
        "  one = 0\n",
        "  zeros = 0\n",
        "  ones = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in range(len(balanced_data)):\n",
        "    x = balanced_data[i]\n",
        "    y_true = balanced_labels[i]\n",
        "    x = x.view(1, -1)\n",
        "    y_pred = trained_model_test(x).squeeze()\n",
        "    y_pred = (y_pred > 0.5).float()\n",
        "    correct += (y_pred == y_true).float().sum().item()\n",
        "    total += 1\n",
        "    if y_pred == 0:\n",
        "      zero += 1\n",
        "    elif y_pred == 1:\n",
        "      one += 1\n",
        "    if y_true == 0:\n",
        "      zeros += 1\n",
        "    elif y_true == 1:\n",
        "      ones += 1\n",
        "\n",
        "  print(f\"Balanced dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")\n",
        "\n",
        "  # raw data\n",
        "  zero = 0\n",
        "  one = 0\n",
        "  zeros = 0\n",
        "  ones = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i in range(len(raw_data)):\n",
        "    x = raw_data[i]\n",
        "    y_true = raw_labels[i]\n",
        "    x = x.view(1, -1)\n",
        "    y_pred = trained_model_test(x).squeeze()\n",
        "    y_pred = (y_pred > 0.5).float()\n",
        "    correct += (y_pred == y_true).float().sum().item()\n",
        "    total += 1\n",
        "    if y_pred == 0:\n",
        "      zero += 1\n",
        "    elif y_pred == 1:\n",
        "      one += 1\n",
        "    if y_true == 0:\n",
        "      zeros += 1\n",
        "    elif y_true == 1:\n",
        "      ones += 1\n",
        "\n",
        "  print(f\"Raw dataset: Accuracy: {correct/total}, Predicted 0s: {zero}, Predicted 1s: {one}, Real 0s: {zeros}, Real 1s: {ones}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm_RQB1pBG7P",
        "outputId": "314f3222-1904-448e-f2a9-3b70581dbe6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalanced dataset: Accuracy: 0.8727578475336323, Predicted 0s: 1025, Predicted 1s: 759, Real 0s: 1242, Real 1s: 542\n",
            "Amount of raw data: 1840\n",
            "Amount of balanced data: 1000\n",
            "Balanced dataset: 0s: 500, 1s: 500\n",
            "Balanced dataset: Accuracy: 0.928, Predicted 0s: 446, Predicted 1s: 554, Real 0s: 500, Real 1s: 500\n",
            "Raw dataset: Accuracy: 0.8847826086956522, Predicted 0s: 1146, Predicted 1s: 694, Real 0s: 1340, Real 1s: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try using the testing function now\n",
        "testing(trained_model_test_1, batch_size=16, dataset_parameters=dataset_parameters, fixed=False, conv=False, verbose=True, balance=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusnuHByBOuf",
        "outputId": "78bdab4d-b16b-4d46-ba27-5d2fe9a375d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========DATASET=========\n",
            "Batch: 1, Prediction: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]), Real: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]), Real: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
            "Batch: 3, Prediction: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 4, Prediction: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]), Real: tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
            "Batch: 8, Prediction: tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 9, Prediction: tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.]), Real: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 10, Prediction: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.]), Real: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
            "Batch: 11, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.]), Real: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
            "Batch: 13, Prediction: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.]), Real: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
            "Batch: 14, Prediction: tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 15, Prediction: tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.]), Real: tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 16, Prediction: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 17, Prediction: tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 18, Prediction: tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.]), Real: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
            "Batch: 19, Prediction: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.]), Real: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
            "Batch: 20, Prediction: tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 21, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 22, Prediction: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.]), Real: tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
            "Batch: 23, Prediction: tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.]), Real: tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
            "Batch: 24, Prediction: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.]), Real: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
            "Batch: 25, Prediction: tensor([1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]), Real: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 26, Prediction: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.]), Real: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
            "Batch: 27, Prediction: tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
            "Batch: 28, Prediction: tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 29, Prediction: tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), Real: tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 30, Prediction: tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 31, Prediction: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 32, Prediction: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 33, Prediction: tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 34, Prediction: tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 35, Prediction: tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.]), Real: tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 36, Prediction: tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
            "Batch: 37, Prediction: tensor([1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.]), Real: tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
            "Batch: 38, Prediction: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.]), Real: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
            "Batch: 39, Prediction: tensor([1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.]), Real: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
            "Batch: 40, Prediction: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.]), Real: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
            "Batch: 41, Prediction: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.]), Real: tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
            "Batch: 42, Prediction: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.]), Real: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
            "Batch: 43, Prediction: tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 44, Prediction: tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 45, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 46, Prediction: tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 47, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 48, Prediction: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 49, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 50, Prediction: tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 51, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 52, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 53, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 54, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 55, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 56, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 57, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 58, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 59, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 60, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 61, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 62, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 63, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 64, Prediction: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Test Accuracy: 0.9062\n",
            "Test Loss: 0.3099\n",
            "Predicted one counter: 590, Predicted zero counter: 434\n",
            "Real one counter: 512, Real zero counter: 512\n",
            "_________________________________________________________________________________________\n",
            "========SUBSET=========\n",
            "Batch: 1, Prediction: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]), Real: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]), Real: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
            "Batch: 3, Prediction: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 4, Prediction: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]), Real: tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
            "Batch: 8, Prediction: tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 9, Prediction: tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.]), Real: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 10, Prediction: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.]), Real: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
            "Batch: 11, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.]), Real: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
            "Batch: 13, Prediction: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.]), Real: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
            "Batch: 14, Prediction: tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Test Accuracy: 0.8795\n",
            "Test Loss: 0.0000\n",
            "Predicted one counter: 93, Predicted zero counter: 131\n",
            "Real one counter: 66, Real zero counter: 158\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8794642857142857, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block size = 3"
      ],
      "metadata": {
        "id": "jEIANGMpQ00S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-4\n",
        "# dropout = 0\n",
        "# n = 15\n",
        "# m = 15\n",
        "# hidden_size = [128, 64]\n",
        "\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 3\n",
        "n = 15\n",
        "m = 15\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 0\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_3, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_3.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_3.pth\")\n",
        "\n",
        "# 55% final accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "wJ2lD7WtLyMM",
        "outputId": "6bcc8c11-fd23-4745-861d-15908bc453eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 3\n",
            "Model created with input_size: 75\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2640791087>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model created with input_size: {input_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrained_model_test_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_l1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinting_rhythm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# save the trained_model_test in my google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model_test_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/trained_model_test_3.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2349955934>\u001b[0m in \u001b[0;36mtrain_validate\u001b[0;34m(model, batch_size, train_size, val_size, dataset_parameters, fixed, conv, balance, lambda_l1, printing_rhythm, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m   \u001b[0;31m# create the training data and load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m   \u001b[0mtraining_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgol_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m   \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2349955934>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_samples, block_size, m, n, tau, t0, rho, balance, normalize)\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0;31m# coarse grain the tau+1 grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0msubgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0mcoarse_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoarse_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2972067934>\u001b[0m in \u001b[0;36mblock_average\u001b[0;34m(grid, block_size)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# we sum over the elements of the subgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0malive_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mdead_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malive_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m     return _wrapreduction(\n\u001b[0m\u001b[1;32m   2390\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m         \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-2\n",
        "# dropout = 0\n",
        "# n = 15\n",
        "# m = 15\n",
        "# hidden_size = [128, 64]\n",
        "# t0 = 15\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 3\n",
        "n = 15\n",
        "m = 15\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 15\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_3, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_3.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCLRhBE6bDJv",
        "outputId": "a7605952-f79a-4cb1-9ec4-8e98af2de1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 3\n",
            "Model created with input_size: 75\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.639894, Validation Loss: 0.696307, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.4999\n",
            "Batch: 10, Training Loss: 0.743087, Validation Loss: 0.691035, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.501953125\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5059\n",
            "Batch: 20, Training Loss: 0.729026, Validation Loss: 0.682842, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.4375 \\| VALIDATION: One counter: 18, Zero counter: 1006, Accuracy: 0.509765625\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5284\n",
            "Batch: 30, Training Loss: 0.661101, Validation Loss: 0.675342, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 71, Zero counter: 953, Accuracy: 0.5185546875\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5506\n",
            "Batch: 40, Training Loss: 0.609712, Validation Loss: 0.665053, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.75 \\| VALIDATION: One counter: 111, Zero counter: 913, Accuracy: 0.5361328125\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5775\n",
            "Batch: 50, Training Loss: 0.768475, Validation Loss: 0.658383, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 190, Zero counter: 834, Accuracy: 0.5703125\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5822\n",
            "Batch: 60, Training Loss: 0.638651, Validation Loss: 0.653837, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 184, Zero counter: 840, Accuracy: 0.572265625\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5647\n",
            "Batch: 70, Training Loss: 0.533343, Validation Loss: 0.655140, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 120, Zero counter: 904, Accuracy: 0.556640625\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5862\n",
            "Batch: 80, Training Loss: 0.746933, Validation Loss: 0.641546, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 176, Zero counter: 848, Accuracy: 0.580078125\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5804\n",
            "Batch: 90, Training Loss: 0.785517, Validation Loss: 0.643952, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 158, Zero counter: 866, Accuracy: 0.578125\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5598\n",
            "Batch: 100, Training Loss: 0.682407, Validation Loss: 0.655515, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 116, Zero counter: 908, Accuracy: 0.55859375\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5926\n",
            "Batch: 110, Training Loss: 0.696163, Validation Loss: 0.645741, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 174, Zero counter: 850, Accuracy: 0.583984375\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5689\n",
            "Batch: 120, Training Loss: 0.779484, Validation Loss: 0.651121, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 129, Zero counter: 895, Accuracy: 0.5673828125\n",
            "[Pre-batch 130] Accuracy on full training data: 0.5653\n",
            "Batch: 130, Training Loss: 0.689374, Validation Loss: 0.663911, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 122, Zero counter: 902, Accuracy: 0.556640625\n",
            "[Pre-batch 140] Accuracy on full training data: 0.6232\n",
            "Batch: 140, Training Loss: 0.563333, Validation Loss: 0.663396, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 387, Zero counter: 637, Accuracy: 0.6279296875\n",
            "[Pre-batch 150] Accuracy on full training data: 0.6025\n",
            "Batch: 150, Training Loss: 0.647127, Validation Loss: 0.660059, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 312, Zero counter: 712, Accuracy: 0.595703125\n",
            "[Pre-batch 160] Accuracy on full training data: 0.5875\n",
            "Batch: 160, Training Loss: 0.671637, Validation Loss: 0.646238, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 183, Zero counter: 841, Accuracy: 0.5771484375\n",
            "[Pre-batch 170] Accuracy on full training data: 0.6059\n",
            "Batch: 170, Training Loss: 0.554163, Validation Loss: 0.638836, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 210, Zero counter: 814, Accuracy: 0.603515625\n",
            "[Pre-batch 180] Accuracy on full training data: 0.5901\n",
            "Batch: 180, Training Loss: 0.536782, Validation Loss: 0.639781, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 163, Zero counter: 861, Accuracy: 0.5830078125\n",
            "[Pre-batch 190] Accuracy on full training data: 0.6000\n",
            "Batch: 190, Training Loss: 0.673621, Validation Loss: 0.634885, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 168, Zero counter: 856, Accuracy: 0.5859375\n",
            "[Pre-batch 200] Accuracy on full training data: 0.5565\n",
            "Batch: 200, Training Loss: 0.697125, Validation Loss: 0.652294, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 86, Zero counter: 938, Accuracy: 0.55078125\n",
            "[Pre-batch 210] Accuracy on full training data: 0.5734\n",
            "Batch: 210, Training Loss: 0.664642, Validation Loss: 0.641247, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 156, Zero counter: 868, Accuracy: 0.57421875\n",
            "[Pre-batch 220] Accuracy on full training data: 0.5847\n",
            "Batch: 220, Training Loss: 0.579965, Validation Loss: 0.660936, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 179, Zero counter: 845, Accuracy: 0.5732421875\n",
            "[Pre-batch 230] Accuracy on full training data: 0.5772\n",
            "Batch: 230, Training Loss: 0.658292, Validation Loss: 0.648220, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 173, Zero counter: 851, Accuracy: 0.5908203125\n",
            "[Pre-batch 240] Accuracy on full training data: 0.6078\n",
            "Batch: 240, Training Loss: 0.834217, Validation Loss: 0.640339, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 215, Zero counter: 809, Accuracy: 0.5927734375\n",
            "[Pre-batch 250] Accuracy on full training data: 0.5998\n",
            "Batch: 250, Training Loss: 0.596470, Validation Loss: 0.642035, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 158, Zero counter: 866, Accuracy: 0.580078125\n",
            "[Pre-batch 260] Accuracy on full training data: 0.5826\n",
            "Batch: 260, Training Loss: 0.624130, Validation Loss: 0.650129, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.8125 \\| VALIDATION: One counter: 128, Zero counter: 896, Accuracy: 0.568359375\n",
            "[Pre-batch 270] Accuracy on full training data: 0.5867\n",
            "Batch: 270, Training Loss: 0.633836, Validation Loss: 0.633386, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 167, Zero counter: 857, Accuracy: 0.5908203125\n",
            "[Pre-batch 280] Accuracy on full training data: 0.6100\n",
            "Batch: 280, Training Loss: 0.633107, Validation Loss: 0.649432, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.375 \\| VALIDATION: One counter: 216, Zero counter: 808, Accuracy: 0.595703125\n",
            "[Pre-batch 290] Accuracy on full training data: 0.5639\n",
            "Batch: 290, Training Loss: 0.562232, Validation Loss: 0.653914, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 109, Zero counter: 915, Accuracy: 0.5595703125\n",
            "[Pre-batch 300] Accuracy on full training data: 0.6031\n",
            "Batch: 300, Training Loss: 0.699047, Validation Loss: 0.656897, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 186, Zero counter: 838, Accuracy: 0.5859375\n",
            "[Pre-batch 310] Accuracy on full training data: 0.5607\n",
            "Batch: 310, Training Loss: 0.654919, Validation Loss: 0.661312, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 140, Zero counter: 884, Accuracy: 0.546875\n",
            "[Pre-batch 320] Accuracy on full training data: 0.6183\n",
            "Batch: 320, Training Loss: 0.574037, Validation Loss: 0.641046, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 247, Zero counter: 777, Accuracy: 0.5947265625\n",
            "[Pre-batch 330] Accuracy on full training data: 0.5904\n",
            "Batch: 330, Training Loss: 0.523746, Validation Loss: 0.645871, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 176, Zero counter: 848, Accuracy: 0.587890625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.6061\n",
            "Batch: 340, Training Loss: 0.550638, Validation Loss: 0.639986, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 183, Zero counter: 841, Accuracy: 0.5927734375\n",
            "[Pre-batch 350] Accuracy on full training data: 0.5856\n",
            "Batch: 350, Training Loss: 0.554164, Validation Loss: 0.643882, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 124, Zero counter: 900, Accuracy: 0.5703125\n",
            "[Pre-batch 360] Accuracy on full training data: 0.5685\n",
            "Batch: 360, Training Loss: 0.620752, Validation Loss: 0.659906, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 116, Zero counter: 908, Accuracy: 0.544921875\n",
            "[Pre-batch 370] Accuracy on full training data: 0.5899\n",
            "Batch: 370, Training Loss: 0.643846, Validation Loss: 0.651458, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 199, Zero counter: 825, Accuracy: 0.5751953125\n",
            "[Pre-batch 380] Accuracy on full training data: 0.5941\n",
            "Batch: 380, Training Loss: 0.623375, Validation Loss: 0.645172, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 174, Zero counter: 850, Accuracy: 0.578125\n",
            "[Pre-batch 390] Accuracy on full training data: 0.5945\n",
            "Batch: 390, Training Loss: 0.604176, Validation Loss: 0.643556, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 159, Zero counter: 865, Accuracy: 0.5693359375\n",
            "[Pre-batch 400] Accuracy on full training data: 0.6102\n",
            "Batch: 400, Training Loss: 0.680819, Validation Loss: 0.638992, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 204, Zero counter: 820, Accuracy: 0.59765625\n",
            "[Pre-batch 410] Accuracy on full training data: 0.6007\n",
            "Batch: 410, Training Loss: 0.608671, Validation Loss: 0.650205, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 174, Zero counter: 850, Accuracy: 0.5859375\n",
            "[Pre-batch 420] Accuracy on full training data: 0.5862\n",
            "Batch: 420, Training Loss: 0.684925, Validation Loss: 0.659764, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 134, Zero counter: 890, Accuracy: 0.56640625\n",
            "[Pre-batch 430] Accuracy on full training data: 0.5877\n",
            "Batch: 430, Training Loss: 0.611338, Validation Loss: 0.655204, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.75 \\| VALIDATION: One counter: 176, Zero counter: 848, Accuracy: 0.5703125\n",
            "[Pre-batch 440] Accuracy on full training data: 0.5962\n",
            "Batch: 440, Training Loss: 0.671676, Validation Loss: 0.641998, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 198, Zero counter: 826, Accuracy: 0.599609375\n",
            "[Pre-batch 450] Accuracy on full training data: 0.5612\n",
            "Batch: 450, Training Loss: 0.604318, Validation Loss: 0.648187, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 133, Zero counter: 891, Accuracy: 0.5673828125\n",
            "[Pre-batch 460] Accuracy on full training data: 0.5446\n",
            "Batch: 460, Training Loss: 0.600304, Validation Loss: 0.650991, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 75, Zero counter: 949, Accuracy: 0.5400390625\n",
            "[Pre-batch 470] Accuracy on full training data: 0.5652\n",
            "Batch: 470, Training Loss: 0.586742, Validation Loss: 0.657858, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 95, Zero counter: 929, Accuracy: 0.5458984375\n",
            "[Pre-batch 480] Accuracy on full training data: 0.5962\n",
            "Batch: 480, Training Loss: 0.648693, Validation Loss: 0.658834, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 179, Zero counter: 845, Accuracy: 0.5810546875\n",
            "[Pre-batch 490] Accuracy on full training data: 0.6000\n",
            "Batch: 490, Training Loss: 0.612389, Validation Loss: 0.648374, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 199, Zero counter: 825, Accuracy: 0.5888671875\n",
            "[Pre-batch 500] Accuracy on full training data: 0.5703\n",
            "Batch: 500, Training Loss: 0.646370, Validation Loss: 0.659077, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 158, Zero counter: 866, Accuracy: 0.564453125\n",
            "[Pre-batch 510] Accuracy on full training data: 0.5715\n",
            "Batch: 510, Training Loss: 0.626477, Validation Loss: 0.653704, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 118, Zero counter: 906, Accuracy: 0.560546875\n",
            "[Pre-batch 520] Accuracy on full training data: 0.5659\n",
            "Batch: 520, Training Loss: 0.653361, Validation Loss: 0.664595, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 134, Zero counter: 890, Accuracy: 0.548828125\n",
            "[Pre-batch 530] Accuracy on full training data: 0.5514\n",
            "Batch: 530, Training Loss: 0.742805, Validation Loss: 0.663597, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.375 \\| VALIDATION: One counter: 114, Zero counter: 910, Accuracy: 0.5390625\n",
            "[Pre-batch 540] Accuracy on full training data: 0.5651\n",
            "Batch: 540, Training Loss: 0.643307, Validation Loss: 0.666157, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 136, Zero counter: 888, Accuracy: 0.556640625\n",
            "[Pre-batch 550] Accuracy on full training data: 0.5939\n",
            "Batch: 550, Training Loss: 0.580277, Validation Loss: 0.645309, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.75 \\| VALIDATION: One counter: 172, Zero counter: 852, Accuracy: 0.59765625\n",
            "[Pre-batch 560] Accuracy on full training data: 0.5809\n",
            "Batch: 560, Training Loss: 0.621725, Validation Loss: 0.644687, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 126, Zero counter: 898, Accuracy: 0.56640625\n",
            "[Pre-batch 570] Accuracy on full training data: 0.5779\n",
            "Batch: 570, Training Loss: 0.613829, Validation Loss: 0.653400, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 109, Zero counter: 915, Accuracy: 0.5576171875\n",
            "[Pre-batch 580] Accuracy on full training data: 0.5192\n",
            "Batch: 580, Training Loss: 0.729152, Validation Loss: 0.679494, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 53, Zero counter: 971, Accuracy: 0.5126953125\n",
            "[Pre-batch 590] Accuracy on full training data: 0.5775\n",
            "Batch: 590, Training Loss: 0.656880, Validation Loss: 0.659119, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 111, Zero counter: 913, Accuracy: 0.5537109375\n",
            "[Pre-batch 600] Accuracy on full training data: 0.5706\n",
            "Batch: 600, Training Loss: 0.669980, Validation Loss: 0.665240, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 142, Zero counter: 882, Accuracy: 0.5625\n",
            "[Pre-batch 610] Accuracy on full training data: 0.5550\n",
            "Batch: 610, Training Loss: 0.649625, Validation Loss: 0.672136, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 67, Zero counter: 957, Accuracy: 0.5302734375\n",
            "[Pre-batch 620] Accuracy on full training data: 0.5568\n",
            "Batch: 620, Training Loss: 0.661302, Validation Loss: 0.663225, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 97, Zero counter: 927, Accuracy: 0.5439453125\n",
            "[Pre-batch 630] Accuracy on full training data: 0.5479\n",
            "Batch: 630, Training Loss: 0.597864, Validation Loss: 0.659515, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 87, Zero counter: 937, Accuracy: 0.5458984375\n",
            "[Pre-batch 640] Accuracy on full training data: 0.5763\n",
            "Batch: 640, Training Loss: 0.658898, Validation Loss: 0.657935, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 128, Zero counter: 896, Accuracy: 0.55859375\n",
            "[Pre-batch 650] Accuracy on full training data: 0.5561\n",
            "Batch: 650, Training Loss: 0.598888, Validation Loss: 0.656085, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 78, Zero counter: 946, Accuracy: 0.541015625\n",
            "[Pre-batch 660] Accuracy on full training data: 0.5713\n",
            "Batch: 660, Training Loss: 0.820960, Validation Loss: 0.650500, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.375 \\| VALIDATION: One counter: 96, Zero counter: 928, Accuracy: 0.5546875\n",
            "[Pre-batch 670] Accuracy on full training data: 0.5889\n",
            "Batch: 670, Training Loss: 0.655646, Validation Loss: 0.656354, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.75 \\| VALIDATION: One counter: 123, Zero counter: 901, Accuracy: 0.5673828125\n",
            "[Pre-batch 680] Accuracy on full training data: 0.5669\n",
            "Batch: 680, Training Loss: 0.614952, Validation Loss: 0.658056, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 79, Zero counter: 945, Accuracy: 0.5361328125\n",
            "[Pre-batch 690] Accuracy on full training data: 0.5840\n",
            "Batch: 690, Training Loss: 0.663517, Validation Loss: 0.648416, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 137, Zero counter: 887, Accuracy: 0.5712890625\n",
            "[Pre-batch 700] Accuracy on full training data: 0.5822\n",
            "Batch: 700, Training Loss: 0.684676, Validation Loss: 0.647225, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 112, Zero counter: 912, Accuracy: 0.5625\n",
            "[Pre-batch 710] Accuracy on full training data: 0.5769\n",
            "Batch: 710, Training Loss: 0.700206, Validation Loss: 0.648345, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 128, Zero counter: 896, Accuracy: 0.5546875\n",
            "[Pre-batch 720] Accuracy on full training data: 0.5435\n",
            "Batch: 720, Training Loss: 0.701297, Validation Loss: 0.660573, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 45, Zero counter: 979, Accuracy: 0.5244140625\n",
            "[Pre-batch 730] Accuracy on full training data: 0.5095\n",
            "Batch: 730, Training Loss: 0.666501, Validation Loss: 0.676400, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 21, Zero counter: 1003, Accuracy: 0.5087890625\n",
            "[Pre-batch 740] Accuracy on full training data: 0.5599\n",
            "Batch: 740, Training Loss: 0.699151, Validation Loss: 0.660927, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 143, Zero counter: 881, Accuracy: 0.5537109375\n",
            "[Pre-batch 750] Accuracy on full training data: 0.5931\n",
            "Batch: 750, Training Loss: 0.646008, Validation Loss: 0.651915, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.6875 \\| VALIDATION: One counter: 171, Zero counter: 853, Accuracy: 0.5791015625\n",
            "[Pre-batch 760] Accuracy on full training data: 0.5952\n",
            "Batch: 760, Training Loss: 0.662064, Validation Loss: 0.650189, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 134, Zero counter: 890, Accuracy: 0.56640625\n",
            "[Pre-batch 770] Accuracy on full training data: 0.5768\n",
            "Batch: 770, Training Loss: 0.589821, Validation Loss: 0.654020, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.75 \\| VALIDATION: One counter: 108, Zero counter: 916, Accuracy: 0.546875\n",
            "[Pre-batch 780] Accuracy on full training data: 0.5838\n",
            "Batch: 780, Training Loss: 0.699027, Validation Loss: 0.649608, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 119, Zero counter: 905, Accuracy: 0.5556640625\n",
            "[Pre-batch 790] Accuracy on full training data: 0.5709\n",
            "Batch: 790, Training Loss: 0.604706, Validation Loss: 0.650344, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 93, Zero counter: 931, Accuracy: 0.5556640625\n",
            "[Pre-batch 800] Accuracy on full training data: 0.5760\n",
            "Batch: 800, Training Loss: 0.651707, Validation Loss: 0.656436, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 102, Zero counter: 922, Accuracy: 0.552734375\n",
            "[Pre-batch 810] Accuracy on full training data: 0.5471\n",
            "Batch: 810, Training Loss: 0.672421, Validation Loss: 0.655378, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 77, Zero counter: 947, Accuracy: 0.5400390625\n",
            "[Pre-batch 820] Accuracy on full training data: 0.5716\n",
            "Batch: 820, Training Loss: 0.660108, Validation Loss: 0.651429, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 106, Zero counter: 918, Accuracy: 0.552734375\n",
            "[Pre-batch 830] Accuracy on full training data: 0.5710\n",
            "Batch: 830, Training Loss: 0.601422, Validation Loss: 0.654219, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 96, Zero counter: 928, Accuracy: 0.55078125\n",
            "[Pre-batch 840] Accuracy on full training data: 0.5760\n",
            "Batch: 840, Training Loss: 0.681612, Validation Loss: 0.657385, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 121, Zero counter: 903, Accuracy: 0.5615234375\n",
            "[Pre-batch 850] Accuracy on full training data: 0.5638\n",
            "Batch: 850, Training Loss: 0.623393, Validation Loss: 0.661881, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 98, Zero counter: 926, Accuracy: 0.55078125\n",
            "[Pre-batch 860] Accuracy on full training data: 0.5798\n",
            "Batch: 860, Training Loss: 0.610072, Validation Loss: 0.655577, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 112, Zero counter: 912, Accuracy: 0.55859375\n",
            "[Pre-batch 870] Accuracy on full training data: 0.5844\n",
            "Batch: 870, Training Loss: 0.650645, Validation Loss: 0.653566, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 120, Zero counter: 904, Accuracy: 0.55859375\n",
            "[Pre-batch 880] Accuracy on full training data: 0.5736\n",
            "Batch: 880, Training Loss: 0.609189, Validation Loss: 0.659760, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 106, Zero counter: 918, Accuracy: 0.55078125\n",
            "[Pre-batch 890] Accuracy on full training data: 0.5423\n",
            "Batch: 890, Training Loss: 0.627127, Validation Loss: 0.659624, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 42, Zero counter: 982, Accuracy: 0.51953125\n",
            "[Pre-batch 900] Accuracy on full training data: 0.5583\n",
            "Batch: 900, Training Loss: 0.642809, Validation Loss: 0.655684, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 68, Zero counter: 956, Accuracy: 0.53125\n",
            "[Pre-batch 910] Accuracy on full training data: 0.5824\n",
            "Batch: 910, Training Loss: 0.648377, Validation Loss: 0.651286, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 130, Zero counter: 894, Accuracy: 0.556640625\n",
            "[Pre-batch 920] Accuracy on full training data: 0.5853\n",
            "Batch: 920, Training Loss: 0.681143, Validation Loss: 0.653717, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 130, Zero counter: 894, Accuracy: 0.564453125\n",
            "[Pre-batch 930] Accuracy on full training data: 0.5800\n",
            "Batch: 930, Training Loss: 0.657369, Validation Loss: 0.655097, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 109, Zero counter: 915, Accuracy: 0.5537109375\n",
            "[Pre-batch 940] Accuracy on full training data: 0.5697\n",
            "Batch: 940, Training Loss: 0.625068, Validation Loss: 0.654661, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 102, Zero counter: 922, Accuracy: 0.546875\n",
            "[Pre-batch 950] Accuracy on full training data: 0.5284\n",
            "Batch: 950, Training Loss: 0.719798, Validation Loss: 0.655010, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 32, Zero counter: 992, Accuracy: 0.515625\n",
            "[Pre-batch 960] Accuracy on full training data: 0.5370\n",
            "Batch: 960, Training Loss: 0.719452, Validation Loss: 0.650436, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 46, Zero counter: 978, Accuracy: 0.515625\n",
            "[Pre-batch 970] Accuracy on full training data: 0.5359\n",
            "Batch: 970, Training Loss: 0.618213, Validation Loss: 0.651138, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.75 \\| VALIDATION: One counter: 33, Zero counter: 991, Accuracy: 0.5166015625\n",
            "[Pre-batch 980] Accuracy on full training data: 0.5098\n",
            "Batch: 980, Training Loss: 0.685619, Validation Loss: 0.655188, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 18, Zero counter: 1006, Accuracy: 0.509765625\n",
            "[Pre-batch 990] Accuracy on full training data: 0.5410\n",
            "Batch: 990, Training Loss: 0.627942, Validation Loss: 0.651207, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 54, Zero counter: 970, Accuracy: 0.53515625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try it with the testing function\n",
        "testing(trained_model_test_3, batch_size=16, dataset_parameters=dataset_parameters, fixed=False, conv=False, verbose=True, balance=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5IFZUYfp4Zi",
        "outputId": "b7cd8f9d-f248-404f-84b2-43cac48f68bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========DATASET=========\n",
            "Batch: 1, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 3, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 4, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 8, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 9, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 10, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 11, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 13, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 14, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 15, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 16, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 17, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 18, Prediction: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
            "Batch: 19, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
            "Batch: 20, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 21, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 22, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 23, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 24, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
            "Batch: 25, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 26, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 27, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 28, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 29, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 30, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 31, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Batch: 32, Prediction: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 33, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
            "Batch: 34, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 35, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 36, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 37, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 38, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 39, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 40, Prediction: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 41, Prediction: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 42, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 43, Prediction: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 44, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 45, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 46, Prediction: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 47, Prediction: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 48, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 49, Prediction: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 50, Prediction: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 51, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 52, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 53, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 54, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 55, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 56, Prediction: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 57, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 58, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 59, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 60, Prediction: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 61, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 62, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 63, Prediction: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Batch: 64, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.]), Real: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "Test Accuracy: 0.5391\n",
            "Test Loss: 0.6520\n",
            "Predicted one counter: 68, Predicted zero counter: 956\n",
            "Real one counter: 512, Real zero counter: 512\n",
            "_________________________________________________________________________________________\n",
            "========SUBSET=========\n",
            "Batch: 1, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 2, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 3, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 4, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 5, Prediction: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
            "Batch: 6, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 7, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 8, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 9, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 10, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
            "Batch: 11, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 12, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 13, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Batch: 14, Prediction: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), Real: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
            "Test Accuracy: 0.9286\n",
            "Test Loss: 0.0000\n",
            "Predicted one counter: 4, Predicted zero counter: 220\n",
            "Real one counter: 14, Real zero counter: 210\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9285714285714286, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-2\n",
        "# dropout = 0\n",
        "# n = 15\n",
        "# m = 15\n",
        "# hidden_size = [128, 64, 32, 16, 8]\n",
        "# t0 = 15\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 3\n",
        "n = 15\n",
        "m = 15\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 15\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64, 32, 16, 8]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_3, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_3.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-soQRVvdElYI",
        "outputId": "9f6a3ba6-d5d5-492c-f385-c0456e9c1526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 3\n",
            "Model created with input_size: 75\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.870932, Validation Loss: 0.706748, TRAINING: One counter: 10, Zero counter: 6, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.4999\n",
            "Batch: 10, Training Loss: 0.717119, Validation Loss: 0.710818, TRAINING: One counter: 11, Zero counter: 5, Accuracy: 0.5 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5285\n",
            "Batch: 20, Training Loss: 0.721507, Validation Loss: 0.712069, TRAINING: One counter: 12, Zero counter: 4, Accuracy: 0.5 \\| VALIDATION: One counter: 249, Zero counter: 775, Accuracy: 0.5322265625\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5585\n",
            "Batch: 30, Training Loss: 0.809182, Validation Loss: 0.708775, TRAINING: One counter: 9, Zero counter: 7, Accuracy: 0.4375 \\| VALIDATION: One counter: 424, Zero counter: 600, Accuracy: 0.546875\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5818\n",
            "Batch: 40, Training Loss: 0.630800, Validation Loss: 0.701127, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.75 \\| VALIDATION: One counter: 480, Zero counter: 544, Accuracy: 0.56640625\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5869\n",
            "Batch: 50, Training Loss: 0.848227, Validation Loss: 0.691096, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.5625 \\| VALIDATION: One counter: 395, Zero counter: 629, Accuracy: 0.5732421875\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5876\n",
            "Batch: 60, Training Loss: 0.609707, Validation Loss: 0.689156, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.625 \\| VALIDATION: One counter: 374, Zero counter: 650, Accuracy: 0.578125\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5797\n",
            "Batch: 70, Training Loss: 0.776133, Validation Loss: 0.682219, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.3125 \\| VALIDATION: One counter: 303, Zero counter: 721, Accuracy: 0.5771484375\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5815\n",
            "Batch: 80, Training Loss: 0.649866, Validation Loss: 0.683097, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.75 \\| VALIDATION: One counter: 285, Zero counter: 739, Accuracy: 0.5869140625\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5849\n",
            "Batch: 90, Training Loss: 0.505996, Validation Loss: 0.675512, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.6875 \\| VALIDATION: One counter: 273, Zero counter: 751, Accuracy: 0.5947265625\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5911\n",
            "Batch: 100, Training Loss: 0.726280, Validation Loss: 0.674581, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 275, Zero counter: 749, Accuracy: 0.6025390625\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5771\n",
            "Batch: 110, Training Loss: 0.655218, Validation Loss: 0.674146, TRAINING: One counter: 7, Zero counter: 9, Accuracy: 0.5625 \\| VALIDATION: One counter: 200, Zero counter: 824, Accuracy: 0.591796875\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5799\n",
            "Batch: 120, Training Loss: 0.586926, Validation Loss: 0.672206, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 226, Zero counter: 798, Accuracy: 0.58203125\n",
            "[Pre-batch 130] Accuracy on full training data: 0.5918\n",
            "Batch: 130, Training Loss: 0.666842, Validation Loss: 0.661612, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5625 \\| VALIDATION: One counter: 194, Zero counter: 830, Accuracy: 0.595703125\n",
            "[Pre-batch 140] Accuracy on full training data: 0.5923\n",
            "Batch: 140, Training Loss: 0.653875, Validation Loss: 0.652845, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.6875 \\| VALIDATION: One counter: 191, Zero counter: 833, Accuracy: 0.5849609375\n",
            "[Pre-batch 150] Accuracy on full training data: 0.5988\n",
            "Batch: 150, Training Loss: 0.554610, Validation Loss: 0.652407, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.8125 \\| VALIDATION: One counter: 212, Zero counter: 812, Accuracy: 0.595703125\n",
            "[Pre-batch 160] Accuracy on full training data: 0.6024\n",
            "Batch: 160, Training Loss: 0.535071, Validation Loss: 0.648857, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 200, Zero counter: 824, Accuracy: 0.6015625\n",
            "[Pre-batch 170] Accuracy on full training data: 0.5903\n",
            "Batch: 170, Training Loss: 0.737602, Validation Loss: 0.650348, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 185, Zero counter: 839, Accuracy: 0.5869140625\n",
            "[Pre-batch 180] Accuracy on full training data: 0.5846\n",
            "Batch: 180, Training Loss: 0.697921, Validation Loss: 0.647226, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.6875 \\| VALIDATION: One counter: 186, Zero counter: 838, Accuracy: 0.595703125\n",
            "[Pre-batch 190] Accuracy on full training data: 0.5741\n",
            "Batch: 190, Training Loss: 0.599660, Validation Loss: 0.652204, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 154, Zero counter: 870, Accuracy: 0.576171875\n",
            "[Pre-batch 200] Accuracy on full training data: 0.5776\n",
            "Batch: 200, Training Loss: 0.587634, Validation Loss: 0.649392, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 165, Zero counter: 859, Accuracy: 0.5751953125\n",
            "[Pre-batch 210] Accuracy on full training data: 0.5681\n",
            "Batch: 210, Training Loss: 0.546714, Validation Loss: 0.649275, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.75 \\| VALIDATION: One counter: 125, Zero counter: 899, Accuracy: 0.5634765625\n",
            "[Pre-batch 220] Accuracy on full training data: 0.5853\n",
            "Batch: 220, Training Loss: 0.701973, Validation Loss: 0.646952, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.58984375\n",
            "[Pre-batch 230] Accuracy on full training data: 0.5886\n",
            "Batch: 230, Training Loss: 0.756889, Validation Loss: 0.644931, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.4375 \\| VALIDATION: One counter: 156, Zero counter: 868, Accuracy: 0.60546875\n",
            "[Pre-batch 240] Accuracy on full training data: 0.5914\n",
            "Batch: 240, Training Loss: 0.656115, Validation Loss: 0.640114, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.6015625\n",
            "[Pre-batch 250] Accuracy on full training data: 0.5866\n",
            "Batch: 250, Training Loss: 0.642021, Validation Loss: 0.649697, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 176, Zero counter: 848, Accuracy: 0.58984375\n",
            "[Pre-batch 260] Accuracy on full training data: 0.5849\n",
            "Batch: 260, Training Loss: 0.659028, Validation Loss: 0.648231, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 170, Zero counter: 854, Accuracy: 0.587890625\n",
            "[Pre-batch 270] Accuracy on full training data: 0.5567\n",
            "Batch: 270, Training Loss: 0.627458, Validation Loss: 0.657450, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 93, Zero counter: 931, Accuracy: 0.5478515625\n",
            "[Pre-batch 280] Accuracy on full training data: 0.5844\n",
            "Batch: 280, Training Loss: 0.623823, Validation Loss: 0.642365, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 141, Zero counter: 883, Accuracy: 0.5830078125\n",
            "[Pre-batch 290] Accuracy on full training data: 0.5639\n",
            "Batch: 290, Training Loss: 0.644247, Validation Loss: 0.635792, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 117, Zero counter: 907, Accuracy: 0.5751953125\n",
            "[Pre-batch 300] Accuracy on full training data: 0.5754\n",
            "Batch: 300, Training Loss: 0.564997, Validation Loss: 0.649638, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 122, Zero counter: 902, Accuracy: 0.578125\n",
            "[Pre-batch 310] Accuracy on full training data: 0.5597\n",
            "Batch: 310, Training Loss: 0.654486, Validation Loss: 0.650210, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 126, Zero counter: 898, Accuracy: 0.56640625\n",
            "[Pre-batch 320] Accuracy on full training data: 0.5651\n",
            "Batch: 320, Training Loss: 0.635551, Validation Loss: 0.648594, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.5 \\| VALIDATION: One counter: 120, Zero counter: 904, Accuracy: 0.578125\n",
            "[Pre-batch 330] Accuracy on full training data: 0.5884\n",
            "Batch: 330, Training Loss: 0.542022, Validation Loss: 0.637033, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 156, Zero counter: 868, Accuracy: 0.603515625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.5713\n",
            "Batch: 340, Training Loss: 0.575380, Validation Loss: 0.637894, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 112, Zero counter: 912, Accuracy: 0.580078125\n",
            "[Pre-batch 350] Accuracy on full training data: 0.5591\n",
            "Batch: 350, Training Loss: 0.698563, Validation Loss: 0.642279, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 101, Zero counter: 923, Accuracy: 0.5732421875\n",
            "[Pre-batch 360] Accuracy on full training data: 0.5805\n",
            "Batch: 360, Training Loss: 0.644004, Validation Loss: 0.646231, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.75 \\| VALIDATION: One counter: 123, Zero counter: 901, Accuracy: 0.5947265625\n",
            "[Pre-batch 370] Accuracy on full training data: 0.5623\n",
            "Batch: 370, Training Loss: 0.587874, Validation Loss: 0.638366, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 103, Zero counter: 921, Accuracy: 0.5849609375\n",
            "[Pre-batch 380] Accuracy on full training data: 0.5714\n",
            "Batch: 380, Training Loss: 0.698182, Validation Loss: 0.666016, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.375 \\| VALIDATION: One counter: 213, Zero counter: 811, Accuracy: 0.5771484375\n",
            "[Pre-batch 390] Accuracy on full training data: 0.5885\n",
            "Batch: 390, Training Loss: 0.583809, Validation Loss: 0.664411, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.875 \\| VALIDATION: One counter: 276, Zero counter: 748, Accuracy: 0.57421875\n",
            "[Pre-batch 400] Accuracy on full training data: 0.5871\n",
            "Batch: 400, Training Loss: 0.642401, Validation Loss: 0.647396, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 190, Zero counter: 834, Accuracy: 0.560546875\n",
            "[Pre-batch 410] Accuracy on full training data: 0.5972\n",
            "Batch: 410, Training Loss: 0.667863, Validation Loss: 0.646183, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 227, Zero counter: 797, Accuracy: 0.5927734375\n",
            "[Pre-batch 420] Accuracy on full training data: 0.5811\n",
            "Batch: 420, Training Loss: 0.666169, Validation Loss: 0.650637, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.56640625\n",
            "[Pre-batch 430] Accuracy on full training data: 0.5483\n",
            "Batch: 430, Training Loss: 0.626619, Validation Loss: 0.664642, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 118, Zero counter: 906, Accuracy: 0.533203125\n",
            "[Pre-batch 440] Accuracy on full training data: 0.5432\n",
            "Batch: 440, Training Loss: 0.542132, Validation Loss: 0.661787, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.4375 \\| VALIDATION: One counter: 78, Zero counter: 946, Accuracy: 0.533203125\n",
            "[Pre-batch 450] Accuracy on full training data: 0.5677\n",
            "Batch: 450, Training Loss: 0.666832, Validation Loss: 0.640909, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 130, Zero counter: 894, Accuracy: 0.583984375\n",
            "[Pre-batch 460] Accuracy on full training data: 0.5855\n",
            "Batch: 460, Training Loss: 0.520884, Validation Loss: 0.651647, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 202, Zero counter: 822, Accuracy: 0.576171875\n",
            "[Pre-batch 470] Accuracy on full training data: 0.5556\n",
            "Batch: 470, Training Loss: 0.772371, Validation Loss: 0.663594, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 139, Zero counter: 885, Accuracy: 0.5458984375\n",
            "[Pre-batch 480] Accuracy on full training data: 0.5351\n",
            "Batch: 480, Training Loss: 0.593711, Validation Loss: 0.690668, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.375 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.5390625\n",
            "[Pre-batch 490] Accuracy on full training data: 0.5059\n",
            "Batch: 490, Training Loss: 0.604360, Validation Loss: 0.660571, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 25, Zero counter: 999, Accuracy: 0.5029296875\n",
            "[Pre-batch 500] Accuracy on full training data: 0.5269\n",
            "Batch: 500, Training Loss: 0.658824, Validation Loss: 0.651403, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.625 \\| VALIDATION: One counter: 56, Zero counter: 968, Accuracy: 0.533203125\n",
            "[Pre-batch 510] Accuracy on full training data: 0.5796\n",
            "Batch: 510, Training Loss: 0.576447, Validation Loss: 0.663249, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 198, Zero counter: 826, Accuracy: 0.58203125\n",
            "[Pre-batch 520] Accuracy on full training data: 0.5885\n",
            "Batch: 520, Training Loss: 0.732261, Validation Loss: 0.658106, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 199, Zero counter: 825, Accuracy: 0.5732421875\n",
            "[Pre-batch 530] Accuracy on full training data: 0.5764\n",
            "Batch: 530, Training Loss: 0.702813, Validation Loss: 0.667710, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.4375 \\| VALIDATION: One counter: 172, Zero counter: 852, Accuracy: 0.56640625\n",
            "[Pre-batch 540] Accuracy on full training data: 0.5917\n",
            "Batch: 540, Training Loss: 0.556712, Validation Loss: 0.639857, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 140, Zero counter: 884, Accuracy: 0.59375\n",
            "[Pre-batch 550] Accuracy on full training data: 0.5688\n",
            "Batch: 550, Training Loss: 0.615778, Validation Loss: 0.646189, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 111, Zero counter: 913, Accuracy: 0.5712890625\n",
            "[Pre-batch 560] Accuracy on full training data: 0.5317\n",
            "Batch: 560, Training Loss: 0.696630, Validation Loss: 0.667003, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 85, Zero counter: 939, Accuracy: 0.5400390625\n",
            "[Pre-batch 570] Accuracy on full training data: 0.5182\n",
            "Batch: 570, Training Loss: 0.810993, Validation Loss: 0.656122, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.25 \\| VALIDATION: One counter: 53, Zero counter: 971, Accuracy: 0.5224609375\n",
            "[Pre-batch 580] Accuracy on full training data: 0.5058\n",
            "Batch: 580, Training Loss: 0.629867, Validation Loss: 0.704151, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.75 \\| VALIDATION: One counter: 18, Zero counter: 1006, Accuracy: 0.509765625\n",
            "[Pre-batch 590] Accuracy on full training data: 0.5292\n",
            "Batch: 590, Training Loss: 0.730099, Validation Loss: 0.668890, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 87, Zero counter: 937, Accuracy: 0.5361328125\n",
            "[Pre-batch 600] Accuracy on full training data: 0.5363\n",
            "Batch: 600, Training Loss: 0.758714, Validation Loss: 0.652397, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 124, Zero counter: 900, Accuracy: 0.541015625\n",
            "[Pre-batch 610] Accuracy on full training data: 0.5978\n",
            "Batch: 610, Training Loss: 0.624186, Validation Loss: 0.629740, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 173, Zero counter: 851, Accuracy: 0.6142578125\n",
            "[Pre-batch 620] Accuracy on full training data: 0.5684\n",
            "Batch: 620, Training Loss: 0.640714, Validation Loss: 0.647851, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 88, Zero counter: 936, Accuracy: 0.556640625\n",
            "[Pre-batch 630] Accuracy on full training data: 0.5377\n",
            "Batch: 630, Training Loss: 0.627462, Validation Loss: 0.659951, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 85, Zero counter: 939, Accuracy: 0.5595703125\n",
            "[Pre-batch 640] Accuracy on full training data: 0.5285\n",
            "Batch: 640, Training Loss: 0.630467, Validation Loss: 0.666757, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 23, Zero counter: 1001, Accuracy: 0.5107421875\n",
            "[Pre-batch 650] Accuracy on full training data: 0.5085\n",
            "Batch: 650, Training Loss: 0.730538, Validation Loss: 0.665972, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.375 \\| VALIDATION: One counter: 38, Zero counter: 986, Accuracy: 0.505859375\n",
            "[Pre-batch 660] Accuracy on full training data: 0.5813\n",
            "Batch: 660, Training Loss: 0.654785, Validation Loss: 0.650065, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 196, Zero counter: 828, Accuracy: 0.58984375\n",
            "[Pre-batch 670] Accuracy on full training data: 0.5891\n",
            "Batch: 670, Training Loss: 0.693995, Validation Loss: 0.653835, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 214, Zero counter: 810, Accuracy: 0.591796875\n",
            "[Pre-batch 680] Accuracy on full training data: 0.5747\n",
            "Batch: 680, Training Loss: 0.627864, Validation Loss: 0.653415, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 122, Zero counter: 902, Accuracy: 0.58203125\n",
            "[Pre-batch 690] Accuracy on full training data: 0.5913\n",
            "Batch: 690, Training Loss: 0.588764, Validation Loss: 0.638462, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.4375 \\| VALIDATION: One counter: 155, Zero counter: 869, Accuracy: 0.5966796875\n",
            "[Pre-batch 700] Accuracy on full training data: 0.5511\n",
            "Batch: 700, Training Loss: 0.586376, Validation Loss: 0.660561, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 71, Zero counter: 953, Accuracy: 0.5576171875\n",
            "[Pre-batch 710] Accuracy on full training data: 0.5696\n",
            "Batch: 710, Training Loss: 0.611737, Validation Loss: 0.656350, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 110, Zero counter: 914, Accuracy: 0.578125\n",
            "[Pre-batch 720] Accuracy on full training data: 0.5889\n",
            "Batch: 720, Training Loss: 0.688521, Validation Loss: 0.642112, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 177, Zero counter: 847, Accuracy: 0.6123046875\n",
            "[Pre-batch 730] Accuracy on full training data: 0.5576\n",
            "Batch: 730, Training Loss: 0.573278, Validation Loss: 0.655154, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.75 \\| VALIDATION: One counter: 123, Zero counter: 901, Accuracy: 0.5595703125\n",
            "[Pre-batch 740] Accuracy on full training data: 0.5174\n",
            "Batch: 740, Training Loss: 0.725023, Validation Loss: 0.702423, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 57, Zero counter: 967, Accuracy: 0.5048828125\n",
            "[Pre-batch 750] Accuracy on full training data: 0.5938\n",
            "Batch: 750, Training Loss: 0.760985, Validation Loss: 0.622831, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 159, Zero counter: 865, Accuracy: 0.6103515625\n",
            "[Pre-batch 760] Accuracy on full training data: 0.5640\n",
            "Batch: 760, Training Loss: 0.693991, Validation Loss: 0.649221, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.375 \\| VALIDATION: One counter: 120, Zero counter: 904, Accuracy: 0.58984375\n",
            "[Pre-batch 770] Accuracy on full training data: 0.5942\n",
            "Batch: 770, Training Loss: 0.547268, Validation Loss: 0.650581, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.6875 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.603515625\n",
            "[Pre-batch 780] Accuracy on full training data: 0.5473\n",
            "Batch: 780, Training Loss: 0.544248, Validation Loss: 0.649604, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.75 \\| VALIDATION: One counter: 45, Zero counter: 979, Accuracy: 0.5341796875\n",
            "[Pre-batch 790] Accuracy on full training data: 0.5296\n",
            "Batch: 790, Training Loss: 0.666255, Validation Loss: 0.645028, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 46, Zero counter: 978, Accuracy: 0.53515625\n",
            "[Pre-batch 800] Accuracy on full training data: 0.5026\n",
            "Batch: 800, Training Loss: 0.684406, Validation Loss: 0.675750, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 810] Accuracy on full training data: 0.5528\n",
            "Batch: 810, Training Loss: 0.673998, Validation Loss: 0.640814, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 88, Zero counter: 936, Accuracy: 0.564453125\n",
            "[Pre-batch 820] Accuracy on full training data: 0.5619\n",
            "Batch: 820, Training Loss: 0.544910, Validation Loss: 0.662630, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 171, Zero counter: 853, Accuracy: 0.5693359375\n",
            "[Pre-batch 830] Accuracy on full training data: 0.5974\n",
            "Batch: 830, Training Loss: 0.617217, Validation Loss: 0.644654, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.75 \\| VALIDATION: One counter: 177, Zero counter: 847, Accuracy: 0.6025390625\n",
            "[Pre-batch 840] Accuracy on full training data: 0.5929\n",
            "Batch: 840, Training Loss: 0.698313, Validation Loss: 0.646393, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 157, Zero counter: 867, Accuracy: 0.6083984375\n",
            "[Pre-batch 850] Accuracy on full training data: 0.5769\n",
            "Batch: 850, Training Loss: 0.653859, Validation Loss: 0.646401, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 111, Zero counter: 913, Accuracy: 0.5810546875\n",
            "[Pre-batch 860] Accuracy on full training data: 0.5577\n",
            "Batch: 860, Training Loss: 0.666117, Validation Loss: 0.664258, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 70, Zero counter: 954, Accuracy: 0.55078125\n",
            "[Pre-batch 870] Accuracy on full training data: 0.5026\n",
            "Batch: 870, Training Loss: 0.639996, Validation Loss: 0.677048, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.5029296875\n",
            "[Pre-batch 880] Accuracy on full training data: 0.5017\n",
            "Batch: 880, Training Loss: 0.566373, Validation Loss: 0.701955, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 890] Accuracy on full training data: 0.5665\n",
            "Batch: 890, Training Loss: 0.590721, Validation Loss: 0.638304, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 97, Zero counter: 927, Accuracy: 0.5576171875\n",
            "[Pre-batch 900] Accuracy on full training data: 0.5842\n",
            "Batch: 900, Training Loss: 0.556664, Validation Loss: 0.675543, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 156, Zero counter: 868, Accuracy: 0.578125\n",
            "[Pre-batch 910] Accuracy on full training data: 0.5854\n",
            "Batch: 910, Training Loss: 0.775772, Validation Loss: 0.692127, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 164, Zero counter: 860, Accuracy: 0.587890625\n",
            "[Pre-batch 920] Accuracy on full training data: 0.5654\n",
            "Batch: 920, Training Loss: 0.666885, Validation Loss: 0.681234, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.6875 \\| VALIDATION: One counter: 101, Zero counter: 923, Accuracy: 0.5673828125\n",
            "[Pre-batch 930] Accuracy on full training data: 0.5269\n",
            "Batch: 930, Training Loss: 0.615648, Validation Loss: 0.671673, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 27, Zero counter: 997, Accuracy: 0.5146484375\n",
            "[Pre-batch 940] Accuracy on full training data: 0.5838\n",
            "Batch: 940, Training Loss: 0.715437, Validation Loss: 0.654208, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 184, Zero counter: 840, Accuracy: 0.57421875\n",
            "[Pre-batch 950] Accuracy on full training data: 0.5673\n",
            "Batch: 950, Training Loss: 0.656636, Validation Loss: 0.644395, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 114, Zero counter: 910, Accuracy: 0.57421875\n",
            "[Pre-batch 960] Accuracy on full training data: 0.5437\n",
            "Batch: 960, Training Loss: 0.746045, Validation Loss: 0.649779, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 71, Zero counter: 953, Accuracy: 0.5517578125\n",
            "[Pre-batch 970] Accuracy on full training data: 0.5066\n",
            "Batch: 970, Training Loss: 0.628743, Validation Loss: 0.672527, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 7, Zero counter: 1017, Accuracy: 0.5068359375\n",
            "[Pre-batch 980] Accuracy on full training data: 0.5000\n",
            "Batch: 980, Training Loss: 0.590766, Validation Loss: 0.670693, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 990] Accuracy on full training data: 0.5092\n",
            "Batch: 990, Training Loss: 0.716516, Validation Loss: 0.684584, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 66, Zero counter: 958, Accuracy: 0.505859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-2\n",
        "# dropout = 0\n",
        "# n = 25\n",
        "# m = 25\n",
        "# hidden_size = [128, 64]\n",
        "# t0 = 0\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 3\n",
        "n = 25\n",
        "m = 25\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 0\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_3, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_3.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UOvn_31RMFR",
        "outputId": "fb1a57c8-ebb7-4c73-ed83-5113e6324efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 3\n",
            "Model created with input_size: 192\n",
            "Starting training...\n",
            "Counter : 16002, Dead count : 8000, Alive count : 8000\n",
            "Counter : 1024, Dead count : 512, Alive count : 512\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.661995, Validation Loss: 0.696084, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.4999\n",
            "Batch: 10, Training Loss: 0.703307, Validation Loss: 0.696651, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.4990234375\n",
            "[Pre-batch 20] Accuracy on full training data: 0.4992\n",
            "Batch: 20, Training Loss: 0.683456, Validation Loss: 0.698541, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.4970703125\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5001\n",
            "Batch: 30, Training Loss: 0.679841, Validation Loss: 0.698700, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 20, Zero counter: 1004, Accuracy: 0.49609375\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5030\n",
            "Batch: 40, Training Loss: 0.731751, Validation Loss: 0.697097, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 25, Zero counter: 999, Accuracy: 0.4970703125\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5069\n",
            "Batch: 50, Training Loss: 0.690921, Validation Loss: 0.695629, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 50, Zero counter: 974, Accuracy: 0.50390625\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5072\n",
            "Batch: 60, Training Loss: 0.674348, Validation Loss: 0.694590, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 33, Zero counter: 991, Accuracy: 0.5009765625\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5101\n",
            "Batch: 70, Training Loss: 0.733564, Validation Loss: 0.688300, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.25 \\| VALIDATION: One counter: 43, Zero counter: 981, Accuracy: 0.5048828125\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5155\n",
            "Batch: 80, Training Loss: 0.688608, Validation Loss: 0.681079, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 68, Zero counter: 956, Accuracy: 0.515625\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5232\n",
            "Batch: 90, Training Loss: 0.744128, Validation Loss: 0.676523, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 98, Zero counter: 926, Accuracy: 0.513671875\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5298\n",
            "Batch: 100, Training Loss: 0.733137, Validation Loss: 0.683066, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 171, Zero counter: 853, Accuracy: 0.5166015625\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5398\n",
            "Batch: 110, Training Loss: 0.630915, Validation Loss: 0.680485, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 223, Zero counter: 801, Accuracy: 0.5654296875\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5361\n",
            "Batch: 120, Training Loss: 0.717272, Validation Loss: 0.675274, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 171, Zero counter: 853, Accuracy: 0.5458984375\n",
            "[Pre-batch 130] Accuracy on full training data: 0.5188\n",
            "Batch: 130, Training Loss: 0.769010, Validation Loss: 0.679780, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 78, Zero counter: 946, Accuracy: 0.517578125\n",
            "[Pre-batch 140] Accuracy on full training data: 0.5064\n",
            "Batch: 140, Training Loss: 0.674894, Validation Loss: 0.696701, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 30, Zero counter: 994, Accuracy: 0.5\n",
            "[Pre-batch 150] Accuracy on full training data: 0.5266\n",
            "Batch: 150, Training Loss: 0.655574, Validation Loss: 0.685362, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.3125 \\| VALIDATION: One counter: 143, Zero counter: 881, Accuracy: 0.5087890625\n",
            "[Pre-batch 160] Accuracy on full training data: 0.5586\n",
            "Batch: 160, Training Loss: 0.658051, Validation Loss: 0.678378, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.75 \\| VALIDATION: One counter: 249, Zero counter: 775, Accuracy: 0.5458984375\n",
            "[Pre-batch 170] Accuracy on full training data: 0.5395\n",
            "Batch: 170, Training Loss: 0.622685, Validation Loss: 0.679100, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.625 \\| VALIDATION: One counter: 187, Zero counter: 837, Accuracy: 0.5205078125\n",
            "[Pre-batch 180] Accuracy on full training data: 0.5245\n",
            "Batch: 180, Training Loss: 0.668313, Validation Loss: 0.688143, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 95, Zero counter: 929, Accuracy: 0.5087890625\n",
            "[Pre-batch 190] Accuracy on full training data: 0.5298\n",
            "Batch: 190, Training Loss: 0.671562, Validation Loss: 0.688410, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 156, Zero counter: 868, Accuracy: 0.51953125\n",
            "[Pre-batch 200] Accuracy on full training data: 0.5494\n",
            "Batch: 200, Training Loss: 0.723961, Validation Loss: 0.679142, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 227, Zero counter: 797, Accuracy: 0.5419921875\n",
            "[Pre-batch 210] Accuracy on full training data: 0.5397\n",
            "Batch: 210, Training Loss: 0.729037, Validation Loss: 0.687144, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 221, Zero counter: 803, Accuracy: 0.5498046875\n",
            "[Pre-batch 220] Accuracy on full training data: 0.5359\n",
            "Batch: 220, Training Loss: 0.798429, Validation Loss: 0.674641, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 143, Zero counter: 881, Accuracy: 0.5048828125\n",
            "[Pre-batch 230] Accuracy on full training data: 0.5338\n",
            "Batch: 230, Training Loss: 0.729262, Validation Loss: 0.669800, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 135, Zero counter: 889, Accuracy: 0.5205078125\n",
            "[Pre-batch 240] Accuracy on full training data: 0.5272\n",
            "Batch: 240, Training Loss: 0.719575, Validation Loss: 0.667782, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 95, Zero counter: 929, Accuracy: 0.5146484375\n",
            "[Pre-batch 250] Accuracy on full training data: 0.5382\n",
            "Batch: 250, Training Loss: 0.760190, Validation Loss: 0.668286, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 168, Zero counter: 856, Accuracy: 0.5390625\n",
            "[Pre-batch 260] Accuracy on full training data: 0.5413\n",
            "Batch: 260, Training Loss: 0.713386, Validation Loss: 0.680312, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 234, Zero counter: 790, Accuracy: 0.548828125\n",
            "[Pre-batch 270] Accuracy on full training data: 0.5302\n",
            "Batch: 270, Training Loss: 0.685225, Validation Loss: 0.676103, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.375 \\| VALIDATION: One counter: 134, Zero counter: 890, Accuracy: 0.52734375\n",
            "[Pre-batch 280] Accuracy on full training data: 0.5053\n",
            "Batch: 280, Training Loss: 0.657480, Validation Loss: 0.669109, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 17, Zero counter: 1007, Accuracy: 0.5009765625\n",
            "[Pre-batch 290] Accuracy on full training data: 0.5244\n",
            "Batch: 290, Training Loss: 0.694825, Validation Loss: 0.673513, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 98, Zero counter: 926, Accuracy: 0.51953125\n",
            "[Pre-batch 300] Accuracy on full training data: 0.5137\n",
            "Batch: 300, Training Loss: 0.804274, Validation Loss: 0.676359, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 55, Zero counter: 969, Accuracy: 0.5068359375\n",
            "[Pre-batch 310] Accuracy on full training data: 0.5142\n",
            "Batch: 310, Training Loss: 0.637574, Validation Loss: 0.684414, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 65, Zero counter: 959, Accuracy: 0.5107421875\n",
            "[Pre-batch 320] Accuracy on full training data: 0.5105\n",
            "Batch: 320, Training Loss: 0.601760, Validation Loss: 0.675702, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 63, Zero counter: 961, Accuracy: 0.5107421875\n",
            "[Pre-batch 330] Accuracy on full training data: 0.5138\n",
            "Batch: 330, Training Loss: 0.643727, Validation Loss: 0.681351, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 78, Zero counter: 946, Accuracy: 0.515625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.5231\n",
            "Batch: 340, Training Loss: 0.653920, Validation Loss: 0.676759, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 72, Zero counter: 952, Accuracy: 0.515625\n",
            "[Pre-batch 350] Accuracy on full training data: 0.5058\n",
            "Batch: 350, Training Loss: 0.688013, Validation Loss: 0.678848, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.3125 \\| VALIDATION: One counter: 54, Zero counter: 970, Accuracy: 0.51171875\n",
            "[Pre-batch 360] Accuracy on full training data: 0.5083\n",
            "Batch: 360, Training Loss: 0.648531, Validation Loss: 0.672967, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 42, Zero counter: 982, Accuracy: 0.51953125\n",
            "[Pre-batch 370] Accuracy on full training data: 0.5028\n",
            "Batch: 370, Training Loss: 0.629554, Validation Loss: 0.673802, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 21, Zero counter: 1003, Accuracy: 0.5009765625\n",
            "[Pre-batch 380] Accuracy on full training data: 0.5098\n",
            "Batch: 380, Training Loss: 0.647810, Validation Loss: 0.677074, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 56, Zero counter: 968, Accuracy: 0.51171875\n",
            "[Pre-batch 390] Accuracy on full training data: 0.5026\n",
            "Batch: 390, Training Loss: 0.612412, Validation Loss: 0.671353, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 17, Zero counter: 1007, Accuracy: 0.4990234375\n",
            "[Pre-batch 400] Accuracy on full training data: 0.5064\n",
            "Batch: 400, Training Loss: 0.690975, Validation Loss: 0.674438, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 24, Zero counter: 1000, Accuracy: 0.501953125\n",
            "[Pre-batch 410] Accuracy on full training data: 0.5089\n",
            "Batch: 410, Training Loss: 0.707089, Validation Loss: 0.674777, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 39, Zero counter: 985, Accuracy: 0.5126953125\n",
            "[Pre-batch 420] Accuracy on full training data: 0.5019\n",
            "Batch: 420, Training Loss: 0.713622, Validation Loss: 0.677219, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 6, Zero counter: 1018, Accuracy: 0.5\n",
            "[Pre-batch 430] Accuracy on full training data: 0.5001\n",
            "Batch: 430, Training Loss: 0.703119, Validation Loss: 0.687981, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 440] Accuracy on full training data: 0.5000\n",
            "Batch: 440, Training Loss: 0.727832, Validation Loss: 0.688075, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 450] Accuracy on full training data: 0.5001\n",
            "Batch: 450, Training Loss: 0.622168, Validation Loss: 0.679443, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 460] Accuracy on full training data: 0.5002\n",
            "Batch: 460, Training Loss: 0.656141, Validation Loss: 0.675336, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 470] Accuracy on full training data: 0.5040\n",
            "Batch: 470, Training Loss: 0.655821, Validation Loss: 0.677930, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 19, Zero counter: 1005, Accuracy: 0.5048828125\n",
            "[Pre-batch 480] Accuracy on full training data: 0.5047\n",
            "Batch: 480, Training Loss: 0.640446, Validation Loss: 0.675435, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 11, Zero counter: 1013, Accuracy: 0.5029296875\n",
            "[Pre-batch 490] Accuracy on full training data: 0.5002\n",
            "Batch: 490, Training Loss: 0.732206, Validation Loss: 0.677384, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.4990234375\n",
            "[Pre-batch 500] Accuracy on full training data: 0.5017\n",
            "Batch: 500, Training Loss: 0.636594, Validation Loss: 0.681290, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.4951171875\n",
            "[Pre-batch 510] Accuracy on full training data: 0.5000\n",
            "Batch: 510, Training Loss: 0.671915, Validation Loss: 0.680072, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 520] Accuracy on full training data: 0.5012\n",
            "Batch: 520, Training Loss: 0.725277, Validation Loss: 0.679050, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.25 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 530] Accuracy on full training data: 0.5000\n",
            "Batch: 530, Training Loss: 0.645517, Validation Loss: 0.676778, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 540] Accuracy on full training data: 0.5000\n",
            "Batch: 540, Training Loss: 0.673905, Validation Loss: 0.677019, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 550] Accuracy on full training data: 0.5002\n",
            "Batch: 550, Training Loss: 0.655418, Validation Loss: 0.671232, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 560] Accuracy on full training data: 0.5000\n",
            "Batch: 560, Training Loss: 0.657705, Validation Loss: 0.676550, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 570] Accuracy on full training data: 0.4999\n",
            "Batch: 570, Training Loss: 0.661738, Validation Loss: 0.681299, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 580] Accuracy on full training data: 0.5000\n",
            "Batch: 580, Training Loss: 0.771390, Validation Loss: 0.681094, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 590] Accuracy on full training data: 0.5000\n",
            "Batch: 590, Training Loss: 0.630788, Validation Loss: 0.678657, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 600] Accuracy on full training data: 0.5000\n",
            "Batch: 600, Training Loss: 0.680883, Validation Loss: 0.683264, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 610] Accuracy on full training data: 0.5000\n",
            "Batch: 610, Training Loss: 0.722948, Validation Loss: 0.676226, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 620] Accuracy on full training data: 0.5000\n",
            "Batch: 620, Training Loss: 0.718119, Validation Loss: 0.681367, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 630] Accuracy on full training data: 0.5000\n",
            "Batch: 630, Training Loss: 0.686807, Validation Loss: 0.682379, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 640] Accuracy on full training data: 0.5000\n",
            "Batch: 640, Training Loss: 0.691495, Validation Loss: 0.676793, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 650] Accuracy on full training data: 0.5000\n",
            "Batch: 650, Training Loss: 0.695940, Validation Loss: 0.675543, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 660] Accuracy on full training data: 0.5000\n",
            "Batch: 660, Training Loss: 0.692362, Validation Loss: 0.678459, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 670] Accuracy on full training data: 0.5000\n",
            "Batch: 670, Training Loss: 0.646900, Validation Loss: 0.675914, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 680] Accuracy on full training data: 0.5000\n",
            "Batch: 680, Training Loss: 0.670062, Validation Loss: 0.677358, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 690] Accuracy on full training data: 0.5000\n",
            "Batch: 690, Training Loss: 0.650705, Validation Loss: 0.674263, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 700] Accuracy on full training data: 0.5000\n",
            "Batch: 700, Training Loss: 0.657120, Validation Loss: 0.672615, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 710] Accuracy on full training data: 0.5000\n",
            "Batch: 710, Training Loss: 0.650585, Validation Loss: 0.673705, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 720] Accuracy on full training data: 0.5000\n",
            "Batch: 720, Training Loss: 0.661582, Validation Loss: 0.675405, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 730] Accuracy on full training data: 0.5000\n",
            "Batch: 730, Training Loss: 0.682597, Validation Loss: 0.675966, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.8125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 740] Accuracy on full training data: 0.5000\n",
            "Batch: 740, Training Loss: 0.714391, Validation Loss: 0.676050, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 750] Accuracy on full training data: 0.5000\n",
            "Batch: 750, Training Loss: 0.698069, Validation Loss: 0.675573, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 760] Accuracy on full training data: 0.5000\n",
            "Batch: 760, Training Loss: 0.648814, Validation Loss: 0.677510, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 770] Accuracy on full training data: 0.5000\n",
            "Batch: 770, Training Loss: 0.678755, Validation Loss: 0.679003, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 780] Accuracy on full training data: 0.5000\n",
            "Batch: 780, Training Loss: 0.698741, Validation Loss: 0.680138, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 790] Accuracy on full training data: 0.5000\n",
            "Batch: 790, Training Loss: 0.677812, Validation Loss: 0.678603, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 800] Accuracy on full training data: 0.5000\n",
            "Batch: 800, Training Loss: 0.680503, Validation Loss: 0.676397, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 810] Accuracy on full training data: 0.5000\n",
            "Batch: 810, Training Loss: 0.704035, Validation Loss: 0.676195, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 820] Accuracy on full training data: 0.5000\n",
            "Batch: 820, Training Loss: 0.713552, Validation Loss: 0.678208, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 830] Accuracy on full training data: 0.5000\n",
            "Batch: 830, Training Loss: 0.704249, Validation Loss: 0.676941, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 840] Accuracy on full training data: 0.5000\n",
            "Batch: 840, Training Loss: 0.647362, Validation Loss: 0.673778, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 850] Accuracy on full training data: 0.5000\n",
            "Batch: 850, Training Loss: 0.677635, Validation Loss: 0.676911, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 860] Accuracy on full training data: 0.5000\n",
            "Batch: 860, Training Loss: 0.651770, Validation Loss: 0.675659, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 870] Accuracy on full training data: 0.5000\n",
            "Batch: 870, Training Loss: 0.720872, Validation Loss: 0.671971, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 880] Accuracy on full training data: 0.5000\n",
            "Batch: 880, Training Loss: 0.684937, Validation Loss: 0.672711, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 890] Accuracy on full training data: 0.5000\n",
            "Batch: 890, Training Loss: 0.707149, Validation Loss: 0.677327, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 900] Accuracy on full training data: 0.5000\n",
            "Batch: 900, Training Loss: 0.672683, Validation Loss: 0.675736, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 910] Accuracy on full training data: 0.5000\n",
            "Batch: 910, Training Loss: 0.652603, Validation Loss: 0.674734, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 920] Accuracy on full training data: 0.5000\n",
            "Batch: 920, Training Loss: 0.668476, Validation Loss: 0.673273, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 930] Accuracy on full training data: 0.5000\n",
            "Batch: 930, Training Loss: 0.670647, Validation Loss: 0.675260, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 940] Accuracy on full training data: 0.5000\n",
            "Batch: 940, Training Loss: 0.695700, Validation Loss: 0.675488, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 950] Accuracy on full training data: 0.5000\n",
            "Batch: 950, Training Loss: 0.649242, Validation Loss: 0.674467, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 960] Accuracy on full training data: 0.5000\n",
            "Batch: 960, Training Loss: 0.643710, Validation Loss: 0.672790, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 970] Accuracy on full training data: 0.5000\n",
            "Batch: 970, Training Loss: 0.666666, Validation Loss: 0.674738, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 980] Accuracy on full training data: 0.5000\n",
            "Batch: 980, Training Loss: 0.671530, Validation Loss: 0.675667, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 990] Accuracy on full training data: 0.5000\n",
            "Batch: 990, Training Loss: 0.672882, Validation Loss: 0.674771, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block size = 5"
      ],
      "metadata": {
        "id": "800xsX02p9Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-2\n",
        "# dropout = 0\n",
        "# n = 15\n",
        "# m = 15\n",
        "# hidden_size = [128, 64]\n",
        "# t0 = 15\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 5\n",
        "n = 15\n",
        "m = 15\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 15\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_5, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_5.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_5.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGuPl7Olp_Bg",
        "outputId": "8a377ca3-1137-41ab-d406-4ce52bd6996a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 5\n",
            "Model created with input_size: 45\n",
            "Starting training...\n",
            "Length of the training dataset: 16000\n",
            "[Pre-batch 0] Accuracy on full training data: 0.5000\n",
            "Batch: 0, Training Loss: 0.613519, Validation Loss: 0.693307, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 10] Accuracy on full training data: 0.5035\n",
            "Batch: 10, Training Loss: 0.685197, Validation Loss: 0.693922, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 19, Zero counter: 1005, Accuracy: 0.5048828125\n",
            "[Pre-batch 20] Accuracy on full training data: 0.5147\n",
            "Batch: 20, Training Loss: 0.741964, Validation Loss: 0.690903, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 69, Zero counter: 955, Accuracy: 0.5087890625\n",
            "[Pre-batch 30] Accuracy on full training data: 0.5337\n",
            "Batch: 30, Training Loss: 0.768807, Validation Loss: 0.689039, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 124, Zero counter: 900, Accuracy: 0.52734375\n",
            "[Pre-batch 40] Accuracy on full training data: 0.5414\n",
            "Batch: 40, Training Loss: 0.630084, Validation Loss: 0.695425, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 230, Zero counter: 794, Accuracy: 0.541015625\n",
            "[Pre-batch 50] Accuracy on full training data: 0.5437\n",
            "Batch: 50, Training Loss: 0.833140, Validation Loss: 0.689565, TRAINING: One counter: 5, Zero counter: 11, Accuracy: 0.3125 \\| VALIDATION: One counter: 212, Zero counter: 812, Accuracy: 0.537109375\n",
            "[Pre-batch 60] Accuracy on full training data: 0.5363\n",
            "Batch: 60, Training Loss: 0.645528, Validation Loss: 0.679333, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.3125 \\| VALIDATION: One counter: 114, Zero counter: 910, Accuracy: 0.541015625\n",
            "[Pre-batch 70] Accuracy on full training data: 0.5383\n",
            "Batch: 70, Training Loss: 0.686726, Validation Loss: 0.680418, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 131, Zero counter: 893, Accuracy: 0.5419921875\n",
            "[Pre-batch 80] Accuracy on full training data: 0.5441\n",
            "Batch: 80, Training Loss: 0.643703, Validation Loss: 0.685755, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 155, Zero counter: 869, Accuracy: 0.5458984375\n",
            "[Pre-batch 90] Accuracy on full training data: 0.5376\n",
            "Batch: 90, Training Loss: 0.725035, Validation Loss: 0.693777, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5625 \\| VALIDATION: One counter: 154, Zero counter: 870, Accuracy: 0.52734375\n",
            "[Pre-batch 100] Accuracy on full training data: 0.5166\n",
            "Batch: 100, Training Loss: 0.698870, Validation Loss: 0.688491, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.4375 \\| VALIDATION: One counter: 88, Zero counter: 936, Accuracy: 0.50390625\n",
            "[Pre-batch 110] Accuracy on full training data: 0.5507\n",
            "Batch: 110, Training Loss: 0.669463, Validation Loss: 0.692718, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 205, Zero counter: 819, Accuracy: 0.5517578125\n",
            "[Pre-batch 120] Accuracy on full training data: 0.5603\n",
            "Batch: 120, Training Loss: 0.765832, Validation Loss: 0.685158, TRAINING: One counter: 4, Zero counter: 12, Accuracy: 0.5 \\| VALIDATION: One counter: 213, Zero counter: 811, Accuracy: 0.5654296875\n",
            "[Pre-batch 130] Accuracy on full training data: 0.5433\n",
            "Batch: 130, Training Loss: 0.763948, Validation Loss: 0.684557, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 128, Zero counter: 896, Accuracy: 0.54296875\n",
            "[Pre-batch 140] Accuracy on full training data: 0.5528\n",
            "Batch: 140, Training Loss: 0.669862, Validation Loss: 0.687965, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.375 \\| VALIDATION: One counter: 172, Zero counter: 852, Accuracy: 0.560546875\n",
            "[Pre-batch 150] Accuracy on full training data: 0.5401\n",
            "Batch: 150, Training Loss: 0.631972, Validation Loss: 0.678562, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 125, Zero counter: 899, Accuracy: 0.5517578125\n",
            "[Pre-batch 160] Accuracy on full training data: 0.5466\n",
            "Batch: 160, Training Loss: 0.710862, Validation Loss: 0.677164, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 162, Zero counter: 862, Accuracy: 0.55859375\n",
            "[Pre-batch 170] Accuracy on full training data: 0.5453\n",
            "Batch: 170, Training Loss: 0.637542, Validation Loss: 0.673246, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.6875 \\| VALIDATION: One counter: 136, Zero counter: 888, Accuracy: 0.5625\n",
            "[Pre-batch 180] Accuracy on full training data: 0.5465\n",
            "Batch: 180, Training Loss: 0.772369, Validation Loss: 0.682524, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5625 \\| VALIDATION: One counter: 159, Zero counter: 865, Accuracy: 0.5556640625\n",
            "[Pre-batch 190] Accuracy on full training data: 0.5212\n",
            "Batch: 190, Training Loss: 0.677938, Validation Loss: 0.690693, TRAINING: One counter: 3, Zero counter: 13, Accuracy: 0.5 \\| VALIDATION: One counter: 96, Zero counter: 928, Accuracy: 0.521484375\n",
            "[Pre-batch 200] Accuracy on full training data: 0.5116\n",
            "Batch: 200, Training Loss: 0.674553, Validation Loss: 0.694227, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.6875 \\| VALIDATION: One counter: 61, Zero counter: 963, Accuracy: 0.5126953125\n",
            "[Pre-batch 210] Accuracy on full training data: 0.5276\n",
            "Batch: 210, Training Loss: 0.698494, Validation Loss: 0.697027, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 84, Zero counter: 940, Accuracy: 0.53125\n",
            "[Pre-batch 220] Accuracy on full training data: 0.5202\n",
            "Batch: 220, Training Loss: 0.654357, Validation Loss: 0.701069, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.6875 \\| VALIDATION: One counter: 74, Zero counter: 950, Accuracy: 0.5078125\n",
            "[Pre-batch 230] Accuracy on full training data: 0.5369\n",
            "Batch: 230, Training Loss: 0.680326, Validation Loss: 0.687941, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 123, Zero counter: 901, Accuracy: 0.5341796875\n",
            "[Pre-batch 240] Accuracy on full training data: 0.5171\n",
            "Batch: 240, Training Loss: 0.664652, Validation Loss: 0.683518, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 48, Zero counter: 976, Accuracy: 0.51171875\n",
            "[Pre-batch 250] Accuracy on full training data: 0.5097\n",
            "Batch: 250, Training Loss: 0.720815, Validation Loss: 0.689512, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.375 \\| VALIDATION: One counter: 69, Zero counter: 955, Accuracy: 0.5126953125\n",
            "[Pre-batch 260] Accuracy on full training data: 0.5393\n",
            "Batch: 260, Training Loss: 0.648768, Validation Loss: 0.689186, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 107, Zero counter: 917, Accuracy: 0.5341796875\n",
            "[Pre-batch 270] Accuracy on full training data: 0.5244\n",
            "Batch: 270, Training Loss: 0.726054, Validation Loss: 0.694352, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 26, Zero counter: 998, Accuracy: 0.509765625\n",
            "[Pre-batch 280] Accuracy on full training data: 0.5298\n",
            "Batch: 280, Training Loss: 0.739054, Validation Loss: 0.685044, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 101, Zero counter: 923, Accuracy: 0.5380859375\n",
            "[Pre-batch 290] Accuracy on full training data: 0.5437\n",
            "Batch: 290, Training Loss: 0.754181, Validation Loss: 0.683574, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 144, Zero counter: 880, Accuracy: 0.548828125\n",
            "[Pre-batch 300] Accuracy on full training data: 0.5302\n",
            "Batch: 300, Training Loss: 0.687221, Validation Loss: 0.684638, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5625 \\| VALIDATION: One counter: 120, Zero counter: 904, Accuracy: 0.5390625\n",
            "[Pre-batch 310] Accuracy on full training data: 0.5385\n",
            "Batch: 310, Training Loss: 0.680641, Validation Loss: 0.684375, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 145, Zero counter: 879, Accuracy: 0.5458984375\n",
            "[Pre-batch 320] Accuracy on full training data: 0.5348\n",
            "Batch: 320, Training Loss: 0.660201, Validation Loss: 0.682034, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 105, Zero counter: 919, Accuracy: 0.5439453125\n",
            "[Pre-batch 330] Accuracy on full training data: 0.5367\n",
            "Batch: 330, Training Loss: 0.699343, Validation Loss: 0.681598, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 101, Zero counter: 923, Accuracy: 0.5400390625\n",
            "[Pre-batch 340] Accuracy on full training data: 0.5296\n",
            "Batch: 340, Training Loss: 0.658489, Validation Loss: 0.676712, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.4375 \\| VALIDATION: One counter: 78, Zero counter: 946, Accuracy: 0.53515625\n",
            "[Pre-batch 350] Accuracy on full training data: 0.5280\n",
            "Batch: 350, Training Loss: 0.718589, Validation Loss: 0.680736, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 61, Zero counter: 963, Accuracy: 0.5380859375\n",
            "[Pre-batch 360] Accuracy on full training data: 0.5084\n",
            "Batch: 360, Training Loss: 0.698720, Validation Loss: 0.702755, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 64, Zero counter: 960, Accuracy: 0.501953125\n",
            "[Pre-batch 370] Accuracy on full training data: 0.5370\n",
            "Batch: 370, Training Loss: 0.732694, Validation Loss: 0.682861, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.375 \\| VALIDATION: One counter: 134, Zero counter: 890, Accuracy: 0.55078125\n",
            "[Pre-batch 380] Accuracy on full training data: 0.5074\n",
            "Batch: 380, Training Loss: 0.659622, Validation Loss: 0.692852, TRAINING: One counter: 2, Zero counter: 14, Accuracy: 0.5 \\| VALIDATION: One counter: 58, Zero counter: 966, Accuracy: 0.50390625\n",
            "[Pre-batch 390] Accuracy on full training data: 0.5258\n",
            "Batch: 390, Training Loss: 0.685475, Validation Loss: 0.679938, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.4375 \\| VALIDATION: One counter: 53, Zero counter: 971, Accuracy: 0.5361328125\n",
            "[Pre-batch 400] Accuracy on full training data: 0.5048\n",
            "Batch: 400, Training Loss: 0.676174, Validation Loss: 0.693945, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.50390625\n",
            "[Pre-batch 410] Accuracy on full training data: 0.5099\n",
            "Batch: 410, Training Loss: 0.688926, Validation Loss: 0.686926, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 21, Zero counter: 1003, Accuracy: 0.5087890625\n",
            "[Pre-batch 420] Accuracy on full training data: 0.5068\n",
            "Batch: 420, Training Loss: 0.736716, Validation Loss: 0.685799, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 10, Zero counter: 1014, Accuracy: 0.50390625\n",
            "[Pre-batch 430] Accuracy on full training data: 0.5074\n",
            "Batch: 430, Training Loss: 0.652863, Validation Loss: 0.682645, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.625 \\| VALIDATION: One counter: 48, Zero counter: 976, Accuracy: 0.53125\n",
            "[Pre-batch 440] Accuracy on full training data: 0.5258\n",
            "Batch: 440, Training Loss: 0.685643, Validation Loss: 0.683539, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.5625 \\| VALIDATION: One counter: 58, Zero counter: 966, Accuracy: 0.537109375\n",
            "[Pre-batch 450] Accuracy on full training data: 0.5264\n",
            "Batch: 450, Training Loss: 0.707197, Validation Loss: 0.684883, TRAINING: One counter: 1, Zero counter: 15, Accuracy: 0.3125 \\| VALIDATION: One counter: 58, Zero counter: 966, Accuracy: 0.529296875\n",
            "[Pre-batch 460] Accuracy on full training data: 0.5066\n",
            "Batch: 460, Training Loss: 0.664388, Validation Loss: 0.685446, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 18, Zero counter: 1006, Accuracy: 0.505859375\n",
            "[Pre-batch 470] Accuracy on full training data: 0.5142\n",
            "Batch: 470, Training Loss: 0.687754, Validation Loss: 0.681431, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 49, Zero counter: 975, Accuracy: 0.5185546875\n",
            "[Pre-batch 480] Accuracy on full training data: 0.5296\n",
            "Batch: 480, Training Loss: 0.680998, Validation Loss: 0.681461, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.25 \\| VALIDATION: One counter: 65, Zero counter: 959, Accuracy: 0.5419921875\n",
            "[Pre-batch 490] Accuracy on full training data: 0.5014\n",
            "Batch: 490, Training Loss: 0.671533, Validation Loss: 0.686815, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.501953125\n",
            "[Pre-batch 500] Accuracy on full training data: 0.5026\n",
            "Batch: 500, Training Loss: 0.710349, Validation Loss: 0.686438, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.501953125\n",
            "[Pre-batch 510] Accuracy on full training data: 0.5048\n",
            "Batch: 510, Training Loss: 0.670938, Validation Loss: 0.688138, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 15, Zero counter: 1009, Accuracy: 0.5048828125\n",
            "[Pre-batch 520] Accuracy on full training data: 0.5246\n",
            "Batch: 520, Training Loss: 0.690757, Validation Loss: 0.684573, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 48, Zero counter: 976, Accuracy: 0.52734375\n",
            "[Pre-batch 530] Accuracy on full training data: 0.5029\n",
            "Batch: 530, Training Loss: 0.678697, Validation Loss: 0.685302, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 2, Zero counter: 1022, Accuracy: 0.501953125\n",
            "[Pre-batch 540] Accuracy on full training data: 0.5000\n",
            "Batch: 540, Training Loss: 0.695562, Validation Loss: 0.686838, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5009765625\n",
            "[Pre-batch 550] Accuracy on full training data: 0.5029\n",
            "Batch: 550, Training Loss: 0.691894, Validation Loss: 0.684091, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 6, Zero counter: 1018, Accuracy: 0.50390625\n",
            "[Pre-batch 560] Accuracy on full training data: 0.5002\n",
            "Batch: 560, Training Loss: 0.680433, Validation Loss: 0.687854, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 570] Accuracy on full training data: 0.5015\n",
            "Batch: 570, Training Loss: 0.689198, Validation Loss: 0.689170, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 6, Zero counter: 1018, Accuracy: 0.501953125\n",
            "[Pre-batch 580] Accuracy on full training data: 0.5033\n",
            "Batch: 580, Training Loss: 0.675665, Validation Loss: 0.688337, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.4990234375\n",
            "[Pre-batch 590] Accuracy on full training data: 0.5005\n",
            "Batch: 590, Training Loss: 0.685009, Validation Loss: 0.687171, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.4990234375\n",
            "[Pre-batch 600] Accuracy on full training data: 0.5286\n",
            "Batch: 600, Training Loss: 0.693421, Validation Loss: 0.681644, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 66, Zero counter: 958, Accuracy: 0.54296875\n",
            "[Pre-batch 610] Accuracy on full training data: 0.5021\n",
            "Batch: 610, Training Loss: 0.704822, Validation Loss: 0.687655, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5009765625\n",
            "[Pre-batch 620] Accuracy on full training data: 0.5001\n",
            "Batch: 620, Training Loss: 0.684860, Validation Loss: 0.688798, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 630] Accuracy on full training data: 0.5009\n",
            "Batch: 630, Training Loss: 0.716790, Validation Loss: 0.687728, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.4990234375\n",
            "[Pre-batch 640] Accuracy on full training data: 0.5008\n",
            "Batch: 640, Training Loss: 0.678280, Validation Loss: 0.684482, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 650] Accuracy on full training data: 0.5011\n",
            "Batch: 650, Training Loss: 0.691059, Validation Loss: 0.685389, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 2, Zero counter: 1022, Accuracy: 0.501953125\n",
            "[Pre-batch 660] Accuracy on full training data: 0.5014\n",
            "Batch: 660, Training Loss: 0.695274, Validation Loss: 0.685469, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 6, Zero counter: 1018, Accuracy: 0.505859375\n",
            "[Pre-batch 670] Accuracy on full training data: 0.5012\n",
            "Batch: 670, Training Loss: 0.690762, Validation Loss: 0.686764, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.5048828125\n",
            "[Pre-batch 680] Accuracy on full training data: 0.5010\n",
            "Batch: 680, Training Loss: 0.694591, Validation Loss: 0.686827, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5029296875\n",
            "[Pre-batch 690] Accuracy on full training data: 0.5058\n",
            "Batch: 690, Training Loss: 0.684751, Validation Loss: 0.688641, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 19, Zero counter: 1005, Accuracy: 0.5068359375\n",
            "[Pre-batch 700] Accuracy on full training data: 0.5011\n",
            "Batch: 700, Training Loss: 0.699453, Validation Loss: 0.689015, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 710] Accuracy on full training data: 0.5001\n",
            "Batch: 710, Training Loss: 0.688804, Validation Loss: 0.687425, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.75 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5009765625\n",
            "[Pre-batch 720] Accuracy on full training data: 0.5218\n",
            "Batch: 720, Training Loss: 0.674641, Validation Loss: 0.684827, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 38, Zero counter: 986, Accuracy: 0.525390625\n",
            "[Pre-batch 730] Accuracy on full training data: 0.5000\n",
            "Batch: 730, Training Loss: 0.688391, Validation Loss: 0.688780, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 740] Accuracy on full training data: 0.5009\n",
            "Batch: 740, Training Loss: 0.685551, Validation Loss: 0.687624, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 5, Zero counter: 1019, Accuracy: 0.5048828125\n",
            "[Pre-batch 750] Accuracy on full training data: 0.5290\n",
            "Batch: 750, Training Loss: 0.700483, Validation Loss: 0.686640, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 52, Zero counter: 972, Accuracy: 0.51171875\n",
            "[Pre-batch 760] Accuracy on full training data: 0.5189\n",
            "Batch: 760, Training Loss: 0.676241, Validation Loss: 0.686019, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.1875 \\| VALIDATION: One counter: 55, Zero counter: 969, Accuracy: 0.5205078125\n",
            "[Pre-batch 770] Accuracy on full training data: 0.5026\n",
            "Batch: 770, Training Loss: 0.704979, Validation Loss: 0.685644, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 14, Zero counter: 1010, Accuracy: 0.50390625\n",
            "[Pre-batch 780] Accuracy on full training data: 0.5019\n",
            "Batch: 780, Training Loss: 0.692582, Validation Loss: 0.687827, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 8, Zero counter: 1016, Accuracy: 0.501953125\n",
            "[Pre-batch 790] Accuracy on full training data: 0.5037\n",
            "Batch: 790, Training Loss: 0.685341, Validation Loss: 0.686987, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.501953125\n",
            "[Pre-batch 800] Accuracy on full training data: 0.5004\n",
            "Batch: 800, Training Loss: 0.678729, Validation Loss: 0.688876, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 810] Accuracy on full training data: 0.5034\n",
            "Batch: 810, Training Loss: 0.677115, Validation Loss: 0.684761, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 8, Zero counter: 1016, Accuracy: 0.50390625\n",
            "[Pre-batch 820] Accuracy on full training data: 0.5001\n",
            "Batch: 820, Training Loss: 0.685615, Validation Loss: 0.688975, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 830] Accuracy on full training data: 0.5000\n",
            "Batch: 830, Training Loss: 0.682126, Validation Loss: 0.687753, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 840] Accuracy on full training data: 0.5060\n",
            "Batch: 840, Training Loss: 0.692629, Validation Loss: 0.686111, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 8, Zero counter: 1016, Accuracy: 0.50390625\n",
            "[Pre-batch 850] Accuracy on full training data: 0.5029\n",
            "Batch: 850, Training Loss: 0.682568, Validation Loss: 0.686371, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.4375 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5029296875\n",
            "[Pre-batch 860] Accuracy on full training data: 0.5024\n",
            "Batch: 860, Training Loss: 0.678357, Validation Loss: 0.685748, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 4, Zero counter: 1020, Accuracy: 0.50390625\n",
            "[Pre-batch 870] Accuracy on full training data: 0.4999\n",
            "Batch: 870, Training Loss: 0.693493, Validation Loss: 0.687665, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 880] Accuracy on full training data: 0.5001\n",
            "Batch: 880, Training Loss: 0.697716, Validation Loss: 0.687304, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 890] Accuracy on full training data: 0.5001\n",
            "Batch: 890, Training Loss: 0.680252, Validation Loss: 0.689615, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 900] Accuracy on full training data: 0.5019\n",
            "Batch: 900, Training Loss: 0.694639, Validation Loss: 0.687741, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.6875 \\| VALIDATION: One counter: 3, Zero counter: 1021, Accuracy: 0.5029296875\n",
            "[Pre-batch 910] Accuracy on full training data: 0.5006\n",
            "Batch: 910, Training Loss: 0.682540, Validation Loss: 0.689640, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 920] Accuracy on full training data: 0.5002\n",
            "Batch: 920, Training Loss: 0.691960, Validation Loss: 0.688913, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 1, Zero counter: 1023, Accuracy: 0.5009765625\n",
            "[Pre-batch 930] Accuracy on full training data: 0.5000\n",
            "Batch: 930, Training Loss: 0.692483, Validation Loss: 0.689586, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 940] Accuracy on full training data: 0.5000\n",
            "Batch: 940, Training Loss: 0.685253, Validation Loss: 0.690144, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.25 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 950] Accuracy on full training data: 0.5000\n",
            "Batch: 950, Training Loss: 0.684212, Validation Loss: 0.690061, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.5625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 960] Accuracy on full training data: 0.5000\n",
            "Batch: 960, Training Loss: 0.689184, Validation Loss: 0.691353, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.375 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 970] Accuracy on full training data: 0.5000\n",
            "Batch: 970, Training Loss: 0.688358, Validation Loss: 0.690690, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.3125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 980] Accuracy on full training data: 0.5000\n",
            "Batch: 980, Training Loss: 0.697133, Validation Loss: 0.690460, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.625 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n",
            "[Pre-batch 990] Accuracy on full training data: 0.5000\n",
            "Batch: 990, Training Loss: 0.686874, Validation Loss: 0.690541, TRAINING: One counter: 0, Zero counter: 16, Accuracy: 0.8125 \\| VALIDATION: One counter: 0, Zero counter: 1024, Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LR = 1e-2\n",
        "# dropout = 0\n",
        "# n = 25\n",
        "# m = 25\n",
        "# hidden_size = [128, 64]\n",
        "# t0 = 0\n",
        "print(\"_______________________________________________________________________\")\n",
        "block_size = 5\n",
        "n = 25\n",
        "m = 25\n",
        "print(f\"Block size = {block_size}\")\n",
        "num_samples = 2**10\n",
        "t0 = 15\n",
        "rho = 0.5\n",
        "tau = block_size\n",
        "dataset_parameters = [num_samples, block_size, m, n, tau, t0, rho]\n",
        "batch_size = 16\n",
        "train_size = 16*1000\n",
        "val_size = 2**10\n",
        "input_size = (m//block_size)**2 * (tau)\n",
        "hidden_size = [128, 64]\n",
        "output_size = 1\n",
        "model = MLP(input_size, hidden_size, output_size, dropout_rate=0)\n",
        "print(f\"Model created with input_size: {input_size}\")\n",
        "print(\"Starting training...\")\n",
        "trained_model_test_5, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
        "# save the trained_model_test in my google drive\n",
        "torch.save(trained_model_test_5.state_dict(), \"/content/drive/My Drive/Colab Notebooks/trained_model_test_5.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwAvbS3tREYh",
        "outputId": "5a5a09ff-2426-4e30-f99e-6ca196baa29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_______________________________________________________________________\n",
            "Block size = 5\n",
            "Model created with input_size: 125\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-1869367598>\", line 26, in <cell line: 0>\n",
            "    trained_model_test_5, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 202, in train_validate\n",
            "    training_dataset = gol_dataset(train_size, block_size, m, n, tau, t0, rho, balance=True, normalize=True)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 96, in __init__\n",
            "    grid = next_step_fn(grid)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-2972067934>\", line None, in next_step_fn\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-1869367598>\", line 26, in <cell line: 0>\n",
            "    trained_model_test_5, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 202, in train_validate\n",
            "    training_dataset = gol_dataset(train_size, block_size, m, n, tau, t0, rho, balance=True, normalize=True)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 96, in __init__\n",
            "    grid = next_step_fn(grid)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-2972067934>\", line None, in next_step_fn\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-1869367598>\", line 26, in <cell line: 0>\n",
            "    trained_model_test_5, train_losses, val_losses, acc_batch = train_validate(model, batch_size, train_size, val_size, dataset_parameters, fixed=True, conv=False, balance=True, lambda_l1=0.01, printing_rhythm = 10, verbose=True)\n",
            "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 202, in train_validate\n",
            "    training_dataset = gol_dataset(train_size, block_size, m, n, tau, t0, rho, balance=True, normalize=True)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-3-2349955934>\", line 96, in __init__\n",
            "    grid = next_step_fn(grid)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-2-2972067934>\", line None, in next_step_fn\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
          ]
        }
      ]
    }
  ]
}